{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For evaluation metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Set the random seeds for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "#If CUDA/MPS is available...\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed Mean: 0.13066047430038452\n",
      "Computed Std: 0.30810782313346863\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the MNIST training set with only the ToTensor() transform\n",
    "temp_transform = transforms.ToTensor()\n",
    "temp_train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=temp_transform)\n",
    "\n",
    "# Create a DataLoader that loads the entire dataset in one batch\n",
    "temp_loader = DataLoader(temp_train_dataset, batch_size=len(temp_train_dataset), shuffle=False)\n",
    "data, _ = next(iter(temp_loader))\n",
    "\n",
    "# Compute the mean and standard deviation across the entire training dataset\n",
    "mean = data.mean().item()\n",
    "std = data.std().item()\n",
    "print(\"Computed Mean:\", mean)\n",
    "print(\"Computed Std:\", std)\n",
    "\n",
    "# Step 2: Define the transformation pipeline using the computed mean and std\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((mean,), (std,))\n",
    "])\n",
    "\n",
    "# Step 3: Reload the MNIST training and test datasets using the updated transform\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Step 4: Create DataLoader objects for batching and shuffling the data\n",
    "batch_size = 64\n",
    "\n",
    "# for windows, linux\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model1, self).__init__()\n",
    "        self.flatten = nn.Flatten()  # Flattens the 28x28 image into a 784-dim vector.\n",
    "        self.fc = nn.Linear(28*28, 10)  # Fully connected layer mapping to 10 output classes.\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model2, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28*28, 128)  # Hidden layer with 128 neurons.\n",
    "        self.relu = nn.ReLU()             # Activation function.\n",
    "        self.fc2 = nn.Linear(128, 10)       # Output layer mapping to 10 classes.\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model3, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)  # Batch normalization after first layer.\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.5)   # Dropout regularization with probability 0.5.\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)     # Batch normalization after second layer.\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, device, epochs=5):\n",
    "    model.train()  # Set model to training mode.\n",
    "    train_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()  # Clear gradients from the previous step.\n",
    "            outputs = model(data)  # Forward pass.\n",
    "            loss = criterion(outputs, target)  # Compute the loss.\n",
    "            loss.backward()  # Backward pass (compute gradients).\n",
    "            optimizer.step()  # Update model parameters.\n",
    "            running_loss += loss.item() * data.size(0)\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        train_losses.append(epoch_loss)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}\")\n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()  # Set model to evaluation mode.\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "    # Compute confusion matrix and classification report\n",
    "    cm = confusion_matrix(all_targets, all_preds)\n",
    "    report = classification_report(all_targets, all_preds, output_dict=True)\n",
    "    return cm, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def plot_misclassified(model, test_loader, device, n=36, title=\"Misclassified Examples\"):\n",
    "    model.eval()\n",
    "    misclassified_images = []\n",
    "    misclassified_preds = []\n",
    "    misclassified_targets = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            for i in range(len(target)):\n",
    "                if preds[i] != target[i]:\n",
    "                    misclassified_images.append(data[i].cpu().numpy().squeeze())\n",
    "                    misclassified_preds.append(preds[i].cpu().item())\n",
    "                    misclassified_targets.append(target[i].cpu().item())\n",
    "                if len(misclassified_images) >= n:\n",
    "                    break\n",
    "            if len(misclassified_images) >= n:\n",
    "                break\n",
    "    \n",
    "    # If misclassified_images has fewer than n, fill the rest with blank images\n",
    "    while len(misclassified_images) < n:\n",
    "        blank_image = np.zeros((28, 28))\n",
    "        misclassified_images.append(blank_image)\n",
    "        misclassified_preds.append(None)\n",
    "        misclassified_targets.append(None)\n",
    "    \n",
    "    # Create a 6x6 grid for 36 images; each subplot is smaller.\n",
    "    fig, axes = plt.subplots(6, 6, figsize=(8, 8))\n",
    "    fig.suptitle(title)\n",
    "    idx = 0\n",
    "    for i in range(6):\n",
    "        for j in range(6):\n",
    "            ax = axes[i, j]\n",
    "            image = misclassified_images[idx]\n",
    "            ax.imshow(image, cmap='gray')\n",
    "            if misclassified_preds[idx] is not None:\n",
    "                ax.set_title(f\"P:{misclassified_preds[idx]}\\nT:{misclassified_targets[idx]}\", fontsize=8)\n",
    "            else:\n",
    "                ax.set_title(\"Blank\", fontsize=8)\n",
    "            ax.axis('off')\n",
    "            idx += 1\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model 1 (One-Layer, No Regularization)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Model 1, define loss function and optimizer\n",
    "model1 = Model1().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer1 = optim.Adam(model1.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Training Model 1 (One-Layer, No Regularization)\")\n",
    "losses1 = train_model(model1, train_loader, criterion, optimizer1, device, epochs=5)\n",
    "\n",
    "# Evaluate Model 1 on test data\n",
    "cm1, report1 = evaluate_model(model1, test_loader, device)\n",
    "print(\"Classification Report for Model 1:\")\n",
    "print(report1)\n",
    "\n",
    "# Plot confusion matrix for Model 1\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm1, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix for Model 1')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Model 2, define its optimizer\n",
    "model2 = Model2().to(device)\n",
    "optimizer2 = optim.Adam(model2.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Training Model 2 (Two-Layer, No Regularization)\")\n",
    "losses2 = train_model(model2, train_loader, criterion, optimizer2, device, epochs=5)\n",
    "\n",
    "# Evaluate Model 2 on test data\n",
    "cm2, report2 = evaluate_model(model2, test_loader, device)\n",
    "print(\"Classification Report for Model 2:\")\n",
    "print(report2)\n",
    "\n",
    "# Plot confusion matrix for Model 2\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm2, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix for Model 2')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Model 3, define its optimizer\n",
    "model3 = Model3().to(device)\n",
    "optimizer3 = optim.Adam(model3.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Training Model 3 (Two Hidden Layers with Batch Norm and Dropout)\")\n",
    "losses3 = train_model(model3, train_loader, criterion, optimizer3, device, epochs=5)\n",
    "\n",
    "# Evaluate Model 3 on test data\n",
    "cm3, report3 = evaluate_model(model3, test_loader, device)\n",
    "print(\"Classification Report for Model 3:\")\n",
    "print(report3)\n",
    "\n",
    "# Plot confusion matrix for Model 3\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm3, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix for Model 3')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(losses1, label='Model 1: 1 Layer')\n",
    "plt.plot(losses2, label='Model 2: 2 Layers')\n",
    "plt.plot(losses3, label='Model 3: 2 Hidden Layers with Reg.')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss per Epoch for Different Models')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metrics(report):\n",
    "    return {\n",
    "        \"Accuracy\": report['accuracy'],\n",
    "        \"Macro Precision\": report['macro avg']['precision'],\n",
    "        \"Macro Recall\": report['macro avg']['recall'],\n",
    "        \"Macro F1-Score\": report['macro avg']['f1-score'],\n",
    "        \"Weighted Precision\": report['weighted avg']['precision'],\n",
    "        \"Weighted Recall\": report['weighted avg']['recall'],\n",
    "        \"Weighted F1-Score\": report['weighted avg']['f1-score']\n",
    "    }\n",
    "\n",
    "metrics1 = extract_metrics(report1)\n",
    "metrics2 = extract_metrics(report2)\n",
    "metrics3 = extract_metrics(report3)\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    \"Model 1\": metrics1,\n",
    "    \"Model 2\": metrics2,\n",
    "    \"Model 3\": metrics3\n",
    "})\n",
    "metrics_df = metrics_df.T  # Transpose for easier reading\n",
    "print(\"Evaluation Metrics Summary:\")\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_misclassified(model1, test_loader, device, n=36, title=\"Misclassified Examples - Model 1\")\n",
    "plot_misclassified(model2, test_loader, device, n=36, title=\"Misclassified Examples - Model 2\")\n",
    "plot_misclassified(model3, test_loader, device, n=36, title=\"Misclassified Examples - Model 3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
