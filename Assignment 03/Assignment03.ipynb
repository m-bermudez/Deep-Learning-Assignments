{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For evaluation metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Set the random seeds for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "#If CUDA/MPS is available...\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
<<<<<<< HEAD
    "print(f\"Using device: {device}\")"
=======
    "print(f\"Using device: {device}\")\n"
>>>>>>> 2c18a8a35eaec464601f7b0ff653642c2621cfd3
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:00<00:00, 11.6MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 865kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 5.90MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 3.63MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed Mean: 0.13066047430038452\n",
      "Computed Std: 0.30810782313346863\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the MNIST training set with only the ToTensor() transform\n",
    "temp_transform = transforms.ToTensor()\n",
    "temp_train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=temp_transform)\n",
    "\n",
    "# Create a DataLoader that loads the entire dataset in one batch\n",
    "temp_loader = DataLoader(temp_train_dataset, batch_size=len(temp_train_dataset), shuffle=False)\n",
    "data, _ = next(iter(temp_loader))\n",
    "\n",
    "# Compute the mean and standard deviation across the entire training dataset\n",
    "mean = data.mean().item()\n",
    "std = data.std().item()\n",
    "print(\"Computed Mean:\", mean)\n",
    "print(\"Computed Std:\", std)\n",
    "\n",
    "# Step 2: Define the transformation pipeline using the computed mean and std\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((mean,), (std,))\n",
    "])\n",
    "\n",
    "# Step 3: Reload the MNIST training and test datasets using the updated transform\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Step 4: Create DataLoader objects for batching and shuffling the data\n",
    "batch_size = 64\n",
    "\n",
    "# for windows, linux\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model1, self).__init__()\n",
    "        self.flatten = nn.Flatten()  # Flattens the 28x28 image into a 784-dim vector.\n",
    "        self.fc = nn.Linear(28*28, 10)  # Fully connected layer mapping to 10 output classes.\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model2, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28*28, 128)  # Hidden layer with 128 neurons.\n",
    "        self.relu = nn.ReLU()             # Activation function.\n",
    "        self.fc2 = nn.Linear(128, 10)       # Output layer mapping to 10 classes.\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model3, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)  # Batch normalization after first layer.\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.5)   # Dropout regularization with probability 0.5.\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)     # Batch normalization after second layer.\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, device, epochs=5):\n",
    "    model.train()  # Set model to training mode.\n",
    "    train_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()  # Clear gradients from the previous step.\n",
    "            outputs = model(data)  # Forward pass.\n",
    "            loss = criterion(outputs, target)  # Compute the loss.\n",
    "            loss.backward()  # Backward pass (compute gradients).\n",
    "            optimizer.step()  # Update model parameters.\n",
    "            running_loss += loss.item() * data.size(0)\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        train_losses.append(epoch_loss)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}\")\n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()  # Set model to evaluation mode.\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "    # Compute confusion matrix and classification report\n",
    "    cm = confusion_matrix(all_targets, all_preds)\n",
    "    report = classification_report(all_targets, all_preds, output_dict=True)\n",
    "    return cm, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_misclassified(model, test_loader, device, n=36, title=\"Misclassified Examples\"):\n",
    "    model.eval()\n",
    "    misclassified_images = []\n",
    "    misclassified_preds = []\n",
    "    misclassified_targets = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            for i in range(len(target)):\n",
    "                if preds[i] != target[i]:\n",
    "                    misclassified_images.append(data[i].cpu().numpy().squeeze())\n",
    "                    misclassified_preds.append(preds[i].cpu().item())\n",
    "                    misclassified_targets.append(target[i].cpu().item())\n",
    "                if len(misclassified_images) >= n:\n",
    "                    break\n",
    "            if len(misclassified_images) >= n:\n",
    "                break\n",
    "    \n",
    "    # If misclassified_images has fewer than n, fill the rest with blank images\n",
    "    while len(misclassified_images) < n:\n",
    "        blank_image = np.zeros((28, 28))\n",
    "        misclassified_images.append(blank_image)\n",
    "        misclassified_preds.append(None)\n",
    "        misclassified_targets.append(None)\n",
    "    \n",
    "    # Create a 6x6 grid for 36 images; each subplot is smaller.\n",
    "    fig, axes = plt.subplots(6, 6, figsize=(8, 8))\n",
    "    fig.suptitle(title)\n",
    "    idx = 0\n",
    "    for i in range(6):\n",
    "        for j in range(6):\n",
    "            ax = axes[i, j]\n",
    "            image = misclassified_images[idx]\n",
    "            ax.imshow(image, cmap='gray')\n",
    "            if misclassified_preds[idx] is not None:\n",
    "                ax.set_title(f\"P:{misclassified_preds[idx]}\\nT:{misclassified_targets[idx]}\", fontsize=8)\n",
    "            else:\n",
    "                ax.set_title(\"Blank\", fontsize=8)\n",
    "            ax.axis('off')\n",
    "            idx += 1\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model 1 (One-Layer, No Regularization)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "                             ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "              ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^  File \"/opt/anaconda3/lib/python3.12/site-packages/torchvision/__init__.py\", line 10, in <module>\n",
      "^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torchvision/__init__.py\", line 10, in <module>\n",
      "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils  # usort:skip    \n",
      "from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils  # usort:skip\n",
      "       ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torchvision/models/__init__.py\", line 2, in <module>\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torchvision/models/__init__.py\", line 2, in <module>\n",
      "    from .convnext import *\n",
      "    from .convnext import *\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torchvision/models/convnext.py\", line 8, in <module>\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torchvision/models/convnext.py\", line 8, in <module>\n",
      "    from ..ops.misc import Conv2dNormActivation, Permute\n",
      "    from ..ops.misc import Conv2dNormActivation, Permute\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torchvision/ops/__init__.py\", line 23, in <module>\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torchvision/ops/__init__.py\", line 23, in <module>\n",
      "    from .poolers import MultiScaleRoIAlign\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torchvision/ops/poolers.py\", line 10, in <module>\n",
      "    from .poolers import MultiScaleRoIAlign\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torchvision/ops/poolers.py\", line 10, in <module>\n",
      "    from .roi_align import roi_align\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torchvision/ops/roi_align.py\", line 7, in <module>\n",
      "    from .roi_align import roi_align\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torchvision/ops/roi_align.py\", line 7, in <module>\n",
      "    from torch._dynamo.utils import is_compile_supported\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/_dynamo/__init__.py\", line 3, in <module>\n",
      "    from torch._dynamo.utils import is_compile_supported\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/_dynamo/__init__.py\", line 3, in <module>\n",
      "    from . import convert_frame, eval_frame, resume_execution\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 33, in <module>\n",
      "    from . import convert_frame, eval_frame, resume_execution\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 33, in <module>\n",
      "    from torch._dynamo.symbolic_convert import TensorifyState\n",
      "    from torch._dynamo.symbolic_convert import TensorifyState\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 30, in <module>\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 30, in <module>\n",
      "    from . import config, exc, logging as torchdynamo_logging, trace_rules, variables\n",
      "    from . import config, exc, logging as torchdynamo_logging, trace_rules, variables\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py\", line 46, in <module>\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py\", line 46, in <module>\n",
      "    from .variables import (\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/_dynamo/variables/__init__.py\", line 2, in <module>\n",
      "    from .variables import (\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/_dynamo/variables/__init__.py\", line 2, in <module>\n",
      "    from .builtin import BuiltinVariable\n",
      "    from .builtin import BuiltinVariable\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py\", line 53, in <module>\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py\", line 53, in <module>\n",
      "    from .ctx_manager import EventVariable, StreamVariable\n",
      "    from .ctx_manager import EventVariable, StreamVariable\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/_dynamo/variables/ctx_manager.py\", line 22, in <module>\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/_dynamo/variables/ctx_manager.py\", line 22, in <module>\n",
      "    from .functions import (\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py\", line 33, in <module>\n",
      "    from .functions import (\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py\", line 33, in <module>\n",
      "    from torch.distributed.fsdp._fully_shard import _fsdp_param_group\n",
      "    from torch.distributed.fsdp._fully_shard import _fsdp_param_group\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/distributed/fsdp/__init__.py\", line 1, in <module>\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/distributed/fsdp/__init__.py\", line 1, in <module>\n",
      "    from ._flat_param import FlatParameter as FlatParameter\n",
      "    from ._flat_param import FlatParameter as FlatParameter\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py\", line 47, in <module>\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py\", line 47, in <module>\n",
      "    from ._fsdp_extensions import (\n",
      "    from ._fsdp_extensions import (  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/distributed/fsdp/_fsdp_extensions.py\", line 8, in <module>\n",
      "\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/distributed/fsdp/_fsdp_extensions.py\", line 8, in <module>\n",
      "    from torch.distributed.fsdp._shard_utils import (\n",
      "    from torch.distributed.fsdp._shard_utils import (\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/distributed/fsdp/_shard_utils.py\", line 18, in <module>\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/distributed/fsdp/_shard_utils.py\", line 18, in <module>\n",
      "    from torch.distributed.tensor import DeviceMesh, DTensor, Replicate, Shard as DShard\n",
      "    from torch.distributed.tensor import DeviceMesh, DTensor, Replicate, Shard as DShard\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/distributed/tensor/__init__.py\", line 4, in <module>\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/distributed/tensor/__init__.py\", line 4, in <module>\n",
      "    import torch.distributed.tensor._ops  # force import all built-in dtensor ops\n",
      "    import torch.distributed.tensor._ops  # force import all built-in dtensor ops\n",
      "     ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/distributed/tensor/_ops/__init__.py\", line 2, in <module>\n",
      "\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/distributed/tensor/_ops/__init__.py\", line 2, in <module>\n",
      "    from ._conv_ops import *  # noqa: F403\n",
      "    from ._conv_ops import *  # noqa: F403\n",
      "    ^^^^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/distributed/tensor/_ops/_conv_ops.py\", line 7, in <module>\n",
      "^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/distributed/tensor/_ops/_conv_ops.py\", line 7, in <module>\n",
      "    from torch.distributed.tensor._dtensor_spec import DTensorSpec, TensorMeta\n",
      "    from torch.distributed.tensor._dtensor_spec import DTensorSpec, TensorMeta\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/distributed/tensor/_dtensor_spec.py\", line 6, in <module>\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/distributed/tensor/_dtensor_spec.py\", line 6, in <module>\n",
      "    from torch.distributed.tensor.placement_types import (\n",
      "    from torch.distributed.tensor.placement_types import (\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/distributed/tensor/placement_types.py\", line 8, in <module>\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/distributed/tensor/placement_types.py\", line 8, in <module>\n",
      "    import torch.distributed._functional_collectives as funcol\n",
      "    import torch.distributed._functional_collectives as funcol\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py\", line 977, in <module>\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py\", line 977, in <module>\n",
      "    lib_impl = torch.library.Library(\"_c10d_functional\", \"IMPL\")\n",
      "    lib_impl = torch.library.Library(\"_c10d_functional\", \"IMPL\")\n",
      "                       ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/library.py\", line 91, in __init__\n",
      "^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/library.py\", line 91, in __init__\n",
      "    frame = traceback.extract_stack(limit=3)[0]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/traceback.py\", line 232, in extract_stack\n",
      "    frame = traceback.extract_stack(limit=3)[0]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/traceback.py\", line 232, in extract_stack\n",
      "    stack = StackSummary.extract(walk_stack(f), limit=limit)\n",
      "    stack = StackSummary.extract(walk_stack(f), limit=limit)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/traceback.py\", line 395, in extract\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/traceback.py\", line 395, in extract\n",
      "    return klass._extract_from_extended_frame_gen(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/traceback.py\", line 434, in _extract_from_extended_frame_gen\n",
      "    return klass._extract_from_extended_frame_gen(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/traceback.py\", line 438, in _extract_from_extended_frame_gen\n",
      "    linecache.checkcache(filename)\n",
      "  File \"/opt/anaconda3/lib/python3.12/linecache.py\", line 52, in checkcache\n",
      "    f.line\n",
      "  File \"/opt/anaconda3/lib/python3.12/traceback.py\", line 323, in line\n",
      "    self._line = linecache.getline(self.filename, self.lineno)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/linecache.py\", line 30, in getline\n",
      "    def checkcache(filename=None):\n",
      "    \n",
      "    KeyboardInterruptlines = getlines(filename, module_globals)\n",
      "\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/linecache.py\", line 46, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/linecache.py\", line 141, in updatecache\n",
      "    with tokenize.open(fullname) as fp:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/tokenize.py\", line 443, in open\n",
      "    buffer = _builtin_open(filename, 'rb')\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x10b0750d0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 790, in _clean_thread_parent_frames\n",
      "    active_threads = {thread.ident for thread in threading.enumerate()}\n",
      "                      ^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/_utils/signal_handling.py\", line 73, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 3212) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m optimizer1 \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model1\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Model 1 (One-Layer, No Regularization)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m losses1 \u001b[38;5;241m=\u001b[39m train_model(model1, train_loader, criterion, optimizer1, device, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Evaluate Model 1 on test data\u001b[39;00m\n\u001b[1;32m     10\u001b[0m cm1, report1 \u001b[38;5;241m=\u001b[39m evaluate_model(model1, test_loader, device)\n",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer, device, epochs)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      5\u001b[0m     running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m      7\u001b[0m         data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Clear gradients from the previous step.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1458\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1457\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1458\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data()\n\u001b[1;32m   1459\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1461\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1420\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1416\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1417\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1419\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1420\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_get_data()\n\u001b[1;32m   1421\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1422\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1251\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1239\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1249\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1251\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_queue\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m   1252\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1254\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1255\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1256\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout):\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/multiprocessing/connection.py:440\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 440\u001b[0m     r \u001b[38;5;241m=\u001b[39m wait([\u001b[38;5;28mself\u001b[39m], timeout)\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/multiprocessing/connection.py:1136\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1136\u001b[0m     ready \u001b[38;5;241m=\u001b[39m selector\u001b[38;5;241m.\u001b[39mselect(timeout)\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector\u001b[38;5;241m.\u001b[39mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Instantiate Model 1, define loss function and optimizer\n",
    "model1 = Model1().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer1 = optim.Adam(model1.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Training Model 1 (One-Layer, No Regularization)\")\n",
    "losses1 = train_model(model1, train_loader, criterion, optimizer1, device, epochs=5)\n",
    "\n",
    "# Evaluate Model 1 on test data\n",
    "cm1, report1 = evaluate_model(model1, test_loader, device)\n",
    "print(\"Classification Report for Model 1:\")\n",
    "print(report1)\n",
    "\n",
    "# Plot confusion matrix for Model 1\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm1, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix for Model 1')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Model 2, define its optimizer\n",
    "model2 = Model2().to(device)\n",
    "optimizer2 = optim.Adam(model2.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Training Model 2 (Two-Layer, No Regularization)\")\n",
    "losses2 = train_model(model2, train_loader, criterion, optimizer2, device, epochs=5)\n",
    "\n",
    "# Evaluate Model 2 on test data\n",
    "cm2, report2 = evaluate_model(model2, test_loader, device)\n",
    "print(\"Classification Report for Model 2:\")\n",
    "print(report2)\n",
    "\n",
    "# Plot confusion matrix for Model 2\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm2, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix for Model 2')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Model 3, define its optimizer\n",
    "model3 = Model3().to(device)\n",
    "optimizer3 = optim.Adam(model3.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Training Model 3 (Two Hidden Layers with Batch Norm and Dropout)\")\n",
    "losses3 = train_model(model3, train_loader, criterion, optimizer3, device, epochs=5)\n",
    "\n",
    "# Evaluate Model 3 on test data\n",
    "cm3, report3 = evaluate_model(model3, test_loader, device)\n",
    "print(\"Classification Report for Model 3:\")\n",
    "print(report3)\n",
    "\n",
    "# Plot confusion matrix for Model 3\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm3, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix for Model 3')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(losses1, label='Model 1: 1 Layer')\n",
    "plt.plot(losses2, label='Model 2: 2 Layers')\n",
    "plt.plot(losses3, label='Model 3: 2 Hidden Layers with Reg.')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss per Epoch for Different Models')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metrics(report):\n",
    "    return {\n",
    "        \"Accuracy\": report['accuracy'],\n",
    "        \"Macro Precision\": report['macro avg']['precision'],\n",
    "        \"Macro Recall\": report['macro avg']['recall'],\n",
    "        \"Macro F1-Score\": report['macro avg']['f1-score'],\n",
    "        \"Weighted Precision\": report['weighted avg']['precision'],\n",
    "        \"Weighted Recall\": report['weighted avg']['recall'],\n",
    "        \"Weighted F1-Score\": report['weighted avg']['f1-score']\n",
    "    }\n",
    "\n",
    "metrics1 = extract_metrics(report1)\n",
    "metrics2 = extract_metrics(report2)\n",
    "metrics3 = extract_metrics(report3)\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    \"Model 1\": metrics1,\n",
    "    \"Model 2\": metrics2,\n",
    "    \"Model 3\": metrics3\n",
    "})\n",
    "metrics_df = metrics_df.T  # Transpose for easier reading\n",
    "print(\"Evaluation Metrics Summary:\")\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_misclassified(model1, test_loader, device, n=36, title=\"Misclassified Examples - Model 1\")\n",
    "plot_misclassified(model2, test_loader, device, n=36, title=\"Misclassified Examples - Model 2\")\n",
    "plot_misclassified(model3, test_loader, device, n=36, title=\"Misclassified Examples - Model 3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
