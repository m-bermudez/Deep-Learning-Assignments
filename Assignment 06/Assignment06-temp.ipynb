{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import wandb\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import requests_cache\n",
    "import openmeteo_requests\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from retry_requests import retry\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# set repeatability\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)     # Set a random seed for CUDA operations.\n",
    "    torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
    "    \n",
    "    # Ensure deterministic behavior for CUDA operations (note: If you are not concerned with reportable reproducibility, set deterministic to false, and benchmark to true - as it can choose faster algorithms).\n",
    "    torch.backends.cudnn.deterministic = True  # Set cuDNN to deterministic mode - it will now only select algorithms that are known to be deterministic.\n",
    "    torch.backends.cudnn.benchmark = False  # Disable cuDNN benchmarking - it may select the best algorithms for the hardware, but it doesn't guarantee deterministic results.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Open-Meteo API client with cache and retry\n",
    "def fetch_weather_data():\n",
    "    cache_session = requests_cache.CachedSession('.cache', expire_after=-1)\n",
    "    retry_session = retry(cache_session, retries=5, backoff_factor=0.2)\n",
    "    openmeteo = openmeteo_requests.Client(session=retry_session)\n",
    "\n",
    "    # Fetch weather data\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    params = {\n",
    "        \"latitude\": 27.9475,\n",
    "        \"longitude\": -82.4584,\n",
    "        \"start_date\": \"1990-03-14\",\n",
    "        \"end_date\": \"2025-03-28\",\n",
    "        \"hourly\": [\n",
    "            \"temperature_2m\", \"precipitation\", \"pressure_msl\",\n",
    "            \"surface_pressure\", \"relative_humidity_2m\", \"wind_speed_10m\"\n",
    "        ]\n",
    "    }\n",
    "    responses = openmeteo.weather_api(url, params=params)\n",
    "    response = responses[0]  # Process first location\n",
    "\n",
    "    # Extract hourly weather data\n",
    "    hourly = response.Hourly()\n",
    "    hourly_data = {\n",
    "        \"date\": pd.date_range(\n",
    "            start=pd.to_datetime(hourly.Time(), unit=\"s\", utc=True),\n",
    "            end=pd.to_datetime(hourly.TimeEnd(), unit=\"s\", utc=True),\n",
    "            freq=pd.Timedelta(seconds=hourly.Interval()),\n",
    "            inclusive=\"left\"\n",
    "        ),\n",
    "        \"temperature\": hourly.Variables(0).ValuesAsNumpy(),\n",
    "        \"humidity\": hourly.Variables(4).ValuesAsNumpy(),\n",
    "        \"wind_speed\": hourly.Variables(5).ValuesAsNumpy(),\n",
    "        \"precipitation\": hourly.Variables(1).ValuesAsNumpy(),\n",
    "        \"pressure_msl\": hourly.Variables(2).ValuesAsNumpy(),\n",
    "        \"surface_pressure\": hourly.Variables(3).ValuesAsNumpy(),\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(data=hourly_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_split(df, train_ratio=0.7, val_ratio=0.15):\n",
    "    \"\"\"Splits the data into train, validation, and test sets.\"\"\"\n",
    "    n = len(df)\n",
    "    train_end = int(n * train_ratio)\n",
    "    val_end = train_end + int(n * val_ratio)\n",
    "\n",
    "    train_data = df.iloc[:train_end]\n",
    "    val_data = df.iloc[train_end:val_end]\n",
    "    test_data = df.iloc[val_end:]\n",
    "\n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data,seq_len):\n",
    "        sequences, targets = [], []\n",
    "        for i in range(len(data) - seq_len):\n",
    "            sequences.append(data.iloc[i:i+seq_len].values)\n",
    "            targets.append(data.iloc[i+seq_len][\"temperature\"])  # Predict temperature\n",
    "        return np.array(sequences), np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df, seq_len=4):\n",
    "    \"\"\"Processes data for training.\"\"\"\n",
    "    df = df.drop(columns=[\"date\"])\n",
    "    print(df.head)\n",
    "    # Split data\n",
    "    train_data, val_data, test_data = time_series_split(df)\n",
    "\n",
    "    # Normalize each split separately using training set statistics\n",
    "    scaler = MinMaxScaler()\n",
    "    train_data = pd.DataFrame(scaler.fit_transform(train_data), columns=df.columns, index=train_data.index)\n",
    "    val_data = pd.DataFrame(scaler.transform(val_data), columns=df.columns, index=val_data.index)\n",
    "    test_data = pd.DataFrame(scaler.transform(test_data), columns=df.columns, index=test_data.index)\n",
    "\n",
    "\n",
    "    X_train, y_train = create_sequences(train_data, seq_len)\n",
    "    X_val, y_val = create_sequences(val_data,seq_len)\n",
    "    X_test, y_test = create_sequences(test_data,seq_len)\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_api_key = \"dc94a6f2fb35e68dd0ce5b185a38960232124958\"\n",
    "if wandb_api_key:\n",
    "    wandb.login(key=wandb_api_key)\n",
    "else:\n",
    "    raise ValueError(\"WANDB_API_KEY environment variable not set!\")\n",
    "\n",
    "# Load the API key from the environment variable\n",
    "wandb.init(project=\"Assignment6\", entity=\"usf-magma\", config={\n",
    "    \"learning_rate\": 0.0002,\n",
    "    \"dropout\": 0.4,\n",
    "    \"batch_size\": 64,\n",
    "    \"epochs\": 10,\n",
    "    \"momentum\": (0.9, 0.92),\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"criterion\": \"MSE\",  # Changed to MAE\n",
    "    \"input_size\": 1,\n",
    "    \"hidden_size\": 64\n",
    "})\n",
    "\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloader(X, y, batch_size):\n",
    "    \"\"\"Create a DataLoader from given features and targets.\"\"\"\n",
    "    dataset = TensorDataset(torch.tensor(X, dtype=torch.float32), \n",
    "                            torch.tensor(y, dtype=torch.float32).unsqueeze(1))\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, save_dir, device):\n",
    "    \"\"\"Train the model, log metrics, and save the best model based on validation loss.\"\"\"\n",
    "\n",
    "    model.to(device)  # Move model to device (CPU/GPU)\n",
    "    train_losses, val_losses = [], []\n",
    "    train_mae, val_mae = [], []\n",
    "    best_loss = float(\"inf\")  # Track best validation loss\n",
    "    best_mae = float(\"inf\")   # Track lowest validation MAE\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss, running_mae = 0.0, 0.0\n",
    "\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)  # Move batch to GPU/CPU\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_mae += nn.functional.l1_loss(y_pred, y_batch).item()\n",
    "\n",
    "        train_loss_epoch = running_loss / len(train_loader)\n",
    "        train_mae_epoch = running_mae / len(train_loader)\n",
    "        train_losses.append(train_loss_epoch)\n",
    "        train_mae.append(train_mae_epoch)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss, val_mae_epoch = 0.0, 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_val_batch, y_val_batch in val_loader:\n",
    "                X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)  # Move to GPU/CPU\n",
    "                y_val_pred = model(X_val_batch)\n",
    "                val_loss += criterion(y_val_pred, y_val_batch).item()\n",
    "                val_mae_epoch += nn.functional.l1_loss(y_val_pred, y_val_batch).item()\n",
    "\n",
    "        val_loss_epoch = val_loss / len(val_loader)\n",
    "        val_mae_epoch = val_mae_epoch / len(val_loader)\n",
    "        val_losses.append(val_loss_epoch)\n",
    "        val_mae.append(val_mae_epoch)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} -> Train Loss: {train_loss_epoch:.4f}, Val Loss: {val_loss_epoch:.4f}, Train MAE: {train_mae_epoch:.4f}, Val MAE: {val_mae_epoch:.4f}\")\n",
    "\n",
    "        # Log to wandb\n",
    "        wandb.log({\n",
    "            \"Train Loss\": train_loss_epoch,\n",
    "            \"Validation Loss\": val_loss_epoch,\n",
    "            \"Train MAE\": train_mae_epoch,\n",
    "            \"Validation MAE\": val_mae_epoch\n",
    "        })\n",
    "\n",
    "        # Save the best model based on validation loss\n",
    "        if val_loss_epoch < best_loss:\n",
    "            best_loss = val_loss_epoch\n",
    "            best_mae = val_mae_epoch  # Track best MAE\n",
    "            model_save_path = os.path.join(save_dir, f\"dual_rnn_best_epoch_{epoch+1}.pth\")\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            wandb.save(model_save_path)\n",
    "            print(f\"Model saved: {model_save_path}\")\n",
    "\n",
    "            # Update wandb summary with best values\n",
    "            wandb.run.summary[\"Best Validation Loss\"] = best_loss\n",
    "            wandb.run.summary[\"Best Validation MAE\"] = best_mae\n",
    "\n",
    "    # Plot Train Loss vs Validation Loss\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(train_losses, label=\"Train Loss\")\n",
    "    plt.plot(val_losses, label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Train Loss vs Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Train MAE vs Validation MAE\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(train_mae, label=\"Train MAE\")\n",
    "    plt.plot(val_mae, label=\"Validation MAE\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"MAE\")\n",
    "    plt.title(\"Train MAE vs Validation MAE\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(model, test_loader, scaler, device):\n",
    "    \"\"\"Evaluate the model on the test set and plot Actual vs Prediction.\"\"\"\n",
    "    model.to(device)  # Ensure model is on the correct device\n",
    "    model.eval()\n",
    "\n",
    "    actuals, predictions = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_test_batch, y_test_batch in test_loader:\n",
    "            X_test_batch, y_test_batch = X_test_batch.to(device), y_test_batch.to(device)  # Move to GPU/CPU\n",
    "            y_test_pred = model(X_test_batch)\n",
    "\n",
    "            # Convert tensors to NumPy\n",
    "            y_test_pred_np = y_test_pred.cpu().numpy().reshape(-1, 1)\n",
    "            y_test_actual_np = y_test_batch.cpu().numpy().reshape(-1, 1)\n",
    "\n",
    "            # Apply inverse transform correctly\n",
    "            # Create a matrix with the predicted values in the first column and zeros for others\n",
    "            y_test_pred_full = np.zeros((y_test_pred_np.shape[0], scaler.scale_.shape[0]))  # Match feature dimension\n",
    "            y_test_pred_full[:, 0] = y_test_pred_np.flatten()  # Fill temperature column with predictions\n",
    "\n",
    "            y_test_actual_full = np.zeros((y_test_actual_np.shape[0], scaler.scale_.shape[0]))  # Same for actuals\n",
    "            y_test_actual_full[:, 0] = y_test_actual_np.flatten()  # Fill temperature column with actuals\n",
    "\n",
    "            # Apply inverse transform for both predicted and actual values\n",
    "            y_test_pred_original = scaler.inverse_transform(y_test_pred_full)[:, 0]  # Get only temperature\n",
    "            y_test_actual_original = scaler.inverse_transform(y_test_actual_full)[:, 0]  # Get only temperature\n",
    "\n",
    "            actuals.extend(y_test_actual_original.tolist())\n",
    "            predictions.extend(y_test_pred_original.tolist())\n",
    "\n",
    "    # Compute final MSE\n",
    "    test_mse = mean_squared_error(actuals, predictions)\n",
    "    print(f\"Test MSE: {test_mse:.4f}\")\n",
    "\n",
    "    # Print first 10 actual and predicted values\n",
    "    print(\"First 10 Actual Values: \", actuals[:10])\n",
    "    print(\"First 10 Predicted Values: \", predictions[:10])\n",
    "\n",
    "    # Plot Actual vs Predicted Values\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.scatter(actuals, predictions, alpha=0.5, label=\"Predicted vs Actual\")\n",
    "    plt.plot([min(actuals), max(actuals)], [min(actuals), max(actuals)], color='red', linestyle='--', label=\"Perfect Prediction\")\n",
    "    plt.xlabel(\"Actual Temperature\")\n",
    "    plt.ylabel(\"Predicted Temperature\")\n",
    "    plt.title(\"Actual vs Predicted Temperature\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return test_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiHeadRNN, self).__init__()\n",
    "        self.rnn_temp = nn.RNN(input_size=1, hidden_size=config.hidden_size, num_layers=1, batch_first=True)\n",
    "        self.rnn_hum = nn.RNN(input_size=1, hidden_size=config.hidden_size, num_layers=1, batch_first=True)\n",
    "        self.rnn_wind = nn.RNN(input_size=1, hidden_size=config.hidden_size, num_layers=1, batch_first=True)\n",
    "        self.rnn_precip = nn.RNN(input_size=1, hidden_size=config.hidden_size, num_layers=1, batch_first=True)\n",
    "        self.rnn_pressure_msl = nn.RNN(input_size=1, hidden_size=config.hidden_size, num_layers=1, batch_first=True)\n",
    "        self.rnn_surface_pressure = nn.RNN(input_size=1, hidden_size=config.hidden_size, num_layers=1, batch_first=True)\n",
    "        \n",
    "        self.fc1 = nn.Linear(config.hidden_size * 6, config.hidden_size)\n",
    "        self.fc2 = nn.Linear(config.hidden_size, 1)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_temp = x[:, :, 0].unsqueeze(-1)  # Extract temperature\n",
    "        x_hum = x[:, :, 1].unsqueeze(-1)   # Extract humidity\n",
    "        x_wind = x[:, :, 2].unsqueeze(-1)  # Extract wind speed\n",
    "        x_precip = x[:, :, 3].unsqueeze(-1)  # Extract precipitation\n",
    "        x_pressure_msl = x[:, :, 4].unsqueeze(-1)  # Extract mean sea level pressure\n",
    "        x_surface_pressure = x[:, :, 5].unsqueeze(-1)  # Extract surface pressure\n",
    "        \n",
    "        out_temp, _ = self.rnn_temp(x_temp)\n",
    "        out_hum, _ = self.rnn_hum(x_hum)\n",
    "        out_wind, _ = self.rnn_wind(x_wind)\n",
    "        out_precip, _ = self.rnn_precip(x_precip)\n",
    "        out_pressure_msl, _ = self.rnn_pressure_msl(x_pressure_msl)\n",
    "        out_surface_pressure, _ = self.rnn_surface_pressure(x_surface_pressure)\n",
    "        \n",
    "        last_temp = out_temp[:, -1, :]\n",
    "        last_hum = out_hum[:, -1, :]\n",
    "        last_wind = out_wind[:, -1, :]\n",
    "        last_precip = out_precip[:, -1, :]\n",
    "        last_pressure_msl = out_pressure_msl[:, -1, :]\n",
    "        last_surface_pressure = out_surface_pressure[:, -1, :]\n",
    "        \n",
    "        combined = torch.cat([last_temp, last_hum, last_wind, last_precip, last_pressure_msl, last_surface_pressure], dim=1)\n",
    "        combined_1 = self.dropout(torch.tanh(self.fc1(combined)))\n",
    "        prediction = self.fc2(combined_1)\n",
    "        return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Create a folder for saving models if it doesn't exist\n",
    "    save_dir = \"saved_models\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    data = fetch_weather_data()\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, scaler = process_data(data)\n",
    "    print(X_train.shape, y_train.shape)  # Debe ser (num_samples, SEQ_LEN, 3) y (num_samples,)\n",
    "    print(X_train[:2])  # Muestra las primeras secuencias para verificar estructura\n",
    "    print(y_train[:2])  # Muestra los valores esperados\n",
    "\n",
    "    # Prepare data loaders\n",
    "    train_loader = prepare_dataloader(X_train, y_train, config.batch_size)\n",
    "    val_loader = prepare_dataloader(X_val, y_val, config.batch_size)\n",
    "    test_loader = prepare_dataloader(X_test, y_test, config.batch_size)\n",
    "\n",
    "    # Initialize model, loss function, and optimizer\n",
    "    model = MultiHeadRNN().to(device)  # Move model to correct device\n",
    "    criterion = nn.MSELoss()  # MSE Loss\n",
    "    #criterion = nn.L1Loss()  # MAE Loss\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "\n",
    "    # Train the model\n",
    "    model = train_model(model, train_loader, val_loader, criterion, optimizer, config.epochs, save_dir, device)\n",
    "\n",
    "    # Save final model\n",
    "    final_model_path = os.path.join(save_dir, \"multihead_rnn_final.pth\")\n",
    "    torch.save(model.state_dict(), final_model_path)\n",
    "    wandb.save(final_model_path)\n",
    "    print(f\"âœ… Final model saved: {final_model_path}\")\n",
    "\n",
    "    # Evaluate the model on test data\n",
    "    evaluate_model(model, test_loader, scaler,device)\n",
    "\n",
    "    # Finish wandb logging\n",
    "    wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
