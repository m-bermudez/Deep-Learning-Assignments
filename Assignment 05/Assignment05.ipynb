{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZeySr6ThNrl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import wandb\n",
        "import os\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torch.nn.init as init\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import f1_score\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "\n",
        "# Set device to GPU if available, otherwise CPU.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Set a global seed value\n",
        "seed = 42\n",
        "\n",
        "# For NumPy\n",
        "np.random.seed(seed)\n",
        "\n",
        "# For PyTorch\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
        "    \n",
        "    # Ensure deterministic behavior for CUDA operations.\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VSTEvtwiAER",
        "outputId": "2c4a0c9e-c40e-4f09-d36d-215a299f5ff6"
      },
      "outputs": [],
      "source": [
        "model = models.resnet50(pretrained=True)  # Load pre-trained ResNet-50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "4CYVOQGn0giB",
        "outputId": "6e3392a2-d98e-452d-b073-be3be93efa51"
      },
      "outputs": [],
      "source": [
        "# Initialize Weights & Biases\n",
        "wandb.login(key=\"9ab13478cceef58f66f93a6be9e5f1e7a1f7e3d4\")  \n",
        "wandb.init(project=\"Assignment5\", entity=\"usf-magma\")\n",
        "wandb.run.name = \"bermudezm\"\n",
        "wandb.run.save()\n",
        "config = wandb.config\n",
        "wandb.init(project=\"Assignment5\", entity=\"usf-magma\")\n",
        "\n",
        "# Define paths to your local dataset\n",
        "annotations_path = \"Assignment 05/archive/annotations\"  # Update this to your local annotations path\n",
        "images_path = \"Assignment 05/archive/images\"            # Update this to your local images path\n",
        "\n",
        "# Check if the annotation path exists\n",
        "if not os.path.exists(annotations_path):\n",
        "    print(f\"Error: The annotations path {annotations_path} does not exist!\")\n",
        "\n",
        "# Print contents of the annotations folder\n",
        "print(\"Folders in annotations path:\", os.listdir(annotations_path))\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Get class labels\n",
        "def get_class_labels(annotations_path):\n",
        "    class_labels = {}\n",
        "    for breed_folder in os.listdir(annotations_path):\n",
        "        folder_path = os.path.join(annotations_path, breed_folder)\n",
        "        if os.path.isdir(folder_path):\n",
        "            if breed_folder not in class_labels:\n",
        "                class_labels[breed_folder] = len(class_labels)\n",
        "    return class_labels\n",
        "\n",
        "class_labels = get_class_labels(annotations_path)\n",
        "\n",
        "# Load Stanford Dogs dataset\n",
        "def load_stanford_dogs(images_path, annotations_path, transform):\n",
        "    dataset = []\n",
        "    for breed_folder in os.listdir(annotations_path):\n",
        "        annotation_folder_path = os.path.join(annotations_path, breed_folder)\n",
        "        image_folder_path = os.path.join(images_path, breed_folder)\n",
        "\n",
        "        if not os.path.isdir(annotation_folder_path) or not os.path.exists(image_folder_path):\n",
        "            print(f\"Skipping {breed_folder}, image folder not found!\")\n",
        "            continue\n",
        "\n",
        "        class_index = class_labels.get(breed_folder, -1)\n",
        "        if class_index == -1:\n",
        "            continue\n",
        "\n",
        "        image_files = os.listdir(image_folder_path)\n",
        "\n",
        "        for image_file in image_files:\n",
        "            image_path = os.path.join(image_folder_path, image_file)\n",
        "            if image_file.endswith(\".jpg\") and os.path.exists(image_path):\n",
        "                image = Image.open(image_path).convert(\"RGB\")\n",
        "                image = transform(image)\n",
        "                dataset.append((image, class_index))\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# Load datasets\n",
        "full_dataset = load_stanford_dogs(images_path, annotations_path, transform)\n",
        "\n",
        "# Create data loaders\n",
        "trainset, testset = train_test_split(full_dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Train set size: {len(trainset)} images\")\n",
        "print(f\"Test set size: {len(testset)} images\")\n",
        "\n",
        "# Validate dataset size before passing to DataLoader\n",
        "if len(trainset) == 0:\n",
        "    raise ValueError(\"Error: trainset is empty! Check image paths.\")\n",
        "\n",
        "# Create data loaders\n",
        "trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "testloader = DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"Loaded Stanford Dogs dataset with {len(class_labels)} classes and {len(trainset)} images.\")\n",
        "\n",
        "# Log dataset information to W&B\n",
        "wandb.config.update({\n",
        "    \"dataset\": \"Stanford Dogs\",\n",
        "    \"num_classes\": len(class_labels),\n",
        "    \"train_size\": len(trainset),\n",
        "    \"test_size\": len(testset),\n",
        "    \"batch_size\": 32\n",
        "})\n",
        "\n",
        "print(f\"Loaded Stanford Dogs dataset with {len(class_labels)} classes and {len(trainset)} images.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kr3fUvR3A2RD",
        "outputId": "3ca7272c-bf18-435f-8b8a-6755cf3ba2d5"
      },
      "outputs": [],
      "source": [
        "# Define the path to your dataset\n",
        "dataset_path = \"Assignment 05/archive/images/Images\"  # Images directory\n",
        "\n",
        "# Extract class names from folder names\n",
        "classes = tuple(sorted(os.listdir(dataset_path)))  # Sorting to ensure consistent order\n",
        "\n",
        "print(f\"Detected {len(classes)} classes:\")\n",
        "print(classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yx0b4h36AJm7"
      },
      "outputs": [],
      "source": [
        "# Load pre-trained ResNet-18\n",
        "model = models.resnet18(weights='IMAGENET1K_V1')\n",
        "\n",
        "# Modify the final layer to match the number of dog breeds (120)\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, len(classes))  # 120 classes in Stanford Dogs\n",
        "\n",
        "# Move model to the device (GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Log model details to W&B\n",
        "wandb.config.update({\n",
        "    \"model\": \"ResNet-18\",\n",
        "    \"pretrained\": True,\n",
        "    \"num_classes\": len(classes),\n",
        "    \"learning_rate\": 0.001\n",
        "})\n",
        "\n",
        "wandb.watch(model, log=\"all\", log_freq=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cZa6YsKAJp1",
        "outputId": "c5b117fa-02e6-4b00-afb4-6cf5a499d544"
      },
      "outputs": [],
      "source": [
        "# Freeze all layers except the final layer\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze parameters of the final fully connected layer\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Count the number of trainable parameters\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Trainable parameters: {trainable_params:,} ({trainable_params/total_params:.2%} of total)\")\n",
        "\n",
        "# Log to W&B\n",
        "wandb.config.update({\n",
        "    \"trainable_params\": trainable_params,\n",
        "    \"total_params\": total_params,\n",
        "    \"approach\": \"feature_extraction\"\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KN9_HHIBqg5-",
        "outputId": "cc9265db-4cc9-4e53-9d5c-5c05668bcf65"
      },
      "outputs": [],
      "source": [
        "# First, add scikit-learn for metrics calculation\n",
        "\n",
        "\n",
        "# Ensure the model is on the correct device\n",
        "model = model.to(device)\n",
        "\n",
        "# Set up loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
        "\n",
        "wandb.init(project=\"Assignment5\", entity=\"usf-magma\")\n",
        "# Log hyperparameters to W&B\n",
        "wandb.config.update({\n",
        "    \"optimizer\": \"Adam\",\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"criterion\": \"CrossEntropyLoss\",\n",
        "    \"epochs\": 5  # We'll train for just 5 epochs for this example\n",
        "})\n",
        "\n",
        "# Number of classes\n",
        "num_classes = len(class_labels)\n",
        "class_names = list(class_labels.keys())\n",
        "\n",
        "# Training loop\n",
        "def train_model(model, trainloader, testloader, criterion, optimizer, num_epochs=5):\n",
        "    # Track best accuracy\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        all_train_preds = []\n",
        "        all_train_labels = []\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "            # Collect predictions and labels for F1 calculation\n",
        "            all_train_preds.extend(predicted.cpu().numpy())\n",
        "            all_train_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            # Log batch statistics (every 100 batches)\n",
        "            if i % 100 == 99:\n",
        "                batch_acc = 100. * correct / total\n",
        "                batch_loss = running_loss / total\n",
        "                print(f'Batch {i+1}, Loss: {batch_loss:.4f}, Acc: {batch_acc:.2f}%')\n",
        "\n",
        "                wandb.log({\n",
        "                    \"train_batch_loss\": batch_loss,\n",
        "                    \"train_batch_acc\": batch_acc,\n",
        "                    \"epoch\": epoch + i/len(trainloader)\n",
        "                })\n",
        "\n",
        "        # Calculate epoch statistics\n",
        "        train_loss = running_loss / len(trainloader.dataset)\n",
        "        train_acc = 100. * correct / total\n",
        "\n",
        "        # Calculate F1 score for the training epoch\n",
        "        train_f1_macro = f1_score(all_train_labels, all_train_preds, average='macro')\n",
        "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, F1-macro: {train_f1_macro:.4f}')\n",
        "\n",
        "        # Evaluation phase\n",
        "        model.eval()\n",
        "        test_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        class_correct = list(0. for _ in range(num_classes))\n",
        "        class_total = list(0. for _ in range(num_classes))\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in testloader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Statistics\n",
        "                test_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "                # Per-class accuracy\n",
        "                c = (predicted == labels).squeeze()\n",
        "                for i in range(labels.size(0)):\n",
        "                    label = labels[i].item()\n",
        "                    class_correct[label] += c[i].item()\n",
        "                    class_total[label] += 1\n",
        "\n",
        "                # Store for confusion matrix and F1 calculation\n",
        "                all_preds.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        # Calculate test statistics\n",
        "        test_loss = test_loss / len(testloader.dataset)\n",
        "        test_acc = 100. * correct / total\n",
        "\n",
        "        # Calculate F1 score for test data\n",
        "        test_f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
        "        print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%, F1-macro: {test_f1_macro:.4f}')\n",
        "\n",
        "        # Per-class accuracy\n",
        "        for i in range(num_classes):\n",
        "            class_acc = 100 * class_correct[i] / class_total[i] if class_total[i] > 0 else 0\n",
        "\n",
        "\n",
        "        # Log epoch statistics to W&B\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"train_loss\": train_loss,\n",
        "            \"train_acc\": train_acc,\n",
        "            \"train_f1_macro\": train_f1_macro,\n",
        "            \"test_loss\": test_loss,\n",
        "            \"test_acc\": test_acc,\n",
        "            \"test_f1_macro\": test_f1_macro\n",
        "        })\n",
        "\n",
        "        # Log per-class accuracy\n",
        "        class_acc_dict = {f\"class_acc_{class_names[i]}\": 100 * class_correct[i] / class_total[i]\n",
        "                         if class_total[i] > 0 else 0 for i in range(num_classes)}\n",
        "        wandb.log(class_acc_dict)\n",
        "\n",
        "        # Log confusion matrix\n",
        "        wandb.log({\n",
        "            \"confusion_matrix\": wandb.plot.confusion_matrix(\n",
        "                probs=None,\n",
        "                y_true=all_labels,\n",
        "                preds=all_preds,\n",
        "                class_names=class_names\n",
        "            )\n",
        "        })\n",
        "\n",
        "        # Save model if it's the best so far\n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "            best_f1 = test_f1_macro\n",
        "            torch.save(model.state_dict(), f'resnet18_stanforddogs_epoch_{epoch+1}.pth')\n",
        "            wandb.save(f'resnet18_stanforddogs_epoch_{epoch+1}.pth')\n",
        "\n",
        "            # Log best model metrics to W&B summary\n",
        "            wandb.run.summary[\"best_accuracy\"] = best_acc\n",
        "            wandb.run.summary[\"best_f1_macro\"] = best_f1\n",
        "            wandb.run.summary[\"best_epoch\"] = epoch + 1\n",
        "\n",
        "    print(f'Best test accuracy: {best_acc:.2f}%')\n",
        "    return model\n",
        "\n",
        "# Train the model\n",
        "model = train_model(model, trainloader, testloader, criterion, optimizer)\n",
        "\n",
        "# Finish the W&B run\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yGvek9pUwe9p",
        "outputId": "a14dbd08-3e8f-42c2-a19b-ccbb6fb68fcc"
      },
      "outputs": [],
      "source": [
        "# Ensure the model is on the correct device\n",
        "model = model.to(device)\n",
        "\n",
        "# Set up loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
        "\n",
        "wandb.init(project=\"Assignment5\", entity=\"usf-magma\")\n",
        "# Log hyperparameters to W&B\n",
        "wandb.config.update({\n",
        "    \"optimizer\": \"Adam\",\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"criterion\": \"CrossEntropyLoss\",\n",
        "    \"epochs\": 15  # Updated to 15 epochs\n",
        "})\n",
        "\n",
        "# Number of classes\n",
        "num_classes = len(class_labels)\n",
        "class_names = list(class_labels.keys())\n",
        "\n",
        "# Training loop\n",
        "def train_model(model, trainloader, testloader, criterion, optimizer, num_epochs=15):  # Updated to 15 epochs\n",
        "    # Track best accuracy\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        all_train_preds = []\n",
        "        all_train_labels = []\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "            # Collect predictions and labels for F1 calculation\n",
        "            all_train_preds.extend(predicted.cpu().numpy())\n",
        "            all_train_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            # Log batch statistics (every 100 batches)\n",
        "            if i % 100 == 99:\n",
        "                batch_acc = 100. * correct / total\n",
        "                batch_loss = running_loss / total\n",
        "                print(f'Batch {i+1}, Loss: {batch_loss:.4f}, Acc: {batch_acc:.2f}%')\n",
        "\n",
        "                wandb.log({\n",
        "                    \"train_batch_loss\": batch_loss,\n",
        "                    \"train_batch_acc\": batch_acc,\n",
        "                    \"epoch\": epoch + i/len(trainloader)\n",
        "                })\n",
        "\n",
        "        # Calculate epoch statistics\n",
        "        train_loss = running_loss / len(trainloader.dataset)\n",
        "        train_acc = 100. * correct / total\n",
        "\n",
        "        # Calculate F1 score for the training epoch\n",
        "        train_f1_macro = f1_score(all_train_labels, all_train_preds, average='macro')\n",
        "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, F1-macro: {train_f1_macro:.4f}')\n",
        "\n",
        "        # Evaluation phase\n",
        "        model.eval()\n",
        "        test_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        class_correct = list(0. for _ in range(num_classes))\n",
        "        class_total = list(0. for _ in range(num_classes))\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in testloader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Statistics\n",
        "                test_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "                # Per-class accuracy\n",
        "                c = (predicted == labels).squeeze()\n",
        "                for i in range(labels.size(0)):\n",
        "                    label = labels[i].item()\n",
        "                    class_correct[label] += c[i].item()\n",
        "                    class_total[label] += 1\n",
        "\n",
        "                # Store for confusion matrix and F1 calculation\n",
        "                all_preds.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        # Calculate test statistics\n",
        "        test_loss = test_loss / len(testloader.dataset)\n",
        "        test_acc = 100. * correct / total\n",
        "\n",
        "        # Calculate F1 score for test data\n",
        "        test_f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
        "        print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%, F1-macro: {test_f1_macro:.4f}')\n",
        "\n",
        "        # Per-class accuracy\n",
        "        for i in range(num_classes):\n",
        "            class_acc = 100 * class_correct[i] / class_total[i] if class_total[i] > 0 else 0\n",
        "\n",
        "        # Log epoch statistics to W&B\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"train_loss\": train_loss,\n",
        "            \"train_acc\": train_acc,\n",
        "            \"train_f1_macro\": train_f1_macro,\n",
        "            \"test_loss\": test_loss,\n",
        "            \"test_acc\": test_acc,\n",
        "            \"test_f1_macro\": test_f1_macro\n",
        "        })\n",
        "\n",
        "        # Log per-class accuracy\n",
        "        class_acc_dict = {f\"class_acc_{class_names[i]}\": 100 * class_correct[i] / class_total[i]\n",
        "                         if class_total[i] > 0 else 0 for i in range(num_classes)}\n",
        "        wandb.log(class_acc_dict)\n",
        "\n",
        "        # Log confusion matrix\n",
        "        wandb.log({\n",
        "            \"confusion_matrix\": wandb.plot.confusion_matrix(\n",
        "                probs=None,\n",
        "                y_true=all_labels,\n",
        "                preds=all_preds,\n",
        "                class_names=class_names\n",
        "            )\n",
        "        })\n",
        "\n",
        "        # Save model if it's the best so far\n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "            best_f1 = test_f1_macro\n",
        "            torch.save(model.state_dict(), f'resnet18_stanforddogs_epoch_{epoch+1}.pth')\n",
        "            wandb.save(f'resnet18_stanforddogs_epoch_{epoch+1}.pth')\n",
        "\n",
        "            # Log best model metrics to W&B summary\n",
        "            wandb.run.summary[\"best_accuracy\"] = best_acc\n",
        "            wandb.run.summary[\"best_f1_macro\"] = best_f1\n",
        "            wandb.run.summary[\"best_epoch\"] = epoch + 1\n",
        "\n",
        "    print(f'Best test accuracy: {best_acc:.2f}%')\n",
        "    return model\n",
        "\n",
        "# Train the model\n",
        "model = train_model(model, trainloader, testloader, criterion, optimizer)\n",
        "\n",
        "# Finish the W&B run\n",
        "wandb.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "8_ivH59-sqyU",
        "outputId": "71de375a-5119-4999-fea5-ab6b1855c660"
      },
      "outputs": [],
      "source": [
        "# Data Augmentation\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Ensure the model is on the correct device\n",
        "model = model.to(device)\n",
        "\n",
        "# Set up loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.fc.parameters(), lr=0.005, weight_decay=1e-4)\n",
        "\n",
        "# Learning Rate Scheduler\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
        "\n",
        "# Early Stopping Variables\n",
        "best_loss = float(\"inf\")\n",
        "patience = 5\n",
        "patience_counter = 0\n",
        "wandb.init(project=\"Assignment5\", entity=\"usf-magma\")\n",
        "# Log hyperparameters to W&B\n",
        "wandb.config.update({\n",
        "    \"optimizer\": \"AdamW\",\n",
        "    \"learning_rate\": 0.005,\n",
        "    \"criterion\": \"CrossEntropyLoss\",\n",
        "    \"epochs\": 15  # Increased epochs for better convergence\n",
        "})\n",
        "\n",
        "# Number of classes\n",
        "num_classes = len(class_labels)\n",
        "class_names = list(class_labels.keys())\n",
        "\n",
        "# Training loop\n",
        "def train_model(model, trainloader, testloader, criterion, optimizer, num_epochs=15):\n",
        "    best_acc = 0.0\n",
        "    global best_loss, patience_counter\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        all_train_preds = []\n",
        "        all_train_labels = []\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            all_train_preds.extend(predicted.cpu().numpy())\n",
        "            all_train_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        train_loss = running_loss / len(trainloader.dataset)\n",
        "        train_acc = 100. * correct / total\n",
        "        train_f1_macro = f1_score(all_train_labels, all_train_preds, average='macro')\n",
        "\n",
        "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, F1-macro: {train_f1_macro:.4f}')\n",
        "\n",
        "        # Evaluation phase\n",
        "        model.eval()\n",
        "        test_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        misclassified_samples = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in testloader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                test_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "                all_preds.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "                # Capture misclassified samples\n",
        "                for i in range(len(labels)):\n",
        "                    if predicted[i] != labels[i]:\n",
        "                        misclassified_samples.append((inputs[i].cpu(), labels[i].cpu(), predicted[i].cpu()))\n",
        "\n",
        "        test_loss = test_loss / len(testloader.dataset)\n",
        "        test_acc = 100. * correct / total\n",
        "        test_f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
        "\n",
        "        print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%, F1-macro: {test_f1_macro:.4f}')\n",
        "\n",
        "        # Log statistics to W&B\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"train_loss\": train_loss,\n",
        "            \"train_acc\": train_acc,\n",
        "            \"train_f1_macro\": train_f1_macro,\n",
        "            \"test_loss\": test_loss,\n",
        "            \"test_acc\": test_acc,\n",
        "            \"test_f1_macro\": test_f1_macro\n",
        "        })\n",
        "\n",
        "        # Log misclassified samples\n",
        "        for img, true_label, pred_label in misclassified_samples[:10]:  # Log only first 10\n",
        "            wandb.log({\n",
        "                \"Misclassified Sample\": [wandb.Image(img, caption=f\"True: {class_names[true_label]} | Pred: {class_names[pred_label]}\")]\n",
        "            })\n",
        "\n",
        "        # Update learning rate scheduler\n",
        "        scheduler.step(test_loss)\n",
        "\n",
        "        # Early stopping\n",
        "        if test_loss < best_loss:\n",
        "            best_loss = test_loss\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), f'best_model.pth')\n",
        "            wandb.save('best_model.pth')\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    print(f'Best test accuracy: {best_acc:.2f}%')\n",
        "    return model\n",
        "\n",
        "# Train the model\n",
        "model = train_model(model, trainloader, testloader, criterion, optimizer)\n",
        "\n",
        "# Finish the W&B run\n",
        "wandb.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6n499XXAJtP",
        "outputId": "7300c897-1c17-4d38-cea8-341c244b4744"
      },
      "outputs": [],
      "source": [
        "# Ensure the model is on the correct device\n",
        "model = model.to(device)\n",
        "\n",
        "# Set up loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
        "\n",
        "# Log hyperparameters to W&B\n",
        "wandb.config.update({\n",
        "    \"optimizer\": \"Adam\",\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"criterion\": \"CrossEntropyLoss\",\n",
        "    \"epochs\": 5  # We'll train for just 5 epochs for this example\n",
        "})\n",
        "\n",
        "# Number of classes\n",
        "num_classes = len(class_labels)\n",
        "class_names = list(class_labels.keys())\n",
        "\n",
        "# Training loop\n",
        "def train_model(model, trainloader, criterion, optimizer, num_epochs=5):\n",
        "    # Track best accuracy\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        all_train_preds = []\n",
        "        all_train_labels = []\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "            # Collect predictions and labels for F1 calculation\n",
        "            all_train_preds.extend(predicted.cpu().numpy())\n",
        "            all_train_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            # Log batch statistics (every 100 batches)\n",
        "            if i % 100 == 99:\n",
        "                batch_acc = 100. * correct / total\n",
        "                batch_loss = running_loss / total\n",
        "                print(f'Batch {i+1}, Loss: {batch_loss:.4f}, Acc: {batch_acc:.2f}%')\n",
        "\n",
        "                wandb.log({\n",
        "                    \"train_batch_loss\": batch_loss,\n",
        "                    \"train_batch_acc\": batch_acc,\n",
        "                    \"epoch\": epoch + i/len(trainloader)\n",
        "                })\n",
        "\n",
        "        # Calculate epoch statistics\n",
        "        train_loss = running_loss / len(trainloader.dataset)\n",
        "        train_acc = 100. * correct / total\n",
        "\n",
        "        # Calculate F1 score for the training epoch\n",
        "        train_f1_macro = f1_score(all_train_labels, all_train_preds, average='macro')\n",
        "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, F1-macro: {train_f1_macro:.4f}')\n",
        "\n",
        "        # Evaluation phase\n",
        "        model.eval()\n",
        "        test_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        class_correct = list(0. for _ in range(num_classes))\n",
        "        class_total = list(0. for _ in range(num_classes))\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in testloader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Statistics\n",
        "                test_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "                # Per-class accuracy\n",
        "                c = (predicted == labels).squeeze()\n",
        "                for i in range(labels.size(0)):\n",
        "                    label = labels[i].item()\n",
        "                    class_correct[label] += c[i].item()\n",
        "                    class_total[label] += 1\n",
        "\n",
        "                # Store for confusion matrix and F1 calculation\n",
        "                all_preds.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        # Calculate test statistics\n",
        "        test_loss = test_loss / len(testloader.dataset)\n",
        "        test_acc = 100. * correct / total\n",
        "\n",
        "        # Calculate F1 score for test data\n",
        "        test_f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
        "        print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%, F1-macro: {test_f1_macro:.4f}')\n",
        "\n",
        "        # Per-class accuracy\n",
        "        for i in range(num_classes):\n",
        "            class_acc = 100 * class_correct[i] / class_total[i] if class_total[i] > 0 else 0\n",
        "            print(f'Accuracy of {class_names[i]}: {class_acc:.2f}%')\n",
        "\n",
        "        # Log epoch statistics to W&B\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"train_loss\": train_loss,\n",
        "            \"train_acc\": train_acc,\n",
        "            \"train_f1_macro\": train_f1_macro,\n",
        "            \"test_loss\": test_loss,\n",
        "            \"test_acc\": test_acc,\n",
        "            \"test_f1_macro\": test_f1_macro\n",
        "        })\n",
        "\n",
        "        # Log per-class accuracy\n",
        "        class_acc_dict = {f\"class_acc_{class_names[i]}\": 100 * class_correct[i] / class_total[i]\n",
        "                         if class_total[i] > 0 else 0 for i in range(num_classes)}\n",
        "        wandb.log(class_acc_dict)\n",
        "\n",
        "        # Log confusion matrix\n",
        "        wandb.log({\n",
        "            \"confusion_matrix\": wandb.plot.confusion_matrix(\n",
        "                probs=None,\n",
        "                y_true=all_labels,\n",
        "                preds=all_preds,\n",
        "                class_names=class_names\n",
        "            )\n",
        "        })\n",
        "\n",
        "        # Save model if it's the best so far\n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "            best_f1 = test_f1_macro\n",
        "            torch.save(model.state_dict(), f'resnet18_stanforddogs_epoch_{epoch+1}.pth')\n",
        "            wandb.save(f'resnet18_stanforddogs_epoch_{epoch+1}.pth')\n",
        "\n",
        "            # Log best model metrics to W&B summary\n",
        "            wandb.run.summary[\"best_accuracy\"] = best_acc\n",
        "            wandb.run.summary[\"best_f1_macro\"] = best_f1\n",
        "            wandb.run.summary[\"best_epoch\"] = epoch + 1\n",
        "\n",
        "    print(f'Best test accuracy: {best_acc:.2f}%')\n",
        "    return model\n",
        "\n",
        "# Train the model (without passing testloader)\n",
        "model = train_model(model, trainloader, criterion, optimizer)\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'resnet18_stanforddogs_final.pth')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
