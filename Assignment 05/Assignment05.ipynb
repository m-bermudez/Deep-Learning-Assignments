{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZeySr6ThNrl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader,random_split,Subset\n",
        "from torchvision import datasets, transforms\n",
        "import torchmetrics\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "import wandb\n",
        "import os\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Set device to GPU if available, otherwise CPU.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "# Set a global seed value\n",
        "seed = 42\n",
        "\n",
        "# For NumPy\n",
        "np.random.seed(seed)\n",
        "\n",
        "# For PyTorch\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
        "    \n",
        "    # Ensure deterministic behavior for CUDA operations.\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VSTEvtwiAER",
        "outputId": "2c4a0c9e-c40e-4f09-d36d-215a299f5ff6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 220MB/s]\n"
          ]
        }
      ],
      "source": [
        "model = models.resnet50(pretrained=True)  # Load pre-trained ResNet-50\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "4CYVOQGn0giB",
        "outputId": "6e3392a2-d98e-452d-b073-be3be93efa51"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhridayreddy\u001b[0m (\u001b[33musf-magma\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250316_233113-0bxn3l3s</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/usf-magma/Assignment5/runs/0bxn3l3s' target=\"_blank\">silvery-surf-3</a></strong> to <a href='https://wandb.ai/usf-magma/Assignment5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/usf-magma/Assignment5' target=\"_blank\">https://wandb.ai/usf-magma/Assignment5</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/usf-magma/Assignment5/runs/0bxn3l3s' target=\"_blank\">https://wandb.ai/usf-magma/Assignment5/runs/0bxn3l3s</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train set size: 16464 images\n",
            "Test set size: 4116 images\n",
            "Loaded Stanford Dogs dataset with 120 classes and 16464 images.\n"
          ]
        }
      ],
      "source": [
        "# Initialize Weights & Biases\n",
        "wandb.init(project=\"Assignment5\", entity=\"usf-magma\")\n",
        "\n",
        "# Define paths to your local dataset\n",
        "annotations_path = \"Assignment 05/archive/annotations\"  # Update this to your local annotations path\n",
        "images_path = \"Assignment 05/archive/images\"            # Update this to your local images path\n",
        "\n",
        "# Check if the annotation path exists\n",
        "if not os.path.exists(annotations_path):\n",
        "    print(f\"Error: The annotations path {annotations_path} does not exist!\")\n",
        "\n",
        "# Print contents of the annotations folder\n",
        "print(\"Folders in annotations path:\", os.listdir(annotations_path))\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Get class labels\n",
        "def get_class_labels(annotations_path):\n",
        "    class_labels = {}\n",
        "    for breed_folder in os.listdir(annotations_path):\n",
        "        folder_path = os.path.join(annotations_path, breed_folder)\n",
        "        if os.path.isdir(folder_path):\n",
        "            if breed_folder not in class_labels:\n",
        "                class_labels[breed_folder] = len(class_labels)\n",
        "    return class_labels\n",
        "\n",
        "class_labels = get_class_labels(annotations_path)\n",
        "\n",
        "# Load Stanford Dogs dataset\n",
        "def load_stanford_dogs(images_path, annotations_path, transform):\n",
        "    dataset = []\n",
        "    for breed_folder in os.listdir(annotations_path):\n",
        "        annotation_folder_path = os.path.join(annotations_path, breed_folder)\n",
        "        image_folder_path = os.path.join(images_path, breed_folder)\n",
        "\n",
        "        if not os.path.isdir(annotation_folder_path) or not os.path.exists(image_folder_path):\n",
        "            print(f\"Skipping {breed_folder}, image folder not found!\")\n",
        "            continue\n",
        "\n",
        "        class_index = class_labels.get(breed_folder, -1)\n",
        "        if class_index == -1:\n",
        "            continue\n",
        "\n",
        "        image_files = os.listdir(image_folder_path)\n",
        "\n",
        "        for image_file in image_files:\n",
        "            image_path = os.path.join(image_folder_path, image_file)\n",
        "            if image_file.endswith(\".jpg\") and os.path.exists(image_path):\n",
        "                image = Image.open(image_path).convert(\"RGB\")\n",
        "                image = transform(image)\n",
        "                dataset.append((image, class_index))\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# Load datasets\n",
        "full_dataset = load_stanford_dogs(images_path, annotations_path, transform)\n",
        "\n",
        "# Create data loaders\n",
        "trainset, testset = train_test_split(full_dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Train set size: {len(trainset)} images\")\n",
        "print(f\"Test set size: {len(testset)} images\")\n",
        "\n",
        "# Validate dataset size before passing to DataLoader\n",
        "if len(trainset) == 0:\n",
        "    raise ValueError(\"Error: trainset is empty! Check image paths.\")\n",
        "\n",
        "# Create data loaders\n",
        "trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "testloader = DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"Loaded Stanford Dogs dataset with {len(class_labels)} classes and {len(trainset)} images.\")\n",
        "\n",
        "# Log dataset information to W&B\n",
        "wandb.config.update({\n",
        "    \"dataset\": \"Stanford Dogs\",\n",
        "    \"num_classes\": len(class_labels),\n",
        "    \"train_size\": len(trainset),\n",
        "    \"test_size\": len(testset),\n",
        "    \"batch_size\": 32\n",
        "})\n",
        "\n",
        "print(f\"Loaded Stanford Dogs dataset with {len(class_labels)} classes and {len(trainset)} images.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kr3fUvR3A2RD",
        "outputId": "3ca7272c-bf18-435f-8b8a-6755cf3ba2d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected 120 classes:\n",
            "('n02085620-Chihuahua', 'n02085782-Japanese_spaniel', 'n02085936-Maltese_dog', 'n02086079-Pekinese', 'n02086240-Shih-Tzu', 'n02086646-Blenheim_spaniel', 'n02086910-papillon', 'n02087046-toy_terrier', 'n02087394-Rhodesian_ridgeback', 'n02088094-Afghan_hound', 'n02088238-basset', 'n02088364-beagle', 'n02088466-bloodhound', 'n02088632-bluetick', 'n02089078-black-and-tan_coonhound', 'n02089867-Walker_hound', 'n02089973-English_foxhound', 'n02090379-redbone', 'n02090622-borzoi', 'n02090721-Irish_wolfhound', 'n02091032-Italian_greyhound', 'n02091134-whippet', 'n02091244-Ibizan_hound', 'n02091467-Norwegian_elkhound', 'n02091635-otterhound', 'n02091831-Saluki', 'n02092002-Scottish_deerhound', 'n02092339-Weimaraner', 'n02093256-Staffordshire_bullterrier', 'n02093428-American_Staffordshire_terrier', 'n02093647-Bedlington_terrier', 'n02093754-Border_terrier', 'n02093859-Kerry_blue_terrier', 'n02093991-Irish_terrier', 'n02094114-Norfolk_terrier', 'n02094258-Norwich_terrier', 'n02094433-Yorkshire_terrier', 'n02095314-wire-haired_fox_terrier', 'n02095570-Lakeland_terrier', 'n02095889-Sealyham_terrier', 'n02096051-Airedale', 'n02096177-cairn', 'n02096294-Australian_terrier', 'n02096437-Dandie_Dinmont', 'n02096585-Boston_bull', 'n02097047-miniature_schnauzer', 'n02097130-giant_schnauzer', 'n02097209-standard_schnauzer', 'n02097298-Scotch_terrier', 'n02097474-Tibetan_terrier', 'n02097658-silky_terrier', 'n02098105-soft-coated_wheaten_terrier', 'n02098286-West_Highland_white_terrier', 'n02098413-Lhasa', 'n02099267-flat-coated_retriever', 'n02099429-curly-coated_retriever', 'n02099601-golden_retriever', 'n02099712-Labrador_retriever', 'n02099849-Chesapeake_Bay_retriever', 'n02100236-German_short-haired_pointer', 'n02100583-vizsla', 'n02100735-English_setter', 'n02100877-Irish_setter', 'n02101006-Gordon_setter', 'n02101388-Brittany_spaniel', 'n02101556-clumber', 'n02102040-English_springer', 'n02102177-Welsh_springer_spaniel', 'n02102318-cocker_spaniel', 'n02102480-Sussex_spaniel', 'n02102973-Irish_water_spaniel', 'n02104029-kuvasz', 'n02104365-schipperke', 'n02105056-groenendael', 'n02105162-malinois', 'n02105251-briard', 'n02105412-kelpie', 'n02105505-komondor', 'n02105641-Old_English_sheepdog', 'n02105855-Shetland_sheepdog', 'n02106030-collie', 'n02106166-Border_collie', 'n02106382-Bouvier_des_Flandres', 'n02106550-Rottweiler', 'n02106662-German_shepherd', 'n02107142-Doberman', 'n02107312-miniature_pinscher', 'n02107574-Greater_Swiss_Mountain_dog', 'n02107683-Bernese_mountain_dog', 'n02107908-Appenzeller', 'n02108000-EntleBucher', 'n02108089-boxer', 'n02108422-bull_mastiff', 'n02108551-Tibetan_mastiff', 'n02108915-French_bulldog', 'n02109047-Great_Dane', 'n02109525-Saint_Bernard', 'n02109961-Eskimo_dog', 'n02110063-malamute', 'n02110185-Siberian_husky', 'n02110627-affenpinscher', 'n02110806-basenji', 'n02110958-pug', 'n02111129-Leonberg', 'n02111277-Newfoundland', 'n02111500-Great_Pyrenees', 'n02111889-Samoyed', 'n02112018-Pomeranian', 'n02112137-chow', 'n02112350-keeshond', 'n02112706-Brabancon_griffon', 'n02113023-Pembroke', 'n02113186-Cardigan', 'n02113624-toy_poodle', 'n02113712-miniature_poodle', 'n02113799-standard_poodle', 'n02113978-Mexican_hairless', 'n02115641-dingo', 'n02115913-dhole', 'n02116738-African_hunting_dog')\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Define the path to your dataset\n",
        "dataset_path = \"/content/drive/MyDrive/StanfordDogs/images/Images\"  # Images directory\n",
        "\n",
        "# Extract class names from folder names\n",
        "classes = tuple(sorted(os.listdir(dataset_path)))  # Sorting to ensure consistent order\n",
        "\n",
        "print(f\"Detected {len(classes)} classes:\")\n",
        "print(classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yx0b4h36AJm7"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "\n",
        "# Load pre-trained ResNet-18\n",
        "model = models.resnet18(weights='IMAGENET1K_V1')\n",
        "\n",
        "# Modify the final layer to match the number of dog breeds (120)\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, len(classes))  # 120 classes in Stanford Dogs\n",
        "\n",
        "# Move model to the device (GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Log model details to W&B\n",
        "wandb.config.update({\n",
        "    \"model\": \"ResNet-18\",\n",
        "    \"pretrained\": True,\n",
        "    \"num_classes\": len(classes),\n",
        "    \"learning_rate\": 0.001\n",
        "})\n",
        "\n",
        "wandb.watch(model, log=\"all\", log_freq=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cZa6YsKAJp1",
        "outputId": "c5b117fa-02e6-4b00-afb4-6cf5a499d544"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trainable parameters: 61,560 (0.55% of total)\n"
          ]
        }
      ],
      "source": [
        "# Freeze all layers except the final layer\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze parameters of the final fully connected layer\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Count the number of trainable parameters\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Trainable parameters: {trainable_params:,} ({trainable_params/total_params:.2%} of total)\")\n",
        "\n",
        "# Log to W&B\n",
        "wandb.config.update({\n",
        "    \"trainable_params\": trainable_params,\n",
        "    \"total_params\": total_params,\n",
        "    \"approach\": \"feature_extraction\"\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KN9_HHIBqg5-",
        "outputId": "cc9265db-4cc9-4e53-9d5c-5c05668bcf65"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250317_013818-2clcbqxi</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/usf-magma/Assignment5/runs/2clcbqxi' target=\"_blank\">generous-monkey-6</a></strong> to <a href='https://wandb.ai/usf-magma/Assignment5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/usf-magma/Assignment5' target=\"_blank\">https://wandb.ai/usf-magma/Assignment5</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/usf-magma/Assignment5/runs/2clcbqxi' target=\"_blank\">https://wandb.ai/usf-magma/Assignment5/runs/2clcbqxi</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "----------\n",
            "Batch 100, Loss: 0.2336, Acc: 92.75%\n",
            "Batch 200, Loss: 0.2375, Acc: 92.48%\n",
            "Batch 300, Loss: 0.2389, Acc: 92.30%\n",
            "Batch 400, Loss: 0.2485, Acc: 92.09%\n",
            "Batch 500, Loss: 0.2540, Acc: 91.83%\n",
            "Train Loss: 0.2540, Train Acc: 91.81%, F1-macro: 0.9180\n",
            "Test Loss: 1.1766, Test Acc: 71.43%, F1-macro: 0.7068\n",
            "Epoch 2/5\n",
            "----------\n",
            "Batch 100, Loss: 0.2255, Acc: 92.47%\n",
            "Batch 200, Loss: 0.2324, Acc: 92.22%\n",
            "Batch 300, Loss: 0.2420, Acc: 91.93%\n",
            "Batch 400, Loss: 0.2443, Acc: 91.81%\n",
            "Batch 500, Loss: 0.2467, Acc: 91.76%\n",
            "Train Loss: 0.2474, Train Acc: 91.69%, F1-macro: 0.9162\n",
            "Test Loss: 1.1433, Test Acc: 70.94%, F1-macro: 0.7071\n",
            "Epoch 3/5\n",
            "----------\n",
            "Batch 100, Loss: 0.2202, Acc: 93.16%\n",
            "Batch 200, Loss: 0.2247, Acc: 92.92%\n",
            "Batch 300, Loss: 0.2282, Acc: 92.77%\n",
            "Batch 400, Loss: 0.2347, Acc: 92.57%\n",
            "Batch 500, Loss: 0.2377, Acc: 92.35%\n",
            "Train Loss: 0.2387, Train Acc: 92.31%, F1-macro: 0.9232\n",
            "Test Loss: 1.1837, Test Acc: 70.99%, F1-macro: 0.7045\n",
            "Epoch 4/5\n",
            "----------\n",
            "Batch 100, Loss: 0.2198, Acc: 92.81%\n",
            "Batch 200, Loss: 0.2200, Acc: 93.00%\n",
            "Batch 300, Loss: 0.2204, Acc: 92.94%\n",
            "Batch 400, Loss: 0.2235, Acc: 92.84%\n",
            "Batch 500, Loss: 0.2288, Acc: 92.64%\n",
            "Train Loss: 0.2286, Train Acc: 92.63%, F1-macro: 0.9263\n",
            "Test Loss: 1.1798, Test Acc: 71.60%, F1-macro: 0.7101\n",
            "Epoch 5/5\n",
            "----------\n",
            "Batch 100, Loss: 0.1940, Acc: 94.34%\n",
            "Batch 200, Loss: 0.2121, Acc: 93.67%\n",
            "Batch 300, Loss: 0.2153, Acc: 93.30%\n",
            "Batch 400, Loss: 0.2246, Acc: 92.88%\n",
            "Batch 500, Loss: 0.2266, Acc: 92.85%\n",
            "Train Loss: 0.2266, Train Acc: 92.84%, F1-macro: 0.9284\n",
            "Test Loss: 1.1911, Test Acc: 70.97%, F1-macro: 0.7039\n",
            "Best test accuracy: 71.60%\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>class_acc_n02085620-Chihuahua</td><td>█▁▆▃▅</td></tr><tr><td>class_acc_n02085782-Japanese_spaniel</td><td>▁▅█▆▅</td></tr><tr><td>class_acc_n02085936-Maltese_dog</td><td>▄▄▁█▂</td></tr><tr><td>class_acc_n02086079-Pekinese</td><td>▅█▁▁▅</td></tr><tr><td>class_acc_n02086240-Shih-Tzu</td><td>▆▇█▆▁</td></tr><tr><td>class_acc_n02086646-Blenheim_spaniel</td><td>▃▃▁▆█</td></tr><tr><td>class_acc_n02086910-papillon</td><td>▅▅▁▆█</td></tr><tr><td>class_acc_n02087046-toy_terrier</td><td>▆██▆▁</td></tr><tr><td>class_acc_n02087394-Rhodesian_ridgeback</td><td>▁▆▆▅█</td></tr><tr><td>class_acc_n02088094-Afghan_hound</td><td>▇▁▂█▇</td></tr><tr><td>class_acc_n02088238-basset</td><td>▁█▅█▂</td></tr><tr><td>class_acc_n02088364-beagle</td><td>█▁▇▂▄</td></tr><tr><td>class_acc_n02088466-bloodhound</td><td>▆█▂▆▁</td></tr><tr><td>class_acc_n02088632-bluetick</td><td>█▆▆▁█</td></tr><tr><td>class_acc_n02089078-black-and-tan_coonhound</td><td>▁██▆█</td></tr><tr><td>class_acc_n02089867-Walker_hound</td><td>▁▆▃▅█</td></tr><tr><td>class_acc_n02089973-English_foxhound</td><td>▅▃▁█▃</td></tr><tr><td>class_acc_n02090379-redbone</td><td>▇▆▁█▂</td></tr><tr><td>class_acc_n02090622-borzoi</td><td>▃▃█▅▁</td></tr><tr><td>class_acc_n02090721-Irish_wolfhound</td><td>▅▁▂█▅</td></tr><tr><td>class_acc_n02091032-Italian_greyhound</td><td>██▃█▁</td></tr><tr><td>class_acc_n02091134-whippet</td><td>▇▁█▆▇</td></tr><tr><td>class_acc_n02091244-Ibizan_hound</td><td>▃▁█▁▃</td></tr><tr><td>class_acc_n02091467-Norwegian_elkhound</td><td>▁▁▁██</td></tr><tr><td>class_acc_n02091635-otterhound</td><td>█▁▄▄▁</td></tr><tr><td>class_acc_n02091831-Saluki</td><td>▆▆█▁█</td></tr><tr><td>class_acc_n02092002-Scottish_deerhound</td><td>██▆▁▆</td></tr><tr><td>class_acc_n02092339-Weimaraner</td><td>▁▁███</td></tr><tr><td>class_acc_n02093256-Staffordshire_bullterrier</td><td>█▁█▃▃</td></tr><tr><td>class_acc_n02093428-American_Staffordshire_terrier</td><td>▁█▃▅▆</td></tr><tr><td>class_acc_n02093647-Bedlington_terrier</td><td>█▆▁▅▆</td></tr><tr><td>class_acc_n02093754-Border_terrier</td><td>█▅▁██</td></tr><tr><td>class_acc_n02093859-Kerry_blue_terrier</td><td>▃▃▁▅█</td></tr><tr><td>class_acc_n02093991-Irish_terrier</td><td>▁▃▃█▁</td></tr><tr><td>class_acc_n02094114-Norfolk_terrier</td><td>▁█▆▆▁</td></tr><tr><td>class_acc_n02094258-Norwich_terrier</td><td>▅▅▅▁█</td></tr><tr><td>class_acc_n02094433-Yorkshire_terrier</td><td>▆▇▇█▁</td></tr><tr><td>class_acc_n02095314-wire-haired_fox_terrier</td><td>█▇█▁█</td></tr><tr><td>class_acc_n02095570-Lakeland_terrier</td><td>▅▅▁█▄</td></tr><tr><td>class_acc_n02095889-Sealyham_terrier</td><td>█▂▅▁▇</td></tr><tr><td>class_acc_n02096051-Airedale</td><td>▆▆█▁▃</td></tr><tr><td>class_acc_n02096177-cairn</td><td>█▁▃█▃</td></tr><tr><td>class_acc_n02096294-Australian_terrier</td><td>▆▁▅█▆</td></tr><tr><td>class_acc_n02096437-Dandie_Dinmont</td><td>▅█▅▁▇</td></tr><tr><td>class_acc_n02096585-Boston_bull</td><td>█▂▆▅▁</td></tr><tr><td>class_acc_n02097047-miniature_schnauzer</td><td>█▆▁▄▃</td></tr><tr><td>class_acc_n02097130-giant_schnauzer</td><td>▁▆▆▃█</td></tr><tr><td>class_acc_n02097209-standard_schnauzer</td><td>▁▅█▆▅</td></tr><tr><td>class_acc_n02097298-Scotch_terrier</td><td>█▃▆▇▁</td></tr><tr><td>class_acc_n02097474-Tibetan_terrier</td><td>▆▁▇█▆</td></tr><tr><td>class_acc_n02097658-silky_terrier</td><td>▅▅▁▁█</td></tr><tr><td>class_acc_n02098105-soft-coated_wheaten_terrier</td><td>▃▆█▁▆</td></tr><tr><td>class_acc_n02098286-West_Highland_white_terrier</td><td>▁▃▁█▃</td></tr><tr><td>class_acc_n02098413-Lhasa</td><td>▅▁▂▅█</td></tr><tr><td>class_acc_n02099267-flat-coated_retriever</td><td>██▇▁▁</td></tr><tr><td>class_acc_n02099429-curly-coated_retriever</td><td>▅▃█▆▁</td></tr><tr><td>class_acc_n02099601-golden_retriever</td><td>▅█▁▁▅</td></tr><tr><td>class_acc_n02099712-Labrador_retriever</td><td>▅▃▆█▁</td></tr><tr><td>class_acc_n02099849-Chesapeake_Bay_retriever</td><td>█▁█▁▃</td></tr><tr><td>class_acc_n02100236-German_short-haired_pointer</td><td>▄▃▅█▁</td></tr><tr><td>class_acc_n02100583-vizsla</td><td>▇▄█▆▁</td></tr><tr><td>class_acc_n02100735-English_setter</td><td>▆█▁▁▆</td></tr><tr><td>class_acc_n02100877-Irish_setter</td><td>█▁██▁</td></tr><tr><td>class_acc_n02101006-Gordon_setter</td><td>▁████</td></tr><tr><td>class_acc_n02101388-Brittany_spaniel</td><td>▁▇▅█▄</td></tr><tr><td>class_acc_n02101556-clumber</td><td>███▁▁</td></tr><tr><td>class_acc_n02102040-English_springer</td><td>▆▆▁█▆</td></tr><tr><td>class_acc_n02102177-Welsh_springer_spaniel</td><td>█▄█▁█</td></tr><tr><td>class_acc_n02102318-cocker_spaniel</td><td>▇▁█▃█</td></tr><tr><td>class_acc_n02102480-Sussex_spaniel</td><td>████▁</td></tr><tr><td>class_acc_n02102973-Irish_water_spaniel</td><td>█▄██▁</td></tr><tr><td>class_acc_n02104029-kuvasz</td><td>█▁▇▆▃</td></tr><tr><td>class_acc_n02104365-schipperke</td><td>█▁▇▇▅</td></tr><tr><td>class_acc_n02105056-groenendael</td><td>▃█▁▃▆</td></tr><tr><td>class_acc_n02105162-malinois</td><td>█▆▁▇▅</td></tr><tr><td>class_acc_n02105251-briard</td><td>▅█▁█▅</td></tr><tr><td>class_acc_n02105412-kelpie</td><td>▁▂▇▁█</td></tr><tr><td>class_acc_n02105505-komondor</td><td>▁██▁▁</td></tr><tr><td>class_acc_n02105641-Old_English_sheepdog</td><td>▅█▁▅▇</td></tr><tr><td>class_acc_n02105855-Shetland_sheepdog</td><td>▁▃▇█▅</td></tr><tr><td>class_acc_n02106030-collie</td><td>▆█▇▁▅</td></tr><tr><td>class_acc_n02106166-Border_collie</td><td>█▃▁▄▇</td></tr><tr><td>class_acc_n02106382-Bouvier_des_Flandres</td><td>█▅▅▅▁</td></tr><tr><td>class_acc_n02106550-Rottweiler</td><td>▅▁███</td></tr><tr><td>class_acc_n02106662-German_shepherd</td><td>▁▆█▁▆</td></tr><tr><td>class_acc_n02107142-Doberman</td><td>▇▇██▁</td></tr><tr><td>class_acc_n02107312-miniature_pinscher</td><td>▆▁▁▅█</td></tr><tr><td>class_acc_n02107574-Greater_Swiss_Mountain_dog</td><td>▃▃█▁▁</td></tr><tr><td>class_acc_n02107683-Bernese_mountain_dog</td><td>▅▅▅▁█</td></tr><tr><td>class_acc_n02107908-Appenzeller</td><td>█▃▁▃▁</td></tr><tr><td>class_acc_n02108000-EntleBucher</td><td>▁▆▄█▄</td></tr><tr><td>class_acc_n02108089-boxer</td><td>▅▆▆█▁</td></tr><tr><td>class_acc_n02108422-bull_mastiff</td><td>▆▁▆▁█</td></tr><tr><td>class_acc_n02108551-Tibetan_mastiff</td><td>█▅▅▁▅</td></tr><tr><td>class_acc_n02108915-French_bulldog</td><td>▁▆▃█▅</td></tr><tr><td>class_acc_n02109047-Great_Dane</td><td>▁▁▆█▆</td></tr><tr><td>class_acc_n02109525-Saint_Bernard</td><td>▁▁█▁▁</td></tr><tr><td>class_acc_n02109961-Eskimo_dog</td><td>▁▇█▇▁</td></tr><tr><td>class_acc_n02110063-malamute</td><td>█▁▄▇▄</td></tr><tr><td>class_acc_n02110185-Siberian_husky</td><td>▄▃▂▁█</td></tr><tr><td>class_acc_n02110627-affenpinscher</td><td>▁▁██▁</td></tr><tr><td>class_acc_n02110806-basenji</td><td>▁▃▁▇█</td></tr><tr><td>class_acc_n02110958-pug</td><td>▁▅█▇▇</td></tr><tr><td>class_acc_n02111129-Leonberg</td><td>█▁█▅▁</td></tr><tr><td>class_acc_n02111277-Newfoundland</td><td>█▅▁▅█</td></tr><tr><td>class_acc_n02111500-Great_Pyrenees</td><td>▁█▁▄▄</td></tr><tr><td>class_acc_n02111889-Samoyed</td><td>█▁▃▆▆</td></tr><tr><td>class_acc_n02112018-Pomeranian</td><td>▇▄▅▁█</td></tr><tr><td>class_acc_n02112137-chow</td><td>█▄▁▁▄</td></tr><tr><td>class_acc_n02112350-keeshond</td><td>▁▃▁▁█</td></tr><tr><td>class_acc_n02112706-Brabancon_griffon</td><td>█▁██▁</td></tr><tr><td>class_acc_n02113023-Pembroke</td><td>█▁▁▅▅</td></tr><tr><td>class_acc_n02113186-Cardigan</td><td>██▁█▃</td></tr><tr><td>class_acc_n02113624-toy_poodle</td><td>▄▂█▁▂</td></tr><tr><td>class_acc_n02113712-miniature_poodle</td><td>▇█▁▃▅</td></tr><tr><td>class_acc_n02113799-standard_poodle</td><td>▆▃█▆▁</td></tr><tr><td>class_acc_n02113978-Mexican_hairless</td><td>▁▁█▁▁</td></tr><tr><td>class_acc_n02115641-dingo</td><td>▄▄█▄▁</td></tr><tr><td>class_acc_n02115913-dhole</td><td>██▁▁█</td></tr><tr><td>class_acc_n02116738-African_hunting_dog</td><td>▁▃▆▃█</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>test_acc</td><td>▆▁▂█▁</td></tr><tr><td>test_f1_macro</td><td>▄▅▂█▁</td></tr><tr><td>test_loss</td><td>▆▁▇▆█</td></tr><tr><td>train_acc</td><td>▂▁▅▇█</td></tr><tr><td>train_batch_acc</td><td>▄▃▂▂▁▃▂▁▁▁▅▄▄▃▃▄▄▄▄▃█▆▅▄▄</td></tr><tr><td>train_batch_loss</td><td>▆▆▆▇█▅▅▇▇▇▄▅▅▆▆▄▄▄▄▅▁▃▃▅▅</td></tr><tr><td>train_f1_macro</td><td>▂▁▅▇█</td></tr><tr><td>train_loss</td><td>█▆▄▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_accuracy</td><td>71.59864</td></tr><tr><td>best_epoch</td><td>4</td></tr><tr><td>best_f1_macro</td><td>0.71012</td></tr><tr><td>class_acc_n02085620-Chihuahua</td><td>51.6129</td></tr><tr><td>class_acc_n02085782-Japanese_spaniel</td><td>85.71429</td></tr><tr><td>class_acc_n02085936-Maltese_dog</td><td>57.44681</td></tr><tr><td>class_acc_n02086079-Pekinese</td><td>72.5</td></tr><tr><td>class_acc_n02086240-Shih-Tzu</td><td>51.28205</td></tr><tr><td>class_acc_n02086646-Blenheim_spaniel</td><td>95.12195</td></tr><tr><td>class_acc_n02086910-papillon</td><td>89.3617</td></tr><tr><td>class_acc_n02087046-toy_terrier</td><td>60.60606</td></tr><tr><td>class_acc_n02087394-Rhodesian_ridgeback</td><td>79.54545</td></tr><tr><td>class_acc_n02088094-Afghan_hound</td><td>90.38462</td></tr><tr><td>class_acc_n02088238-basset</td><td>64</td></tr><tr><td>class_acc_n02088364-beagle</td><td>57.14286</td></tr><tr><td>class_acc_n02088466-bloodhound</td><td>56.75676</td></tr><tr><td>class_acc_n02088632-bluetick</td><td>66.66667</td></tr><tr><td>class_acc_n02089078-black-and-tan_coonhound</td><td>86.2069</td></tr><tr><td>class_acc_n02089867-Walker_hound</td><td>66.66667</td></tr><tr><td>class_acc_n02089973-English_foxhound</td><td>53.57143</td></tr><tr><td>class_acc_n02090379-redbone</td><td>48.48485</td></tr><tr><td>class_acc_n02090622-borzoi</td><td>70.96774</td></tr><tr><td>class_acc_n02090721-Irish_wolfhound</td><td>69.76744</td></tr><tr><td>class_acc_n02091032-Italian_greyhound</td><td>61.53846</td></tr><tr><td>class_acc_n02091134-whippet</td><td>63.33333</td></tr><tr><td>class_acc_n02091244-Ibizan_hound</td><td>83.33333</td></tr><tr><td>class_acc_n02091467-Norwegian_elkhound</td><td>80.55556</td></tr><tr><td>class_acc_n02091635-otterhound</td><td>58.06452</td></tr><tr><td>class_acc_n02091831-Saluki</td><td>78.78788</td></tr><tr><td>class_acc_n02092002-Scottish_deerhound</td><td>76.59574</td></tr><tr><td>class_acc_n02092339-Weimaraner</td><td>88.88889</td></tr><tr><td>class_acc_n02093256-Staffordshire_bullterrier</td><td>54.83871</td></tr><tr><td>class_acc_n02093428-American_Staffordshire_terrier</td><td>44.73684</td></tr><tr><td>class_acc_n02093647-Bedlington_terrier</td><td>90.69767</td></tr><tr><td>class_acc_n02093754-Border_terrier</td><td>83.33333</td></tr><tr><td>class_acc_n02093859-Kerry_blue_terrier</td><td>64.51613</td></tr><tr><td>class_acc_n02093991-Irish_terrier</td><td>61.53846</td></tr><tr><td>class_acc_n02094114-Norfolk_terrier</td><td>56.41026</td></tr><tr><td>class_acc_n02094258-Norwich_terrier</td><td>83.33333</td></tr><tr><td>class_acc_n02094433-Yorkshire_terrier</td><td>32.5</td></tr><tr><td>class_acc_n02095314-wire-haired_fox_terrier</td><td>69.44444</td></tr><tr><td>class_acc_n02095570-Lakeland_terrier</td><td>55.81395</td></tr><tr><td>class_acc_n02095889-Sealyham_terrier</td><td>87.93103</td></tr><tr><td>class_acc_n02096051-Airedale</td><td>76.92308</td></tr><tr><td>class_acc_n02096177-cairn</td><td>69.23077</td></tr><tr><td>class_acc_n02096294-Australian_terrier</td><td>79.54545</td></tr><tr><td>class_acc_n02096437-Dandie_Dinmont</td><td>84.61538</td></tr><tr><td>class_acc_n02096585-Boston_bull</td><td>60</td></tr><tr><td>class_acc_n02097047-miniature_schnauzer</td><td>53.125</td></tr><tr><td>class_acc_n02097130-giant_schnauzer</td><td>64.28571</td></tr><tr><td>class_acc_n02097209-standard_schnauzer</td><td>55</td></tr><tr><td>class_acc_n02097298-Scotch_terrier</td><td>67.85714</td></tr><tr><td>class_acc_n02097474-Tibetan_terrier</td><td>68.29268</td></tr><tr><td>class_acc_n02097658-silky_terrier</td><td>70.58824</td></tr><tr><td>class_acc_n02098105-soft-coated_wheaten_terrier</td><td>76</td></tr><tr><td>class_acc_n02098286-West_Highland_white_terrier</td><td>74.19355</td></tr><tr><td>class_acc_n02098413-Lhasa</td><td>56.25</td></tr><tr><td>class_acc_n02099267-flat-coated_retriever</td><td>62.5</td></tr><tr><td>class_acc_n02099429-curly-coated_retriever</td><td>71.875</td></tr><tr><td>class_acc_n02099601-golden_retriever</td><td>61.53846</td></tr><tr><td>class_acc_n02099712-Labrador_retriever</td><td>54.7619</td></tr><tr><td>class_acc_n02099849-Chesapeake_Bay_retriever</td><td>72.72727</td></tr><tr><td>class_acc_n02100236-German_short-haired_pointer</td><td>67.5</td></tr><tr><td>class_acc_n02100583-vizsla</td><td>60.52632</td></tr><tr><td>class_acc_n02100735-English_setter</td><td>67.56757</td></tr><tr><td>class_acc_n02100877-Irish_setter</td><td>87.09677</td></tr><tr><td>class_acc_n02101006-Gordon_setter</td><td>87.87879</td></tr><tr><td>class_acc_n02101388-Brittany_spaniel</td><td>60</td></tr><tr><td>class_acc_n02101556-clumber</td><td>82.75862</td></tr><tr><td>class_acc_n02102040-English_springer</td><td>69.56522</td></tr><tr><td>class_acc_n02102177-Welsh_springer_spaniel</td><td>96</td></tr><tr><td>class_acc_n02102318-cocker_spaniel</td><td>62.85714</td></tr><tr><td>class_acc_n02102480-Sussex_spaniel</td><td>74.19355</td></tr><tr><td>class_acc_n02102973-Irish_water_spaniel</td><td>75</td></tr><tr><td>class_acc_n02104029-kuvasz</td><td>55.17241</td></tr><tr><td>class_acc_n02104365-schipperke</td><td>78.94737</td></tr><tr><td>class_acc_n02105056-groenendael</td><td>87.5</td></tr><tr><td>class_acc_n02105162-malinois</td><td>65.625</td></tr><tr><td>class_acc_n02105251-briard</td><td>81.81818</td></tr><tr><td>class_acc_n02105412-kelpie</td><td>81.81818</td></tr><tr><td>class_acc_n02105505-komondor</td><td>87.5</td></tr><tr><td>class_acc_n02105641-Old_English_sheepdog</td><td>84.375</td></tr><tr><td>class_acc_n02105855-Shetland_sheepdog</td><td>76</td></tr><tr><td>class_acc_n02106030-collie</td><td>34.09091</td></tr><tr><td>class_acc_n02106166-Border_collie</td><td>75.86207</td></tr><tr><td>class_acc_n02106382-Bouvier_des_Flandres</td><td>75</td></tr><tr><td>class_acc_n02106550-Rottweiler</td><td>85.18519</td></tr><tr><td>class_acc_n02106662-German_shepherd</td><td>68.75</td></tr><tr><td>class_acc_n02107142-Doberman</td><td>46.42857</td></tr><tr><td>class_acc_n02107312-miniature_pinscher</td><td>81.08108</td></tr><tr><td>class_acc_n02107574-Greater_Swiss_Mountain_dog</td><td>66.66667</td></tr><tr><td>class_acc_n02107683-Bernese_mountain_dog</td><td>92</td></tr><tr><td>class_acc_n02107908-Appenzeller</td><td>62.06897</td></tr><tr><td>class_acc_n02108000-EntleBucher</td><td>74.4186</td></tr><tr><td>class_acc_n02108089-boxer</td><td>45.83333</td></tr><tr><td>class_acc_n02108422-bull_mastiff</td><td>79.31034</td></tr><tr><td>class_acc_n02108551-Tibetan_mastiff</td><td>84.375</td></tr><tr><td>class_acc_n02108915-French_bulldog</td><td>60.97561</td></tr><tr><td>class_acc_n02109047-Great_Dane</td><td>50</td></tr><tr><td>class_acc_n02109525-Saint_Bernard</td><td>84.84848</td></tr><tr><td>class_acc_n02109961-Eskimo_dog</td><td>14.81481</td></tr><tr><td>class_acc_n02110063-malamute</td><td>64.70588</td></tr><tr><td>class_acc_n02110185-Siberian_husky</td><td>63.15789</td></tr><tr><td>class_acc_n02110627-affenpinscher</td><td>64.86486</td></tr><tr><td>class_acc_n02110806-basenji</td><td>82.22222</td></tr><tr><td>class_acc_n02110958-pug</td><td>85</td></tr><tr><td>class_acc_n02111129-Leonberg</td><td>91.17647</td></tr><tr><td>class_acc_n02111277-Newfoundland</td><td>76.92308</td></tr><tr><td>class_acc_n02111500-Great_Pyrenees</td><td>69.56522</td></tr><tr><td>class_acc_n02111889-Samoyed</td><td>83.78378</td></tr><tr><td>class_acc_n02112018-Pomeranian</td><td>86.36364</td></tr><tr><td>class_acc_n02112137-chow</td><td>86.2069</td></tr><tr><td>class_acc_n02112350-keeshond</td><td>97.22222</td></tr><tr><td>class_acc_n02112706-Brabancon_griffon</td><td>88.88889</td></tr><tr><td>class_acc_n02113023-Pembroke</td><td>76.74419</td></tr><tr><td>class_acc_n02113186-Cardigan</td><td>44.11765</td></tr><tr><td>class_acc_n02113624-toy_poodle</td><td>33.33333</td></tr><tr><td>class_acc_n02113712-miniature_poodle</td><td>54.28571</td></tr><tr><td>class_acc_n02113799-standard_poodle</td><td>55</td></tr><tr><td>class_acc_n02113978-Mexican_hairless</td><td>89.28571</td></tr><tr><td>class_acc_n02115641-dingo</td><td>71.42857</td></tr><tr><td>class_acc_n02115913-dhole</td><td>86.66667</td></tr><tr><td>class_acc_n02116738-African_hunting_dog</td><td>97.67442</td></tr><tr><td>epoch</td><td>5</td></tr><tr><td>test_acc</td><td>70.96696</td></tr><tr><td>test_f1_macro</td><td>0.70393</td></tr><tr><td>test_loss</td><td>1.19108</td></tr><tr><td>train_acc</td><td>92.83892</td></tr><tr><td>train_batch_acc</td><td>92.85</td></tr><tr><td>train_batch_loss</td><td>0.2266</td></tr><tr><td>train_f1_macro</td><td>0.92836</td></tr><tr><td>train_loss</td><td>0.22663</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">generous-monkey-6</strong> at: <a href='https://wandb.ai/usf-magma/Assignment5/runs/2clcbqxi' target=\"_blank\">https://wandb.ai/usf-magma/Assignment5/runs/2clcbqxi</a><br> View project at: <a href='https://wandb.ai/usf-magma/Assignment5' target=\"_blank\">https://wandb.ai/usf-magma/Assignment5</a><br>Synced 5 W&B file(s), 5 media file(s), 10 artifact file(s) and 2 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250317_013818-2clcbqxi/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# First, add scikit-learn for metrics calculation\n",
        "\n",
        "\n",
        "# Ensure the model is on the correct device\n",
        "model = model.to(device)\n",
        "\n",
        "# Set up loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
        "\n",
        "wandb.init(project=\"Assignment5\", entity=\"usf-magma\")\n",
        "# Log hyperparameters to W&B\n",
        "wandb.config.update({\n",
        "    \"optimizer\": \"Adam\",\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"criterion\": \"CrossEntropyLoss\",\n",
        "    \"epochs\": 5  # We'll train for just 5 epochs for this example\n",
        "})\n",
        "\n",
        "# Number of classes\n",
        "num_classes = len(class_labels)\n",
        "class_names = list(class_labels.keys())\n",
        "\n",
        "# Training loop\n",
        "def train_model(model, trainloader, testloader, criterion, optimizer, num_epochs=5):\n",
        "    # Track best accuracy\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        all_train_preds = []\n",
        "        all_train_labels = []\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "            # Collect predictions and labels for F1 calculation\n",
        "            all_train_preds.extend(predicted.cpu().numpy())\n",
        "            all_train_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            # Log batch statistics (every 100 batches)\n",
        "            if i % 100 == 99:\n",
        "                batch_acc = 100. * correct / total\n",
        "                batch_loss = running_loss / total\n",
        "                print(f'Batch {i+1}, Loss: {batch_loss:.4f}, Acc: {batch_acc:.2f}%')\n",
        "\n",
        "                wandb.log({\n",
        "                    \"train_batch_loss\": batch_loss,\n",
        "                    \"train_batch_acc\": batch_acc,\n",
        "                    \"epoch\": epoch + i/len(trainloader)\n",
        "                })\n",
        "\n",
        "        # Calculate epoch statistics\n",
        "        train_loss = running_loss / len(trainloader.dataset)\n",
        "        train_acc = 100. * correct / total\n",
        "\n",
        "        # Calculate F1 score for the training epoch\n",
        "        train_f1_macro = f1_score(all_train_labels, all_train_preds, average='macro')\n",
        "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, F1-macro: {train_f1_macro:.4f}')\n",
        "\n",
        "        # Evaluation phase\n",
        "        model.eval()\n",
        "        test_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        class_correct = list(0. for _ in range(num_classes))\n",
        "        class_total = list(0. for _ in range(num_classes))\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in testloader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Statistics\n",
        "                test_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "                # Per-class accuracy\n",
        "                c = (predicted == labels).squeeze()\n",
        "                for i in range(labels.size(0)):\n",
        "                    label = labels[i].item()\n",
        "                    class_correct[label] += c[i].item()\n",
        "                    class_total[label] += 1\n",
        "\n",
        "                # Store for confusion matrix and F1 calculation\n",
        "                all_preds.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        # Calculate test statistics\n",
        "        test_loss = test_loss / len(testloader.dataset)\n",
        "        test_acc = 100. * correct / total\n",
        "\n",
        "        # Calculate F1 score for test data\n",
        "        test_f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
        "        print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%, F1-macro: {test_f1_macro:.4f}')\n",
        "\n",
        "        # Per-class accuracy\n",
        "        for i in range(num_classes):\n",
        "            class_acc = 100 * class_correct[i] / class_total[i] if class_total[i] > 0 else 0\n",
        "\n",
        "\n",
        "        # Log epoch statistics to W&B\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"train_loss\": train_loss,\n",
        "            \"train_acc\": train_acc,\n",
        "            \"train_f1_macro\": train_f1_macro,\n",
        "            \"test_loss\": test_loss,\n",
        "            \"test_acc\": test_acc,\n",
        "            \"test_f1_macro\": test_f1_macro\n",
        "        })\n",
        "\n",
        "        # Log per-class accuracy\n",
        "        class_acc_dict = {f\"class_acc_{class_names[i]}\": 100 * class_correct[i] / class_total[i]\n",
        "                         if class_total[i] > 0 else 0 for i in range(num_classes)}\n",
        "        wandb.log(class_acc_dict)\n",
        "\n",
        "        # Log confusion matrix\n",
        "        wandb.log({\n",
        "            \"confusion_matrix\": wandb.plot.confusion_matrix(\n",
        "                probs=None,\n",
        "                y_true=all_labels,\n",
        "                preds=all_preds,\n",
        "                class_names=class_names\n",
        "            )\n",
        "        })\n",
        "\n",
        "        # Save model if it's the best so far\n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "            best_f1 = test_f1_macro\n",
        "            torch.save(model.state_dict(), f'resnet18_stanforddogs_epoch_{epoch+1}.pth')\n",
        "            wandb.save(f'resnet18_stanforddogs_epoch_{epoch+1}.pth')\n",
        "\n",
        "            # Log best model metrics to W&B summary\n",
        "            wandb.run.summary[\"best_accuracy\"] = best_acc\n",
        "            wandb.run.summary[\"best_f1_macro\"] = best_f1\n",
        "            wandb.run.summary[\"best_epoch\"] = epoch + 1\n",
        "\n",
        "    print(f'Best test accuracy: {best_acc:.2f}%')\n",
        "    return model\n",
        "\n",
        "# Train the model\n",
        "model = train_model(model, trainloader, testloader, criterion, optimizer)\n",
        "\n",
        "# Finish the W&B run\n",
        "wandb.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yGvek9pUwe9p",
        "outputId": "a14dbd08-3e8f-42c2-a19b-ccbb6fb68fcc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250317_014000-43pkuqfp</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/usf-magma/Assignment5/runs/43pkuqfp' target=\"_blank\">copper-gorge-7</a></strong> to <a href='https://wandb.ai/usf-magma/Assignment5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/usf-magma/Assignment5' target=\"_blank\">https://wandb.ai/usf-magma/Assignment5</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/usf-magma/Assignment5/runs/43pkuqfp' target=\"_blank\">https://wandb.ai/usf-magma/Assignment5/runs/43pkuqfp</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "----------\n",
            "Batch 100, Loss: 0.2251, Acc: 92.44%\n",
            "Batch 200, Loss: 0.2321, Acc: 92.33%\n",
            "Batch 300, Loss: 0.2286, Acc: 92.49%\n",
            "Batch 400, Loss: 0.2304, Acc: 92.54%\n",
            "Batch 500, Loss: 0.2286, Acc: 92.61%\n",
            "Train Loss: 0.2301, Train Acc: 92.51%, F1-macro: 0.9249\n",
            "Test Loss: 1.1963, Test Acc: 70.97%, F1-macro: 0.7048\n",
            "Epoch 2/15\n",
            "----------\n",
            "Batch 100, Loss: 0.1998, Acc: 93.28%\n",
            "Batch 200, Loss: 0.2065, Acc: 93.31%\n",
            "Batch 300, Loss: 0.2058, Acc: 93.44%\n",
            "Batch 400, Loss: 0.2103, Acc: 93.30%\n",
            "Batch 500, Loss: 0.2142, Acc: 93.21%\n",
            "Train Loss: 0.2152, Train Acc: 93.17%, F1-macro: 0.9316\n",
            "Test Loss: 1.2186, Test Acc: 70.70%, F1-macro: 0.7008\n",
            "Epoch 3/15\n",
            "----------\n",
            "Batch 100, Loss: 0.1886, Acc: 93.94%\n",
            "Batch 200, Loss: 0.1985, Acc: 93.75%\n",
            "Batch 300, Loss: 0.1984, Acc: 93.75%\n",
            "Batch 400, Loss: 0.2041, Acc: 93.45%\n",
            "Batch 500, Loss: 0.2096, Acc: 93.28%\n",
            "Train Loss: 0.2102, Train Acc: 93.25%, F1-macro: 0.9325\n",
            "Test Loss: 1.2532, Test Acc: 70.41%, F1-macro: 0.7000\n",
            "Epoch 4/15\n",
            "----------\n",
            "Batch 100, Loss: 0.2047, Acc: 93.12%\n",
            "Batch 200, Loss: 0.2035, Acc: 93.28%\n",
            "Batch 300, Loss: 0.1998, Acc: 93.36%\n",
            "Batch 400, Loss: 0.2062, Acc: 93.06%\n",
            "Batch 500, Loss: 0.2090, Acc: 92.97%\n",
            "Train Loss: 0.2103, Train Acc: 92.92%, F1-macro: 0.9292\n",
            "Test Loss: 1.2790, Test Acc: 69.95%, F1-macro: 0.6931\n",
            "Epoch 5/15\n",
            "----------\n",
            "Batch 100, Loss: 0.1994, Acc: 93.09%\n",
            "Batch 200, Loss: 0.1963, Acc: 93.28%\n",
            "Batch 300, Loss: 0.1976, Acc: 93.30%\n",
            "Batch 400, Loss: 0.2016, Acc: 93.16%\n",
            "Batch 500, Loss: 0.2034, Acc: 93.14%\n",
            "Train Loss: 0.2053, Train Acc: 93.05%, F1-macro: 0.9301\n",
            "Test Loss: 1.2437, Test Acc: 70.29%, F1-macro: 0.6956\n",
            "Epoch 6/15\n",
            "----------\n",
            "Batch 100, Loss: 0.1869, Acc: 94.19%\n",
            "Batch 200, Loss: 0.1962, Acc: 93.34%\n",
            "Batch 300, Loss: 0.2000, Acc: 93.36%\n",
            "Batch 400, Loss: 0.2074, Acc: 93.13%\n",
            "Batch 500, Loss: 0.2102, Acc: 93.06%\n",
            "Train Loss: 0.2101, Train Acc: 93.03%, F1-macro: 0.9301\n",
            "Test Loss: 1.2877, Test Acc: 70.00%, F1-macro: 0.6968\n",
            "Epoch 7/15\n",
            "----------\n",
            "Batch 100, Loss: 0.1688, Acc: 94.84%\n",
            "Batch 200, Loss: 0.1751, Acc: 94.61%\n",
            "Batch 300, Loss: 0.1758, Acc: 94.48%\n",
            "Batch 400, Loss: 0.1864, Acc: 94.11%\n",
            "Batch 500, Loss: 0.1904, Acc: 93.94%\n",
            "Train Loss: 0.1906, Train Acc: 93.88%, F1-macro: 0.9382\n",
            "Test Loss: 1.2893, Test Acc: 70.04%, F1-macro: 0.6949\n",
            "Epoch 8/15\n",
            "----------\n",
            "Batch 100, Loss: 0.1915, Acc: 93.72%\n",
            "Batch 200, Loss: 0.2005, Acc: 93.39%\n",
            "Batch 300, Loss: 0.1992, Acc: 93.31%\n",
            "Batch 400, Loss: 0.1971, Acc: 93.45%\n",
            "Batch 500, Loss: 0.2004, Acc: 93.43%\n",
            "Train Loss: 0.2007, Train Acc: 93.46%, F1-macro: 0.9342\n",
            "Test Loss: 1.2529, Test Acc: 71.19%, F1-macro: 0.7063\n",
            "Epoch 9/15\n",
            "----------\n",
            "Batch 100, Loss: 0.1614, Acc: 94.72%\n",
            "Batch 200, Loss: 0.1704, Acc: 94.50%\n",
            "Batch 300, Loss: 0.1750, Acc: 94.32%\n",
            "Batch 400, Loss: 0.1816, Acc: 94.08%\n",
            "Batch 500, Loss: 0.1861, Acc: 93.88%\n",
            "Train Loss: 0.1862, Train Acc: 93.87%, F1-macro: 0.9385\n",
            "Test Loss: 1.3082, Test Acc: 70.41%, F1-macro: 0.7014\n",
            "Epoch 10/15\n",
            "----------\n",
            "Batch 100, Loss: 0.1749, Acc: 94.59%\n",
            "Batch 200, Loss: 0.1740, Acc: 94.53%\n",
            "Batch 300, Loss: 0.1762, Acc: 94.35%\n",
            "Batch 400, Loss: 0.1820, Acc: 94.04%\n",
            "Batch 500, Loss: 0.1818, Acc: 94.06%\n",
            "Train Loss: 0.1815, Train Acc: 94.08%, F1-macro: 0.9409\n",
            "Test Loss: 1.2764, Test Acc: 70.87%, F1-macro: 0.7039\n",
            "Epoch 11/15\n",
            "----------\n",
            "Batch 100, Loss: 0.1734, Acc: 94.28%\n",
            "Batch 200, Loss: 0.1778, Acc: 94.38%\n",
            "Batch 300, Loss: 0.1758, Acc: 94.40%\n",
            "Batch 400, Loss: 0.1792, Acc: 94.19%\n",
            "Batch 500, Loss: 0.1809, Acc: 94.11%\n",
            "Train Loss: 0.1803, Train Acc: 94.18%, F1-macro: 0.9415\n",
            "Test Loss: 1.2898, Test Acc: 70.92%, F1-macro: 0.7032\n",
            "Epoch 12/15\n",
            "----------\n",
            "Batch 100, Loss: 0.1608, Acc: 94.72%\n",
            "Batch 200, Loss: 0.1679, Acc: 94.78%\n",
            "Batch 300, Loss: 0.1736, Acc: 94.44%\n",
            "Batch 400, Loss: 0.1827, Acc: 94.06%\n",
            "Batch 500, Loss: 0.1847, Acc: 93.94%\n",
            "Train Loss: 0.1858, Train Acc: 93.90%, F1-macro: 0.9390\n",
            "Test Loss: 1.3312, Test Acc: 70.19%, F1-macro: 0.6957\n",
            "Epoch 13/15\n",
            "----------\n",
            "Batch 100, Loss: 0.1703, Acc: 94.62%\n",
            "Batch 200, Loss: 0.1692, Acc: 94.59%\n",
            "Batch 300, Loss: 0.1788, Acc: 94.11%\n",
            "Batch 400, Loss: 0.1787, Acc: 93.95%\n",
            "Batch 500, Loss: 0.1807, Acc: 93.86%\n",
            "Train Loss: 0.1823, Train Acc: 93.80%, F1-macro: 0.9381\n",
            "Test Loss: 1.3415, Test Acc: 70.85%, F1-macro: 0.7039\n",
            "Epoch 14/15\n",
            "----------\n",
            "Batch 100, Loss: 0.1840, Acc: 94.34%\n",
            "Batch 200, Loss: 0.1855, Acc: 94.12%\n",
            "Batch 300, Loss: 0.1803, Acc: 94.16%\n",
            "Batch 400, Loss: 0.1774, Acc: 94.32%\n",
            "Batch 500, Loss: 0.1794, Acc: 94.25%\n",
            "Train Loss: 0.1799, Train Acc: 94.27%, F1-macro: 0.9424\n",
            "Test Loss: 1.3501, Test Acc: 69.75%, F1-macro: 0.6939\n",
            "Epoch 15/15\n",
            "----------\n",
            "Batch 100, Loss: 0.1734, Acc: 94.75%\n",
            "Batch 200, Loss: 0.1643, Acc: 95.27%\n",
            "Batch 300, Loss: 0.1679, Acc: 94.89%\n",
            "Batch 400, Loss: 0.1690, Acc: 94.69%\n",
            "Batch 500, Loss: 0.1754, Acc: 94.34%\n",
            "Train Loss: 0.1765, Train Acc: 94.28%, F1-macro: 0.9427\n",
            "Test Loss: 1.3212, Test Acc: 70.70%, F1-macro: 0.7024\n",
            "Best test accuracy: 71.19%\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>class_acc_n02085620-Chihuahua</td><td>▅█▅▅▅▄▄▁▅▂▆▁▅▅▃</td></tr><tr><td>class_acc_n02085782-Japanese_spaniel</td><td>▁▇▅▅█▇▅▇▇█▇▇▇██</td></tr><tr><td>class_acc_n02085936-Maltese_dog</td><td>▅█▆▆▄▂▁▃▆▃▅▂▅▄▅</td></tr><tr><td>class_acc_n02086079-Pekinese</td><td>▇▃▁▄▄▅▄▅█▄▅▄▄▄▂</td></tr><tr><td>class_acc_n02086240-Shih-Tzu</td><td>█▄█▆▆▆▁▅▇▆▆▄▅█▆</td></tr><tr><td>class_acc_n02086646-Blenheim_spaniel</td><td>█▆▆▄▄█▆█▃▃▆▆▁▆▃</td></tr><tr><td>class_acc_n02086910-papillon</td><td>▇▆▅▆▂▅▄▅▆▅█▅▅▁▅</td></tr><tr><td>class_acc_n02087046-toy_terrier</td><td>▅▆▇▁▇▇▇▆▅▇█▅█▄▇</td></tr><tr><td>class_acc_n02087394-Rhodesian_ridgeback</td><td>▄▇█▆▅▇▇▃▇▄▁▃▂▅▆</td></tr><tr><td>class_acc_n02088094-Afghan_hound</td><td>▁▆█▃▅▂▆▆▄▅▄▇▄▆▇</td></tr><tr><td>class_acc_n02088238-basset</td><td>▇▅█▅▅▅▆▆▃▆▅▁▆▆▅</td></tr><tr><td>class_acc_n02088364-beagle</td><td>▄▃▅▄▅▅▃▂▅▂▁█▁▁▃</td></tr><tr><td>class_acc_n02088466-bloodhound</td><td>▄█▃▅▇▁▅▄▄▇▃▃▅▂█</td></tr><tr><td>class_acc_n02088632-bluetick</td><td>▅▇▇▁▅▆▅▅▅▅█▆▅▆▇</td></tr><tr><td>class_acc_n02089078-black-and-tan_coonhound</td><td>▅▄▁█▄▅▄▇▅▁▆▅▇▅▄</td></tr><tr><td>class_acc_n02089867-Walker_hound</td><td>▆▃▃▆▆▆█▃▆▄▁▇█▇▆</td></tr><tr><td>class_acc_n02089973-English_foxhound</td><td>▆▇▆▅▁▆▅▇▆▆█▃▆▅▆</td></tr><tr><td>class_acc_n02090379-redbone</td><td>█▄▇▁▃▅▅▅▅▅▇██▆▄</td></tr><tr><td>class_acc_n02090622-borzoi</td><td>██▆█▇▇▇█▇▇█▁▆▅▄</td></tr><tr><td>class_acc_n02090721-Irish_wolfhound</td><td>▁▅▅█▄▇▁▂▄▄▇▃█▇▄</td></tr><tr><td>class_acc_n02091032-Italian_greyhound</td><td>▆▇▄▆▄▆▇▁█▂▂█▆█▇</td></tr><tr><td>class_acc_n02091134-whippet</td><td>▆▄▅▃▆▅▄▆▅█▇▄▇▁▄</td></tr><tr><td>class_acc_n02091244-Ibizan_hound</td><td>▅▅▅█▄▄▄▅▁▁▁▄▅▄▂</td></tr><tr><td>class_acc_n02091467-Norwegian_elkhound</td><td>▅▅▂▃▄▆▆█▁▂▁▄▅▅▇</td></tr><tr><td>class_acc_n02091635-otterhound</td><td>▃█▆▃▃▃▃█▆▃▄▆▃▁▄</td></tr><tr><td>class_acc_n02091831-Saluki</td><td>▄▅▇▄█▅▁▇▇▄▇█▅▄▇</td></tr><tr><td>class_acc_n02092002-Scottish_deerhound</td><td>█▅▃▁▄▃▅▅▃▇▃▄▁▃▅</td></tr><tr><td>class_acc_n02092339-Weimaraner</td><td>█▆▅▅▅▆▆▅▆▄▄▁▃▆▆</td></tr><tr><td>class_acc_n02093256-Staffordshire_bullterrier</td><td>█▁▆▂▆▂▇▆▆▆▂▃▇▆▄</td></tr><tr><td>class_acc_n02093428-American_Staffordshire_terrier</td><td>▃▇▁█▃▄▂▆▃▅▆▆▅▅▆</td></tr><tr><td>class_acc_n02093647-Bedlington_terrier</td><td>▄▄█▄▄▄▁▄▄▂▂▂▄▄▄</td></tr><tr><td>class_acc_n02093754-Border_terrier</td><td>██▁▃▆▆▆▆▅▆▁▆█▅▅</td></tr><tr><td>class_acc_n02093859-Kerry_blue_terrier</td><td>▇▁▃▃▅▅▃▃█▂▃▅▂▁▅</td></tr><tr><td>class_acc_n02093991-Irish_terrier</td><td>▆█▆▃▄▆▄▃▄▆▃▁▄▃▄</td></tr><tr><td>class_acc_n02094114-Norfolk_terrier</td><td>▂▁▄▇▂▄▄▄▅▆▄▇█▃█</td></tr><tr><td>class_acc_n02094258-Norwich_terrier</td><td>▇█▇▁██▂▂▁▄▄▁▁▅▂</td></tr><tr><td>class_acc_n02094433-Yorkshire_terrier</td><td>▆▂▆▂▁█▇█▃▇▇▆▅▆▆</td></tr><tr><td>class_acc_n02095314-wire-haired_fox_terrier</td><td>▇█▅█▄▇▁▁▁▅▅▅▇▇▅</td></tr><tr><td>class_acc_n02095570-Lakeland_terrier</td><td>▄▁▁▅▇▅█▅▇▄▄▅▃▂▁</td></tr><tr><td>class_acc_n02095889-Sealyham_terrier</td><td>▆▂▆▃▂▁▂▆▆▄▂█▆▂▆</td></tr><tr><td>class_acc_n02096051-Airedale</td><td>▄█▄█▅▁▅▇▄▄▂▇▇▅▅</td></tr><tr><td>class_acc_n02096177-cairn</td><td>▆▂▄▄▁▃██▄▄▆▆▅▄▆</td></tr><tr><td>class_acc_n02096294-Australian_terrier</td><td>▄█▂▄▆▁▃▄█▁▅▅▃▅▂</td></tr><tr><td>class_acc_n02096437-Dandie_Dinmont</td><td>▃▅▁█▅▅▃▅▆▇▃▃▇▃▆</td></tr><tr><td>class_acc_n02096585-Boston_bull</td><td>▄▆▅▁▁▇▄▇▃▁█▃▇▅▆</td></tr><tr><td>class_acc_n02097047-miniature_schnauzer</td><td>▃▄▅▇▅▇▁▅▂█▇▅▇▇▄</td></tr><tr><td>class_acc_n02097130-giant_schnauzer</td><td>▄█▇▂▄▂▂▁▂▅▇▅▂█▂</td></tr><tr><td>class_acc_n02097209-standard_schnauzer</td><td>▆▅▇▂▅▄█▅▇▁▂▆▃▃█</td></tr><tr><td>class_acc_n02097298-Scotch_terrier</td><td>▅▂▁▂▄▂▂▄█▂▄▅▂▂▅</td></tr><tr><td>class_acc_n02097474-Tibetan_terrier</td><td>▁▇█▄▆▅▅▄▆▄▆▇▂▃▃</td></tr><tr><td>class_acc_n02097658-silky_terrier</td><td>▆▃▆██▃▃▁▃▃▃▆█▃▆</td></tr><tr><td>class_acc_n02098105-soft-coated_wheaten_terrier</td><td>█▂▂▆▇▆▆▇▆▆▆▅▁▇▆</td></tr><tr><td>class_acc_n02098286-West_Highland_white_terrier</td><td>▆▅▆▆█▁▃▅▆▆▇▃▃▃▂</td></tr><tr><td>class_acc_n02098413-Lhasa</td><td>▂▅▁▃▄▅█▇▂▅▅▆▆▆▆</td></tr><tr><td>class_acc_n02099267-flat-coated_retriever</td><td>▃▁▅▂▇▃▇█▅▅▅▆▇▇▇</td></tr><tr><td>class_acc_n02099429-curly-coated_retriever</td><td>█▂▁██▇▅▇▇▇▁██▇█</td></tr><tr><td>class_acc_n02099601-golden_retriever</td><td>▂▁▄▄▇▂█▅█▅▅▇▄▄█</td></tr><tr><td>class_acc_n02099712-Labrador_retriever</td><td>█▅▅▄▃▂▁▂▁▅▅▁▃▂▅</td></tr><tr><td>class_acc_n02099849-Chesapeake_Bay_retriever</td><td>▁▇▆█▇▁▇█▄▇▇▆▇▆▅</td></tr><tr><td>class_acc_n02100236-German_short-haired_pointer</td><td>▂▄▄▂▃▂▇▅▅▅▅█▁▄▃</td></tr><tr><td>class_acc_n02100583-vizsla</td><td>▂▆▁▅▅█▄▅▆▆▇▂▅▄▄</td></tr><tr><td>class_acc_n02100735-English_setter</td><td>▄▇▁▃█▅▄▄▄▅▅▂▄▃▄</td></tr><tr><td>class_acc_n02100877-Irish_setter</td><td>█▁▆▇█▇▆▇███▇█▇▄</td></tr><tr><td>class_acc_n02101006-Gordon_setter</td><td>█▁███▆████████▆</td></tr><tr><td>class_acc_n02101388-Brittany_spaniel</td><td>▆▁▅▂▁▂▃▄▇▄▃▆▃▄█</td></tr><tr><td>class_acc_n02101556-clumber</td><td>▅▁▇▄▂█▄█▇▄▅▄▂▂▄</td></tr><tr><td>class_acc_n02102040-English_springer</td><td>▃▃█▄▃▆▃▃▃▁▁▃▂▁▂</td></tr><tr><td>class_acc_n02102177-Welsh_springer_spaniel</td><td>▃▆▁█▆▅▃▃▅█▅▃▅▅▁</td></tr><tr><td>class_acc_n02102318-cocker_spaniel</td><td>▆▆▅▄▅▆▅█▂▆▄▄▅▆▁</td></tr><tr><td>class_acc_n02102480-Sussex_spaniel</td><td>▆█▅▆▆▁▆▃▆▆▆▆▆▆▆</td></tr><tr><td>class_acc_n02102973-Irish_water_spaniel</td><td>▆█▆▁▆▆▆█▆▆█▆██▆</td></tr><tr><td>class_acc_n02104029-kuvasz</td><td>▁▅█▃▂▃▁▄▆▅▃▄▄▆▄</td></tr><tr><td>class_acc_n02104365-schipperke</td><td>█▇▅▁█▆▄▇█▆█▃█▅▇</td></tr><tr><td>class_acc_n02105056-groenendael</td><td>▄▆▇█▅▅▄▄▁▆▃▇▃▇▂</td></tr><tr><td>class_acc_n02105162-malinois</td><td>▃▃▂▅▃▃▁▅█▅▅▁▃▃▃</td></tr><tr><td>class_acc_n02105251-briard</td><td>▇▅▅▇▇▅▇█▅▂▅▁▅▅▇</td></tr><tr><td>class_acc_n02105412-kelpie</td><td>▂█▇▃▃▂▇▁▄▆▇▁▂▂▃</td></tr><tr><td>class_acc_n02105505-komondor</td><td>▄▁▁▁▁█▄▁▁▁█▁▁▁▁</td></tr><tr><td>class_acc_n02105641-Old_English_sheepdog</td><td>▅▆▆▅█▅██▅▁▅▅▁▁█</td></tr><tr><td>class_acc_n02105855-Shetland_sheepdog</td><td>▆▁▇▇▁▄▇▇▅▇▇▇▇█▅</td></tr><tr><td>class_acc_n02106030-collie</td><td>▄▆▅▅█▄▁▃▅▃▃▃▁▃▅</td></tr><tr><td>class_acc_n02106166-Border_collie</td><td>▄▄▂▄▁▄█▆▄▄▃▅▇▆▅</td></tr><tr><td>class_acc_n02106382-Bouvier_des_Flandres</td><td>▃▇▇▃▃▃▁▂▂█▆▃▂▅▃</td></tr><tr><td>class_acc_n02106550-Rottweiler</td><td>▃█▆▂▅▁▅▅▅▅▅▆▃▅▅</td></tr><tr><td>class_acc_n02106662-German_shepherd</td><td>▆▃▆▅▆▆▇▄▁▆▆▆▅█▇</td></tr><tr><td>class_acc_n02107142-Doberman</td><td>▂▄▅▄█▆▄▂▅▆▅▅▂▅▁</td></tr><tr><td>class_acc_n02107312-miniature_pinscher</td><td>█▄▁▇▂▆▂▆▅▆▃▅█▅▇</td></tr><tr><td>class_acc_n02107574-Greater_Swiss_Mountain_dog</td><td>▆▆▆████▆██▆██▁▆</td></tr><tr><td>class_acc_n02107683-Bernese_mountain_dog</td><td>▄▅▄▁▂▂▅▄▄█▅▂▅▄▂</td></tr><tr><td>class_acc_n02107908-Appenzeller</td><td>▄▂▁▃▂▃▂█▂▃▄▄▃▄▅</td></tr><tr><td>class_acc_n02108000-EntleBucher</td><td>▃▇▅▇▅█▅▇▅▄▇▇▇▇▁</td></tr><tr><td>class_acc_n02108089-boxer</td><td>█▆▃▁▆▃▃▃█▃▃▄▃▄▆</td></tr><tr><td>class_acc_n02108422-bull_mastiff</td><td>██████▁▁██▁██▁█</td></tr><tr><td>class_acc_n02108551-Tibetan_mastiff</td><td>▃▆▁▆██▅▆▁▃▃▅▆▆▅</td></tr><tr><td>class_acc_n02108915-French_bulldog</td><td>▅▁█▃▇▂▆▂▃▄▃▆▂▅▅</td></tr><tr><td>class_acc_n02109047-Great_Dane</td><td>▅▆██▂▅▅▆▅▅▄█▄▁▆</td></tr><tr><td>class_acc_n02109525-Saint_Bernard</td><td>▅█▅█▅▁▅▁▅▅▁▅▅▁█</td></tr><tr><td>class_acc_n02109961-Eskimo_dog</td><td>▃▃█▁▂▃▃▃▅▄▂▃▇▅▆</td></tr><tr><td>class_acc_n02110063-malamute</td><td>▂▅█▅▄▃▄▆▄▇▆▄█▁▃</td></tr><tr><td>class_acc_n02110185-Siberian_husky</td><td>▇▅▁▇█▇▇▇▆▅▇▇▂▇▅</td></tr><tr><td>class_acc_n02110627-affenpinscher</td><td>▆▆▆▆▃▁▁▃▅▅▃▃█▆▅</td></tr><tr><td>class_acc_n02110806-basenji</td><td>▇▅▅█▆▁▇▇▆█▆▇▆▆▇</td></tr><tr><td>class_acc_n02110958-pug</td><td>█▆▁▅▅▇▇▇▆▆▇▇▅▃▃</td></tr><tr><td>class_acc_n02111129-Leonberg</td><td>▃▃▆█▃▆▆▆▃▃█▆█▁▆</td></tr><tr><td>class_acc_n02111277-Newfoundland</td><td>▇▂█▅▇▆▅▅▃▆▅▅▇▁▅</td></tr><tr><td>class_acc_n02111500-Great_Pyrenees</td><td>▇▄▁▅▅▃█▅▄▃▆▆▆▂▃</td></tr><tr><td>class_acc_n02111889-Samoyed</td><td>▄▅█▄▃▆▁▄▃▆▄▄▄▄▅</td></tr><tr><td>class_acc_n02112018-Pomeranian</td><td>▅█▃▄▆▅▃▃▁▄█▄▇▄▄</td></tr><tr><td>class_acc_n02112137-chow</td><td>▄▄▁▅▄▄▆▅▇█▅▅▅▃▆</td></tr><tr><td>class_acc_n02112350-keeshond</td><td>▅▇▅█▅▇▅▄▄▅▂▁▂▅▅</td></tr><tr><td>class_acc_n02112706-Brabancon_griffon</td><td>▅▆▅▄▄▄█▅▁▄▄▁▅▃▆</td></tr><tr><td>class_acc_n02113023-Pembroke</td><td>▃▅▁▄█▄▁█▂█▇▃▅▇▅</td></tr><tr><td>class_acc_n02113186-Cardigan</td><td>▆▁▆▃▃▅█▃▅▅▃▃▆▆▃</td></tr><tr><td>class_acc_n02113624-toy_poodle</td><td>▃▄▆▅▆▇▇▄▄▂▁█▅▅▃</td></tr><tr><td>class_acc_n02113712-miniature_poodle</td><td>▆▂▁▃▃▄▁▅▄▇█▁▄▃▄</td></tr><tr><td>class_acc_n02113799-standard_poodle</td><td>▁▇█▇▂▅▇▄▅▄▂█▄▅▅</td></tr><tr><td>class_acc_n02113978-Mexican_hairless</td><td>▇▄▅▄▄▇▄▇█▄▇▄▇▁▄</td></tr><tr><td>class_acc_n02115641-dingo</td><td>▄▅▄▄▂▅▂▁▂▅▄█▅▅▄</td></tr><tr><td>class_acc_n02115913-dhole</td><td>▅▂▂▂▄▄█▂▇▂▇▂▇▅▁</td></tr><tr><td>class_acc_n02116738-African_hunting_dog</td><td>▄█▇▅▇▇▅▄▇▂▄▂▂▅▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇███</td></tr><tr><td>test_acc</td><td>▇▆▄▂▄▂▂█▄▆▇▃▆▁▆</td></tr><tr><td>test_f1_macro</td><td>▇▅▅▁▂▃▂█▅▇▆▂▇▁▆</td></tr><tr><td>test_loss</td><td>▁▂▄▅▃▅▅▄▆▅▅▇██▇</td></tr><tr><td>train_acc</td><td>▁▄▄▃▃▃▆▅▆▇█▆▆██</td></tr><tr><td>train_batch_acc</td><td>▁▁▁▂▂▄▅▅▄▃▃▃▄▆▃█▇▅▄▄▄█▇▆▇▇▆▇▇▆█▇▆▅▇▅▇▆▆█</td></tr><tr><td>train_batch_loss</td><td>██▆▄▅▆▅▅▆▆▅▅▄▅▅▆▂▂▃▄▅▅▁▂▂▄▂▃▃▁▂▂▂▃▃▃▄▃▂▂</td></tr><tr><td>train_f1_macro</td><td>▁▄▄▃▃▃▆▅▆▇█▇▆██</td></tr><tr><td>train_loss</td><td>█▆▅▅▅▅▃▄▂▂▁▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_accuracy</td><td>71.18562</td></tr><tr><td>best_epoch</td><td>8</td></tr><tr><td>best_f1_macro</td><td>0.70629</td></tr><tr><td>class_acc_n02085620-Chihuahua</td><td>51.6129</td></tr><tr><td>class_acc_n02085782-Japanese_spaniel</td><td>96.42857</td></tr><tr><td>class_acc_n02085936-Maltese_dog</td><td>65.95745</td></tr><tr><td>class_acc_n02086079-Pekinese</td><td>62.5</td></tr><tr><td>class_acc_n02086240-Shih-Tzu</td><td>58.97436</td></tr><tr><td>class_acc_n02086646-Blenheim_spaniel</td><td>82.92683</td></tr><tr><td>class_acc_n02086910-papillon</td><td>82.97872</td></tr><tr><td>class_acc_n02087046-toy_terrier</td><td>66.66667</td></tr><tr><td>class_acc_n02087394-Rhodesian_ridgeback</td><td>63.63636</td></tr><tr><td>class_acc_n02088094-Afghan_hound</td><td>92.30769</td></tr><tr><td>class_acc_n02088238-basset</td><td>68</td></tr><tr><td>class_acc_n02088364-beagle</td><td>57.14286</td></tr><tr><td>class_acc_n02088466-bloodhound</td><td>78.37838</td></tr><tr><td>class_acc_n02088632-bluetick</td><td>66.66667</td></tr><tr><td>class_acc_n02089078-black-and-tan_coonhound</td><td>72.41379</td></tr><tr><td>class_acc_n02089867-Walker_hound</td><td>59.25926</td></tr><tr><td>class_acc_n02089973-English_foxhound</td><td>53.57143</td></tr><tr><td>class_acc_n02090379-redbone</td><td>54.54545</td></tr><tr><td>class_acc_n02090622-borzoi</td><td>64.51613</td></tr><tr><td>class_acc_n02090721-Irish_wolfhound</td><td>58.13953</td></tr><tr><td>class_acc_n02091032-Italian_greyhound</td><td>80.76923</td></tr><tr><td>class_acc_n02091134-whippet</td><td>53.33333</td></tr><tr><td>class_acc_n02091244-Ibizan_hound</td><td>80</td></tr><tr><td>class_acc_n02091467-Norwegian_elkhound</td><td>86.11111</td></tr><tr><td>class_acc_n02091635-otterhound</td><td>61.29032</td></tr><tr><td>class_acc_n02091831-Saluki</td><td>78.78788</td></tr><tr><td>class_acc_n02092002-Scottish_deerhound</td><td>78.7234</td></tr><tr><td>class_acc_n02092339-Weimaraner</td><td>85.18519</td></tr><tr><td>class_acc_n02093256-Staffordshire_bullterrier</td><td>51.6129</td></tr><tr><td>class_acc_n02093428-American_Staffordshire_terrier</td><td>47.36842</td></tr><tr><td>class_acc_n02093647-Bedlington_terrier</td><td>90.69767</td></tr><tr><td>class_acc_n02093754-Border_terrier</td><td>77.77778</td></tr><tr><td>class_acc_n02093859-Kerry_blue_terrier</td><td>58.06452</td></tr><tr><td>class_acc_n02093991-Irish_terrier</td><td>69.23077</td></tr><tr><td>class_acc_n02094114-Norfolk_terrier</td><td>74.35897</td></tr><tr><td>class_acc_n02094258-Norwich_terrier</td><td>75</td></tr><tr><td>class_acc_n02094433-Yorkshire_terrier</td><td>57.5</td></tr><tr><td>class_acc_n02095314-wire-haired_fox_terrier</td><td>66.66667</td></tr><tr><td>class_acc_n02095570-Lakeland_terrier</td><td>51.16279</td></tr><tr><td>class_acc_n02095889-Sealyham_terrier</td><td>84.48276</td></tr><tr><td>class_acc_n02096051-Airedale</td><td>79.48718</td></tr><tr><td>class_acc_n02096177-cairn</td><td>74.35897</td></tr><tr><td>class_acc_n02096294-Australian_terrier</td><td>75</td></tr><tr><td>class_acc_n02096437-Dandie_Dinmont</td><td>84.61538</td></tr><tr><td>class_acc_n02096585-Boston_bull</td><td>73.33333</td></tr><tr><td>class_acc_n02097047-miniature_schnauzer</td><td>56.25</td></tr><tr><td>class_acc_n02097130-giant_schnauzer</td><td>60.71429</td></tr><tr><td>class_acc_n02097209-standard_schnauzer</td><td>67.5</td></tr><tr><td>class_acc_n02097298-Scotch_terrier</td><td>82.14286</td></tr><tr><td>class_acc_n02097474-Tibetan_terrier</td><td>58.53659</td></tr><tr><td>class_acc_n02097658-silky_terrier</td><td>64.70588</td></tr><tr><td>class_acc_n02098105-soft-coated_wheaten_terrier</td><td>72</td></tr><tr><td>class_acc_n02098286-West_Highland_white_terrier</td><td>67.74194</td></tr><tr><td>class_acc_n02098413-Lhasa</td><td>56.25</td></tr><tr><td>class_acc_n02099267-flat-coated_retriever</td><td>81.25</td></tr><tr><td>class_acc_n02099429-curly-coated_retriever</td><td>84.375</td></tr><tr><td>class_acc_n02099601-golden_retriever</td><td>69.23077</td></tr><tr><td>class_acc_n02099712-Labrador_retriever</td><td>61.90476</td></tr><tr><td>class_acc_n02099849-Chesapeake_Bay_retriever</td><td>72.72727</td></tr><tr><td>class_acc_n02100236-German_short-haired_pointer</td><td>75</td></tr><tr><td>class_acc_n02100583-vizsla</td><td>71.05263</td></tr><tr><td>class_acc_n02100735-English_setter</td><td>64.86486</td></tr><tr><td>class_acc_n02100877-Irish_setter</td><td>83.87097</td></tr><tr><td>class_acc_n02101006-Gordon_setter</td><td>84.84848</td></tr><tr><td>class_acc_n02101388-Brittany_spaniel</td><td>86.66667</td></tr><tr><td>class_acc_n02101556-clumber</td><td>75.86207</td></tr><tr><td>class_acc_n02102040-English_springer</td><td>65.21739</td></tr><tr><td>class_acc_n02102177-Welsh_springer_spaniel</td><td>72</td></tr><tr><td>class_acc_n02102318-cocker_spaniel</td><td>42.85714</td></tr><tr><td>class_acc_n02102480-Sussex_spaniel</td><td>77.41935</td></tr><tr><td>class_acc_n02102973-Irish_water_spaniel</td><td>82.14286</td></tr><tr><td>class_acc_n02104029-kuvasz</td><td>62.06897</td></tr><tr><td>class_acc_n02104365-schipperke</td><td>84.21053</td></tr><tr><td>class_acc_n02105056-groenendael</td><td>62.5</td></tr><tr><td>class_acc_n02105162-malinois</td><td>59.375</td></tr><tr><td>class_acc_n02105251-briard</td><td>84.84848</td></tr><tr><td>class_acc_n02105412-kelpie</td><td>63.63636</td></tr><tr><td>class_acc_n02105505-komondor</td><td>87.5</td></tr><tr><td>class_acc_n02105641-Old_English_sheepdog</td><td>84.375</td></tr><tr><td>class_acc_n02105855-Shetland_sheepdog</td><td>72</td></tr><tr><td>class_acc_n02106030-collie</td><td>40.90909</td></tr><tr><td>class_acc_n02106166-Border_collie</td><td>68.96552</td></tr><tr><td>class_acc_n02106382-Bouvier_des_Flandres</td><td>71.875</td></tr><tr><td>class_acc_n02106550-Rottweiler</td><td>85.18519</td></tr><tr><td>class_acc_n02106662-German_shepherd</td><td>75</td></tr><tr><td>class_acc_n02107142-Doberman</td><td>46.42857</td></tr><tr><td>class_acc_n02107312-miniature_pinscher</td><td>72.97297</td></tr><tr><td>class_acc_n02107574-Greater_Swiss_Mountain_dog</td><td>74.07407</td></tr><tr><td>class_acc_n02107683-Bernese_mountain_dog</td><td>88</td></tr><tr><td>class_acc_n02107908-Appenzeller</td><td>68.96552</td></tr><tr><td>class_acc_n02108000-EntleBucher</td><td>53.48837</td></tr><tr><td>class_acc_n02108089-boxer</td><td>70.83333</td></tr><tr><td>class_acc_n02108422-bull_mastiff</td><td>72.41379</td></tr><tr><td>class_acc_n02108551-Tibetan_mastiff</td><td>84.375</td></tr><tr><td>class_acc_n02108915-French_bulldog</td><td>63.41463</td></tr><tr><td>class_acc_n02109047-Great_Dane</td><td>58.33333</td></tr><tr><td>class_acc_n02109525-Saint_Bernard</td><td>87.87879</td></tr><tr><td>class_acc_n02109961-Eskimo_dog</td><td>37.03704</td></tr><tr><td>class_acc_n02110063-malamute</td><td>61.76471</td></tr><tr><td>class_acc_n02110185-Siberian_husky</td><td>44.73684</td></tr><tr><td>class_acc_n02110627-affenpinscher</td><td>64.86486</td></tr><tr><td>class_acc_n02110806-basenji</td><td>73.33333</td></tr><tr><td>class_acc_n02110958-pug</td><td>77.5</td></tr><tr><td>class_acc_n02111129-Leonberg</td><td>94.11765</td></tr><tr><td>class_acc_n02111277-Newfoundland</td><td>69.23077</td></tr><tr><td>class_acc_n02111500-Great_Pyrenees</td><td>60.86957</td></tr><tr><td>class_acc_n02111889-Samoyed</td><td>86.48649</td></tr><tr><td>class_acc_n02112018-Pomeranian</td><td>77.27273</td></tr><tr><td>class_acc_n02112137-chow</td><td>89.65517</td></tr><tr><td>class_acc_n02112350-keeshond</td><td>91.66667</td></tr><tr><td>class_acc_n02112706-Brabancon_griffon</td><td>94.44444</td></tr><tr><td>class_acc_n02113023-Pembroke</td><td>74.4186</td></tr><tr><td>class_acc_n02113186-Cardigan</td><td>47.05882</td></tr><tr><td>class_acc_n02113624-toy_poodle</td><td>36.36364</td></tr><tr><td>class_acc_n02113712-miniature_poodle</td><td>42.85714</td></tr><tr><td>class_acc_n02113799-standard_poodle</td><td>70</td></tr><tr><td>class_acc_n02113978-Mexican_hairless</td><td>89.28571</td></tr><tr><td>class_acc_n02115641-dingo</td><td>82.14286</td></tr><tr><td>class_acc_n02115913-dhole</td><td>76.66667</td></tr><tr><td>class_acc_n02116738-African_hunting_dog</td><td>88.37209</td></tr><tr><td>epoch</td><td>15</td></tr><tr><td>test_acc</td><td>70.69971</td></tr><tr><td>test_f1_macro</td><td>0.70238</td></tr><tr><td>test_loss</td><td>1.32124</td></tr><tr><td>train_acc</td><td>94.2845</td></tr><tr><td>train_batch_acc</td><td>94.34375</td></tr><tr><td>train_batch_loss</td><td>0.17537</td></tr><tr><td>train_f1_macro</td><td>0.94265</td></tr><tr><td>train_loss</td><td>0.17652</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">copper-gorge-7</strong> at: <a href='https://wandb.ai/usf-magma/Assignment5/runs/43pkuqfp' target=\"_blank\">https://wandb.ai/usf-magma/Assignment5/runs/43pkuqfp</a><br> View project at: <a href='https://wandb.ai/usf-magma/Assignment5' target=\"_blank\">https://wandb.ai/usf-magma/Assignment5</a><br>Synced 5 W&B file(s), 15 media file(s), 30 artifact file(s) and 2 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250317_014000-43pkuqfp/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# First, add scikit-learn for metrics calculation\n",
        "from sklearn.metrics import f1_score\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import wandb\n",
        "\n",
        "# Ensure the model is on the correct device\n",
        "model = model.to(device)\n",
        "\n",
        "# Set up loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
        "\n",
        "wandb.init(project=\"Assignment5\", entity=\"usf-magma\")\n",
        "# Log hyperparameters to W&B\n",
        "wandb.config.update({\n",
        "    \"optimizer\": \"Adam\",\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"criterion\": \"CrossEntropyLoss\",\n",
        "    \"epochs\": 15  # Updated to 15 epochs\n",
        "})\n",
        "\n",
        "# Number of classes\n",
        "num_classes = len(class_labels)\n",
        "class_names = list(class_labels.keys())\n",
        "\n",
        "# Training loop\n",
        "def train_model(model, trainloader, testloader, criterion, optimizer, num_epochs=15):  # Updated to 15 epochs\n",
        "    # Track best accuracy\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        all_train_preds = []\n",
        "        all_train_labels = []\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "            # Collect predictions and labels for F1 calculation\n",
        "            all_train_preds.extend(predicted.cpu().numpy())\n",
        "            all_train_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            # Log batch statistics (every 100 batches)\n",
        "            if i % 100 == 99:\n",
        "                batch_acc = 100. * correct / total\n",
        "                batch_loss = running_loss / total\n",
        "                print(f'Batch {i+1}, Loss: {batch_loss:.4f}, Acc: {batch_acc:.2f}%')\n",
        "\n",
        "                wandb.log({\n",
        "                    \"train_batch_loss\": batch_loss,\n",
        "                    \"train_batch_acc\": batch_acc,\n",
        "                    \"epoch\": epoch + i/len(trainloader)\n",
        "                })\n",
        "\n",
        "        # Calculate epoch statistics\n",
        "        train_loss = running_loss / len(trainloader.dataset)\n",
        "        train_acc = 100. * correct / total\n",
        "\n",
        "        # Calculate F1 score for the training epoch\n",
        "        train_f1_macro = f1_score(all_train_labels, all_train_preds, average='macro')\n",
        "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, F1-macro: {train_f1_macro:.4f}')\n",
        "\n",
        "        # Evaluation phase\n",
        "        model.eval()\n",
        "        test_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        class_correct = list(0. for _ in range(num_classes))\n",
        "        class_total = list(0. for _ in range(num_classes))\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in testloader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Statistics\n",
        "                test_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "                # Per-class accuracy\n",
        "                c = (predicted == labels).squeeze()\n",
        "                for i in range(labels.size(0)):\n",
        "                    label = labels[i].item()\n",
        "                    class_correct[label] += c[i].item()\n",
        "                    class_total[label] += 1\n",
        "\n",
        "                # Store for confusion matrix and F1 calculation\n",
        "                all_preds.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        # Calculate test statistics\n",
        "        test_loss = test_loss / len(testloader.dataset)\n",
        "        test_acc = 100. * correct / total\n",
        "\n",
        "        # Calculate F1 score for test data\n",
        "        test_f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
        "        print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%, F1-macro: {test_f1_macro:.4f}')\n",
        "\n",
        "        # Per-class accuracy\n",
        "        for i in range(num_classes):\n",
        "            class_acc = 100 * class_correct[i] / class_total[i] if class_total[i] > 0 else 0\n",
        "\n",
        "        # Log epoch statistics to W&B\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"train_loss\": train_loss,\n",
        "            \"train_acc\": train_acc,\n",
        "            \"train_f1_macro\": train_f1_macro,\n",
        "            \"test_loss\": test_loss,\n",
        "            \"test_acc\": test_acc,\n",
        "            \"test_f1_macro\": test_f1_macro\n",
        "        })\n",
        "\n",
        "        # Log per-class accuracy\n",
        "        class_acc_dict = {f\"class_acc_{class_names[i]}\": 100 * class_correct[i] / class_total[i]\n",
        "                         if class_total[i] > 0 else 0 for i in range(num_classes)}\n",
        "        wandb.log(class_acc_dict)\n",
        "\n",
        "        # Log confusion matrix\n",
        "        wandb.log({\n",
        "            \"confusion_matrix\": wandb.plot.confusion_matrix(\n",
        "                probs=None,\n",
        "                y_true=all_labels,\n",
        "                preds=all_preds,\n",
        "                class_names=class_names\n",
        "            )\n",
        "        })\n",
        "\n",
        "        # Save model if it's the best so far\n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "            best_f1 = test_f1_macro\n",
        "            torch.save(model.state_dict(), f'resnet18_stanforddogs_epoch_{epoch+1}.pth')\n",
        "            wandb.save(f'resnet18_stanforddogs_epoch_{epoch+1}.pth')\n",
        "\n",
        "            # Log best model metrics to W&B summary\n",
        "            wandb.run.summary[\"best_accuracy\"] = best_acc\n",
        "            wandb.run.summary[\"best_f1_macro\"] = best_f1\n",
        "            wandb.run.summary[\"best_epoch\"] = epoch + 1\n",
        "\n",
        "    print(f'Best test accuracy: {best_acc:.2f}%')\n",
        "    return model\n",
        "\n",
        "# Train the model\n",
        "model = train_model(model, trainloader, testloader, criterion, optimizer)\n",
        "\n",
        "# Finish the W&B run\n",
        "wandb.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "8_ivH59-sqyU",
        "outputId": "71de375a-5119-4999-fea5-ab6b1855c660"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "----------\n",
            "Train Loss: 0.4948, Train Acc: 90.31%, F1-macro: 0.9028\n",
            "Test Loss: 4.1914, Test Acc: 68.22%, F1-macro: 0.6771\n",
            "Epoch 2/15\n",
            "----------\n",
            "Train Loss: 0.4743, Train Acc: 90.82%, F1-macro: 0.9078\n",
            "Test Loss: 4.2828, Test Acc: 67.83%, F1-macro: 0.6764\n",
            "Epoch 3/15\n",
            "----------\n",
            "Train Loss: 0.4762, Train Acc: 90.58%, F1-macro: 0.9058\n",
            "Test Loss: 4.3441, Test Acc: 67.40%, F1-macro: 0.6712\n",
            "Epoch 4/15\n",
            "----------\n"
          ]
        }
      ],
      "source": [
        "# made data augmentation, used adamW optimizer, no of epochs =15, lr scheduler\n",
        "from sklearn.metrics import f1_score\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import wandb\n",
        "from torchvision import transforms\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# Data Augmentation\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Ensure the model is on the correct device\n",
        "model = model.to(device)\n",
        "\n",
        "# Set up loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.fc.parameters(), lr=0.005, weight_decay=1e-4)\n",
        "\n",
        "# Learning Rate Scheduler\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
        "\n",
        "# Early Stopping Variables\n",
        "best_loss = float(\"inf\")\n",
        "patience = 5\n",
        "patience_counter = 0\n",
        "wandb.init(project=\"Assignment5\", entity=\"usf-magma\")\n",
        "# Log hyperparameters to W&B\n",
        "wandb.config.update({\n",
        "    \"optimizer\": \"AdamW\",\n",
        "    \"learning_rate\": 0.005,\n",
        "    \"criterion\": \"CrossEntropyLoss\",\n",
        "    \"epochs\": 15  # Increased epochs for better convergence\n",
        "})\n",
        "\n",
        "# Number of classes\n",
        "num_classes = len(class_labels)\n",
        "class_names = list(class_labels.keys())\n",
        "\n",
        "# Training loop\n",
        "def train_model(model, trainloader, testloader, criterion, optimizer, num_epochs=15):\n",
        "    best_acc = 0.0\n",
        "    global best_loss, patience_counter\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        all_train_preds = []\n",
        "        all_train_labels = []\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            all_train_preds.extend(predicted.cpu().numpy())\n",
        "            all_train_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        train_loss = running_loss / len(trainloader.dataset)\n",
        "        train_acc = 100. * correct / total\n",
        "        train_f1_macro = f1_score(all_train_labels, all_train_preds, average='macro')\n",
        "\n",
        "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, F1-macro: {train_f1_macro:.4f}')\n",
        "\n",
        "        # Evaluation phase\n",
        "        model.eval()\n",
        "        test_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        misclassified_samples = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in testloader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                test_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "                all_preds.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "                # Capture misclassified samples\n",
        "                for i in range(len(labels)):\n",
        "                    if predicted[i] != labels[i]:\n",
        "                        misclassified_samples.append((inputs[i].cpu(), labels[i].cpu(), predicted[i].cpu()))\n",
        "\n",
        "        test_loss = test_loss / len(testloader.dataset)\n",
        "        test_acc = 100. * correct / total\n",
        "        test_f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
        "\n",
        "        print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%, F1-macro: {test_f1_macro:.4f}')\n",
        "\n",
        "        # Log statistics to W&B\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"train_loss\": train_loss,\n",
        "            \"train_acc\": train_acc,\n",
        "            \"train_f1_macro\": train_f1_macro,\n",
        "            \"test_loss\": test_loss,\n",
        "            \"test_acc\": test_acc,\n",
        "            \"test_f1_macro\": test_f1_macro\n",
        "        })\n",
        "\n",
        "        # Log misclassified samples\n",
        "        for img, true_label, pred_label in misclassified_samples[:10]:  # Log only first 10\n",
        "            wandb.log({\n",
        "                \"Misclassified Sample\": [wandb.Image(img, caption=f\"True: {class_names[true_label]} | Pred: {class_names[pred_label]}\")]\n",
        "            })\n",
        "\n",
        "        # Update learning rate scheduler\n",
        "        scheduler.step(test_loss)\n",
        "\n",
        "        # Early stopping\n",
        "        if test_loss < best_loss:\n",
        "            best_loss = test_loss\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), f'best_model.pth')\n",
        "            wandb.save('best_model.pth')\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    print(f'Best test accuracy: {best_acc:.2f}%')\n",
        "    return model\n",
        "\n",
        "# Train the model\n",
        "model = train_model(model, trainloader, testloader, criterion, optimizer)\n",
        "\n",
        "# Finish the W&B run\n",
        "wandb.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6n499XXAJtP",
        "outputId": "7300c897-1c17-4d38-cea8-341c244b4744"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "----------\n",
            "Batch 100, Loss: 3.7894, Acc: 22.41%\n",
            "Batch 200, Loss: 3.0475, Acc: 34.66%\n",
            "Batch 300, Loss: 2.6039, Acc: 43.03%\n",
            "Batch 400, Loss: 2.3158, Acc: 48.02%\n",
            "Batch 500, Loss: 2.1128, Acc: 51.82%\n",
            "Train Loss: 2.0895, Train Acc: 52.33%, F1-macro: 0.5157\n",
            "Test Loss: 1.1756, Test Acc: 67.69%, F1-macro: 0.6641\n",
            "Accuracy of n02086240-Shih-Tzu: 17.95%\n",
            "Accuracy of n02092002-Scottish_deerhound: 70.21%\n",
            "Accuracy of n02085782-Japanese_spaniel: 96.43%\n",
            "Accuracy of n02090622-borzoi: 45.16%\n",
            "Accuracy of n02088238-basset: 56.00%\n",
            "Accuracy of n02090721-Irish_wolfhound: 81.40%\n",
            "Accuracy of n02093859-Kerry_blue_terrier: 64.52%\n",
            "Accuracy of n02091467-Norwegian_elkhound: 91.67%\n",
            "Accuracy of n02091134-whippet: 26.67%\n",
            "Accuracy of n02088364-beagle: 80.95%\n",
            "Accuracy of n02093256-Staffordshire_bullterrier: 58.06%\n",
            "Accuracy of n02086910-papillon: 55.32%\n",
            "Accuracy of n02094258-Norwich_terrier: 77.78%\n",
            "Accuracy of n02088094-Afghan_hound: 90.38%\n",
            "Accuracy of n02086646-Blenheim_spaniel: 87.80%\n",
            "Accuracy of n02093428-American_Staffordshire_terrier: 42.11%\n",
            "Accuracy of n02087046-toy_terrier: 57.58%\n",
            "Accuracy of n02088466-bloodhound: 56.76%\n",
            "Accuracy of n02100236-German_short-haired_pointer: 72.50%\n",
            "Accuracy of n02096437-Dandie_Dinmont: 82.05%\n",
            "Accuracy of n02096585-Boston_bull: 93.33%\n",
            "Accuracy of n02097209-standard_schnauzer: 40.00%\n",
            "Accuracy of n02101006-Gordon_setter: 84.85%\n",
            "Accuracy of n02110806-basenji: 57.78%\n",
            "Accuracy of n02097047-miniature_schnauzer: 62.50%\n",
            "Accuracy of n02097474-Tibetan_terrier: 70.73%\n",
            "Accuracy of n02095570-Lakeland_terrier: 74.42%\n",
            "Accuracy of n02096177-cairn: 53.85%\n",
            "Accuracy of n02104029-kuvasz: 72.41%\n",
            "Accuracy of n02096051-Airedale: 66.67%\n",
            "Accuracy of n02105641-Old_English_sheepdog: 84.38%\n",
            "Accuracy of n02108089-boxer: 37.50%\n",
            "Accuracy of n02099267-flat-coated_retriever: 84.38%\n",
            "Accuracy of n02107683-Bernese_mountain_dog: 94.00%\n",
            "Accuracy of n02110063-malamute: 73.53%\n",
            "Accuracy of n02110627-affenpinscher: 70.27%\n",
            "Accuracy of n02110185-Siberian_husky: 39.47%\n",
            "Accuracy of n02102177-Welsh_springer_spaniel: 88.00%\n",
            "Accuracy of n02098413-Lhasa: 59.38%\n",
            "Accuracy of n02099429-curly-coated_retriever: 81.25%\n",
            "Accuracy of n02105855-Shetland_sheepdog: 72.00%\n",
            "Accuracy of n02102318-cocker_spaniel: 60.00%\n",
            "Accuracy of n02108000-EntleBucher: 79.07%\n",
            "Accuracy of n02102480-Sussex_spaniel: 74.19%\n",
            "Accuracy of n02107574-Greater_Swiss_Mountain_dog: 51.85%\n",
            "Accuracy of n02099849-Chesapeake_Bay_retriever: 79.55%\n",
            "Accuracy of n02108915-French_bulldog: 34.15%\n",
            "Accuracy of n02106166-Border_collie: 68.97%\n",
            "Accuracy of n02097130-giant_schnauzer: 57.14%\n",
            "Accuracy of n02099712-Labrador_retriever: 54.76%\n",
            "Accuracy of n02105505-komondor: 83.33%\n",
            "Accuracy of n02107908-Appenzeller: 51.72%\n",
            "Accuracy of n02106662-German_shepherd: 46.88%\n",
            "Accuracy of n02105162-malinois: 43.75%\n",
            "Accuracy of n02108551-Tibetan_mastiff: 71.88%\n",
            "Accuracy of n02096294-Australian_terrier: 72.73%\n",
            "Accuracy of n02098286-West_Highland_white_terrier: 83.87%\n",
            "Accuracy of n02112018-Pomeranian: 88.64%\n",
            "Accuracy of n02113023-Pembroke: 88.37%\n",
            "Accuracy of n02115913-dhole: 100.00%\n",
            "Accuracy of n02113799-standard_poodle: 20.00%\n",
            "Accuracy of n02111500-Great_Pyrenees: 36.96%\n",
            "Accuracy of n02113186-Cardigan: 67.65%\n",
            "Accuracy of n02112350-keeshond: 91.67%\n",
            "Accuracy of n02113978-Mexican_hairless: 92.86%\n",
            "Accuracy of n02085620-Chihuahua: 38.71%\n",
            "Accuracy of n02085936-Maltese_dog: 48.94%\n",
            "Accuracy of n02086079-Pekinese: 55.00%\n",
            "Accuracy of n02087394-Rhodesian_ridgeback: 88.64%\n",
            "Accuracy of n02088632-bluetick: 93.94%\n",
            "Accuracy of n02089078-black-and-tan_coonhound: 48.28%\n",
            "Accuracy of n02089867-Walker_hound: 59.26%\n",
            "Accuracy of n02089973-English_foxhound: 42.86%\n",
            "Accuracy of n02090379-redbone: 51.52%\n",
            "Accuracy of n02091032-Italian_greyhound: 88.46%\n",
            "Accuracy of n02091244-Ibizan_hound: 90.00%\n",
            "Accuracy of n02091635-otterhound: 67.74%\n",
            "Accuracy of n02091831-Saluki: 84.85%\n",
            "Accuracy of n02092339-Weimaraner: 74.07%\n",
            "Accuracy of n02093647-Bedlington_terrier: 81.40%\n",
            "Accuracy of n02093754-Border_terrier: 83.33%\n",
            "Accuracy of n02093991-Irish_terrier: 57.69%\n",
            "Accuracy of n02094114-Norfolk_terrier: 71.79%\n",
            "Accuracy of n02094433-Yorkshire_terrier: 47.50%\n",
            "Accuracy of n02095314-wire-haired_fox_terrier: 61.11%\n",
            "Accuracy of n02095889-Sealyham_terrier: 87.93%\n",
            "Accuracy of n02097298-Scotch_terrier: 75.00%\n",
            "Accuracy of n02097658-silky_terrier: 67.65%\n",
            "Accuracy of n02098105-soft-coated_wheaten_terrier: 64.00%\n",
            "Accuracy of n02099601-golden_retriever: 73.08%\n",
            "Accuracy of n02100583-vizsla: 44.74%\n",
            "Accuracy of n02100735-English_setter: 67.57%\n",
            "Accuracy of n02100877-Irish_setter: 77.42%\n",
            "Accuracy of n02101388-Brittany_spaniel: 60.00%\n",
            "Accuracy of n02101556-clumber: 82.76%\n",
            "Accuracy of n02102040-English_springer: 65.22%\n",
            "Accuracy of n02102973-Irish_water_spaniel: 71.43%\n",
            "Accuracy of n02104365-schipperke: 92.11%\n",
            "Accuracy of n02105056-groenendael: 50.00%\n",
            "Accuracy of n02105251-briard: 78.79%\n",
            "Accuracy of n02105412-kelpie: 68.18%\n",
            "Accuracy of n02106030-collie: 18.18%\n",
            "Accuracy of n02106382-Bouvier_des_Flandres: 71.88%\n",
            "Accuracy of n02106550-Rottweiler: 92.59%\n",
            "Accuracy of n02107142-Doberman: 67.86%\n",
            "Accuracy of n02107312-miniature_pinscher: 62.16%\n",
            "Accuracy of n02108422-bull_mastiff: 75.86%\n",
            "Accuracy of n02109047-Great_Dane: 33.33%\n",
            "Accuracy of n02109525-Saint_Bernard: 75.76%\n",
            "Accuracy of n02109961-Eskimo_dog: 11.11%\n",
            "Accuracy of n02110958-pug: 72.50%\n",
            "Accuracy of n02111129-Leonberg: 94.12%\n",
            "Accuracy of n02111277-Newfoundland: 79.49%\n",
            "Accuracy of n02111889-Samoyed: 94.59%\n",
            "Accuracy of n02112137-chow: 75.86%\n",
            "Accuracy of n02112706-Brabancon_griffon: 91.67%\n",
            "Accuracy of n02113624-toy_poodle: 9.09%\n",
            "Accuracy of n02113712-miniature_poodle: 57.14%\n",
            "Accuracy of n02115641-dingo: 60.71%\n",
            "Accuracy of n02116738-African_hunting_dog: 97.67%\n",
            "Epoch 2/5\n",
            "----------\n",
            "Batch 100, Loss: 1.0770, Acc: 72.25%\n",
            "Batch 200, Loss: 1.0547, Acc: 72.98%\n",
            "Batch 300, Loss: 1.0365, Acc: 72.93%\n",
            "Batch 400, Loss: 1.0244, Acc: 72.95%\n",
            "Batch 500, Loss: 1.0076, Acc: 73.04%\n",
            "Train Loss: 1.0070, Train Acc: 73.02%, F1-macro: 0.7253\n",
            "Test Loss: 0.9750, Test Acc: 71.21%, F1-macro: 0.7039\n",
            "Accuracy of n02086240-Shih-Tzu: 64.10%\n",
            "Accuracy of n02092002-Scottish_deerhound: 76.60%\n",
            "Accuracy of n02085782-Japanese_spaniel: 96.43%\n",
            "Accuracy of n02090622-borzoi: 70.97%\n",
            "Accuracy of n02088238-basset: 68.00%\n",
            "Accuracy of n02090721-Irish_wolfhound: 74.42%\n",
            "Accuracy of n02093859-Kerry_blue_terrier: 67.74%\n",
            "Accuracy of n02091467-Norwegian_elkhound: 91.67%\n",
            "Accuracy of n02091134-whippet: 26.67%\n",
            "Accuracy of n02088364-beagle: 80.95%\n",
            "Accuracy of n02093256-Staffordshire_bullterrier: 51.61%\n",
            "Accuracy of n02086910-papillon: 80.85%\n",
            "Accuracy of n02094258-Norwich_terrier: 83.33%\n",
            "Accuracy of n02088094-Afghan_hound: 80.77%\n",
            "Accuracy of n02086646-Blenheim_spaniel: 95.12%\n",
            "Accuracy of n02093428-American_Staffordshire_terrier: 34.21%\n",
            "Accuracy of n02087046-toy_terrier: 63.64%\n",
            "Accuracy of n02088466-bloodhound: 54.05%\n",
            "Accuracy of n02100236-German_short-haired_pointer: 65.00%\n",
            "Accuracy of n02096437-Dandie_Dinmont: 79.49%\n",
            "Accuracy of n02096585-Boston_bull: 93.33%\n",
            "Accuracy of n02097209-standard_schnauzer: 62.50%\n",
            "Accuracy of n02101006-Gordon_setter: 81.82%\n",
            "Accuracy of n02110806-basenji: 60.00%\n",
            "Accuracy of n02097047-miniature_schnauzer: 68.75%\n",
            "Accuracy of n02097474-Tibetan_terrier: 68.29%\n",
            "Accuracy of n02095570-Lakeland_terrier: 41.86%\n",
            "Accuracy of n02096177-cairn: 71.79%\n",
            "Accuracy of n02104029-kuvasz: 62.07%\n",
            "Accuracy of n02096051-Airedale: 74.36%\n",
            "Accuracy of n02105641-Old_English_sheepdog: 78.12%\n",
            "Accuracy of n02108089-boxer: 66.67%\n",
            "Accuracy of n02099267-flat-coated_retriever: 84.38%\n",
            "Accuracy of n02107683-Bernese_mountain_dog: 94.00%\n",
            "Accuracy of n02110063-malamute: 47.06%\n",
            "Accuracy of n02110627-affenpinscher: 72.97%\n",
            "Accuracy of n02110185-Siberian_husky: 73.68%\n",
            "Accuracy of n02102177-Welsh_springer_spaniel: 84.00%\n",
            "Accuracy of n02098413-Lhasa: 28.12%\n",
            "Accuracy of n02099429-curly-coated_retriever: 78.12%\n",
            "Accuracy of n02105855-Shetland_sheepdog: 48.00%\n",
            "Accuracy of n02102318-cocker_spaniel: 45.71%\n",
            "Accuracy of n02108000-EntleBucher: 81.40%\n",
            "Accuracy of n02102480-Sussex_spaniel: 74.19%\n",
            "Accuracy of n02107574-Greater_Swiss_Mountain_dog: 74.07%\n",
            "Accuracy of n02099849-Chesapeake_Bay_retriever: 68.18%\n",
            "Accuracy of n02108915-French_bulldog: 43.90%\n",
            "Accuracy of n02106166-Border_collie: 68.97%\n",
            "Accuracy of n02097130-giant_schnauzer: 53.57%\n",
            "Accuracy of n02099712-Labrador_retriever: 69.05%\n",
            "Accuracy of n02105505-komondor: 87.50%\n",
            "Accuracy of n02107908-Appenzeller: 34.48%\n",
            "Accuracy of n02106662-German_shepherd: 62.50%\n",
            "Accuracy of n02105162-malinois: 71.88%\n",
            "Accuracy of n02108551-Tibetan_mastiff: 90.62%\n",
            "Accuracy of n02096294-Australian_terrier: 70.45%\n",
            "Accuracy of n02098286-West_Highland_white_terrier: 87.10%\n",
            "Accuracy of n02112018-Pomeranian: 84.09%\n",
            "Accuracy of n02113023-Pembroke: 65.12%\n",
            "Accuracy of n02115913-dhole: 90.00%\n",
            "Accuracy of n02113799-standard_poodle: 45.00%\n",
            "Accuracy of n02111500-Great_Pyrenees: 52.17%\n",
            "Accuracy of n02113186-Cardigan: 50.00%\n",
            "Accuracy of n02112350-keeshond: 91.67%\n",
            "Accuracy of n02113978-Mexican_hairless: 92.86%\n",
            "Accuracy of n02085620-Chihuahua: 38.71%\n",
            "Accuracy of n02085936-Maltese_dog: 61.70%\n",
            "Accuracy of n02086079-Pekinese: 70.00%\n",
            "Accuracy of n02087394-Rhodesian_ridgeback: 45.45%\n",
            "Accuracy of n02088632-bluetick: 93.94%\n",
            "Accuracy of n02089078-black-and-tan_coonhound: 72.41%\n",
            "Accuracy of n02089867-Walker_hound: 55.56%\n",
            "Accuracy of n02089973-English_foxhound: 32.14%\n",
            "Accuracy of n02090379-redbone: 90.91%\n",
            "Accuracy of n02091032-Italian_greyhound: 84.62%\n",
            "Accuracy of n02091244-Ibizan_hound: 86.67%\n",
            "Accuracy of n02091635-otterhound: 74.19%\n",
            "Accuracy of n02091831-Saluki: 75.76%\n",
            "Accuracy of n02092339-Weimaraner: 96.30%\n",
            "Accuracy of n02093647-Bedlington_terrier: 95.35%\n",
            "Accuracy of n02093754-Border_terrier: 83.33%\n",
            "Accuracy of n02093991-Irish_terrier: 84.62%\n",
            "Accuracy of n02094114-Norfolk_terrier: 51.28%\n",
            "Accuracy of n02094433-Yorkshire_terrier: 57.50%\n",
            "Accuracy of n02095314-wire-haired_fox_terrier: 75.00%\n",
            "Accuracy of n02095889-Sealyham_terrier: 96.55%\n",
            "Accuracy of n02097298-Scotch_terrier: 78.57%\n",
            "Accuracy of n02097658-silky_terrier: 70.59%\n",
            "Accuracy of n02098105-soft-coated_wheaten_terrier: 72.00%\n",
            "Accuracy of n02099601-golden_retriever: 80.77%\n",
            "Accuracy of n02100583-vizsla: 60.53%\n",
            "Accuracy of n02100735-English_setter: 72.97%\n",
            "Accuracy of n02100877-Irish_setter: 83.87%\n",
            "Accuracy of n02101388-Brittany_spaniel: 63.33%\n",
            "Accuracy of n02101556-clumber: 82.76%\n",
            "Accuracy of n02102040-English_springer: 78.26%\n",
            "Accuracy of n02102973-Irish_water_spaniel: 85.71%\n",
            "Accuracy of n02104365-schipperke: 97.37%\n",
            "Accuracy of n02105056-groenendael: 85.00%\n",
            "Accuracy of n02105251-briard: 75.76%\n",
            "Accuracy of n02105412-kelpie: 50.00%\n",
            "Accuracy of n02106030-collie: 45.45%\n",
            "Accuracy of n02106382-Bouvier_des_Flandres: 75.00%\n",
            "Accuracy of n02106550-Rottweiler: 88.89%\n",
            "Accuracy of n02107142-Doberman: 57.14%\n",
            "Accuracy of n02107312-miniature_pinscher: 75.68%\n",
            "Accuracy of n02108422-bull_mastiff: 72.41%\n",
            "Accuracy of n02109047-Great_Dane: 70.83%\n",
            "Accuracy of n02109525-Saint_Bernard: 87.88%\n",
            "Accuracy of n02109961-Eskimo_dog: 14.81%\n",
            "Accuracy of n02110958-pug: 67.50%\n",
            "Accuracy of n02111129-Leonberg: 94.12%\n",
            "Accuracy of n02111277-Newfoundland: 74.36%\n",
            "Accuracy of n02111889-Samoyed: 91.89%\n",
            "Accuracy of n02112137-chow: 82.76%\n",
            "Accuracy of n02112706-Brabancon_griffon: 88.89%\n",
            "Accuracy of n02113624-toy_poodle: 30.30%\n",
            "Accuracy of n02113712-miniature_poodle: 57.14%\n",
            "Accuracy of n02115641-dingo: 82.14%\n",
            "Accuracy of n02116738-African_hunting_dog: 100.00%\n",
            "Epoch 3/5\n",
            "----------\n",
            "Batch 100, Loss: 0.8009, Acc: 78.06%\n",
            "Batch 200, Loss: 0.8191, Acc: 77.44%\n",
            "Batch 300, Loss: 0.8300, Acc: 76.98%\n",
            "Batch 400, Loss: 0.8237, Acc: 76.85%\n",
            "Batch 500, Loss: 0.8180, Acc: 76.99%\n",
            "Train Loss: 0.8198, Train Acc: 76.91%, F1-macro: 0.7654\n",
            "Test Loss: 0.9354, Test Acc: 71.50%, F1-macro: 0.7066\n",
            "Accuracy of n02086240-Shih-Tzu: 5.13%\n",
            "Accuracy of n02092002-Scottish_deerhound: 82.98%\n",
            "Accuracy of n02085782-Japanese_spaniel: 92.86%\n",
            "Accuracy of n02090622-borzoi: 70.97%\n",
            "Accuracy of n02088238-basset: 76.00%\n",
            "Accuracy of n02090721-Irish_wolfhound: 76.74%\n",
            "Accuracy of n02093859-Kerry_blue_terrier: 58.06%\n",
            "Accuracy of n02091467-Norwegian_elkhound: 77.78%\n",
            "Accuracy of n02091134-whippet: 56.67%\n",
            "Accuracy of n02088364-beagle: 71.43%\n",
            "Accuracy of n02093256-Staffordshire_bullterrier: 19.35%\n",
            "Accuracy of n02086910-papillon: 80.85%\n",
            "Accuracy of n02094258-Norwich_terrier: 83.33%\n",
            "Accuracy of n02088094-Afghan_hound: 88.46%\n",
            "Accuracy of n02086646-Blenheim_spaniel: 90.24%\n",
            "Accuracy of n02093428-American_Staffordshire_terrier: 50.00%\n",
            "Accuracy of n02087046-toy_terrier: 66.67%\n",
            "Accuracy of n02088466-bloodhound: 78.38%\n",
            "Accuracy of n02100236-German_short-haired_pointer: 92.50%\n",
            "Accuracy of n02096437-Dandie_Dinmont: 84.62%\n",
            "Accuracy of n02096585-Boston_bull: 93.33%\n",
            "Accuracy of n02097209-standard_schnauzer: 65.00%\n",
            "Accuracy of n02101006-Gordon_setter: 81.82%\n",
            "Accuracy of n02110806-basenji: 64.44%\n",
            "Accuracy of n02097047-miniature_schnauzer: 65.62%\n",
            "Accuracy of n02097474-Tibetan_terrier: 73.17%\n",
            "Accuracy of n02095570-Lakeland_terrier: 48.84%\n",
            "Accuracy of n02096177-cairn: 69.23%\n",
            "Accuracy of n02104029-kuvasz: 79.31%\n",
            "Accuracy of n02096051-Airedale: 89.74%\n",
            "Accuracy of n02105641-Old_English_sheepdog: 81.25%\n",
            "Accuracy of n02108089-boxer: 58.33%\n",
            "Accuracy of n02099267-flat-coated_retriever: 81.25%\n",
            "Accuracy of n02107683-Bernese_mountain_dog: 94.00%\n",
            "Accuracy of n02110063-malamute: 76.47%\n",
            "Accuracy of n02110627-affenpinscher: 72.97%\n",
            "Accuracy of n02110185-Siberian_husky: 39.47%\n",
            "Accuracy of n02102177-Welsh_springer_spaniel: 92.00%\n",
            "Accuracy of n02098413-Lhasa: 75.00%\n",
            "Accuracy of n02099429-curly-coated_retriever: 87.50%\n",
            "Accuracy of n02105855-Shetland_sheepdog: 88.00%\n",
            "Accuracy of n02102318-cocker_spaniel: 71.43%\n",
            "Accuracy of n02108000-EntleBucher: 83.72%\n",
            "Accuracy of n02102480-Sussex_spaniel: 77.42%\n",
            "Accuracy of n02107574-Greater_Swiss_Mountain_dog: 62.96%\n",
            "Accuracy of n02099849-Chesapeake_Bay_retriever: 54.55%\n",
            "Accuracy of n02108915-French_bulldog: 63.41%\n",
            "Accuracy of n02106166-Border_collie: 79.31%\n",
            "Accuracy of n02097130-giant_schnauzer: 50.00%\n",
            "Accuracy of n02099712-Labrador_retriever: 64.29%\n",
            "Accuracy of n02105505-komondor: 83.33%\n",
            "Accuracy of n02107908-Appenzeller: 58.62%\n",
            "Accuracy of n02106662-German_shepherd: 59.38%\n",
            "Accuracy of n02105162-malinois: 71.88%\n",
            "Accuracy of n02108551-Tibetan_mastiff: 87.50%\n",
            "Accuracy of n02096294-Australian_terrier: 68.18%\n",
            "Accuracy of n02098286-West_Highland_white_terrier: 83.87%\n",
            "Accuracy of n02112018-Pomeranian: 72.73%\n",
            "Accuracy of n02113023-Pembroke: 86.05%\n",
            "Accuracy of n02115913-dhole: 100.00%\n",
            "Accuracy of n02113799-standard_poodle: 55.00%\n",
            "Accuracy of n02111500-Great_Pyrenees: 63.04%\n",
            "Accuracy of n02113186-Cardigan: 47.06%\n",
            "Accuracy of n02112350-keeshond: 88.89%\n",
            "Accuracy of n02113978-Mexican_hairless: 92.86%\n",
            "Accuracy of n02085620-Chihuahua: 48.39%\n",
            "Accuracy of n02085936-Maltese_dog: 63.83%\n",
            "Accuracy of n02086079-Pekinese: 75.00%\n",
            "Accuracy of n02087394-Rhodesian_ridgeback: 68.18%\n",
            "Accuracy of n02088632-bluetick: 66.67%\n",
            "Accuracy of n02089078-black-and-tan_coonhound: 86.21%\n",
            "Accuracy of n02089867-Walker_hound: 37.04%\n",
            "Accuracy of n02089973-English_foxhound: 67.86%\n",
            "Accuracy of n02090379-redbone: 48.48%\n",
            "Accuracy of n02091032-Italian_greyhound: 84.62%\n",
            "Accuracy of n02091244-Ibizan_hound: 76.67%\n",
            "Accuracy of n02091635-otterhound: 67.74%\n",
            "Accuracy of n02091831-Saluki: 63.64%\n",
            "Accuracy of n02092339-Weimaraner: 96.30%\n",
            "Accuracy of n02093647-Bedlington_terrier: 86.05%\n",
            "Accuracy of n02093754-Border_terrier: 86.11%\n",
            "Accuracy of n02093991-Irish_terrier: 80.77%\n",
            "Accuracy of n02094114-Norfolk_terrier: 56.41%\n",
            "Accuracy of n02094433-Yorkshire_terrier: 67.50%\n",
            "Accuracy of n02095314-wire-haired_fox_terrier: 75.00%\n",
            "Accuracy of n02095889-Sealyham_terrier: 94.83%\n",
            "Accuracy of n02097298-Scotch_terrier: 64.29%\n",
            "Accuracy of n02097658-silky_terrier: 67.65%\n",
            "Accuracy of n02098105-soft-coated_wheaten_terrier: 64.00%\n",
            "Accuracy of n02099601-golden_retriever: 69.23%\n",
            "Accuracy of n02100583-vizsla: 78.95%\n",
            "Accuracy of n02100735-English_setter: 67.57%\n",
            "Accuracy of n02100877-Irish_setter: 83.87%\n",
            "Accuracy of n02101388-Brittany_spaniel: 60.00%\n",
            "Accuracy of n02101556-clumber: 82.76%\n",
            "Accuracy of n02102040-English_springer: 69.57%\n",
            "Accuracy of n02102973-Irish_water_spaniel: 67.86%\n",
            "Accuracy of n02104365-schipperke: 92.11%\n",
            "Accuracy of n02105056-groenendael: 32.50%\n",
            "Accuracy of n02105251-briard: 75.76%\n",
            "Accuracy of n02105412-kelpie: 59.09%\n",
            "Accuracy of n02106030-collie: 13.64%\n",
            "Accuracy of n02106382-Bouvier_des_Flandres: 81.25%\n",
            "Accuracy of n02106550-Rottweiler: 81.48%\n",
            "Accuracy of n02107142-Doberman: 53.57%\n",
            "Accuracy of n02107312-miniature_pinscher: 75.68%\n",
            "Accuracy of n02108422-bull_mastiff: 72.41%\n",
            "Accuracy of n02109047-Great_Dane: 50.00%\n",
            "Accuracy of n02109525-Saint_Bernard: 90.91%\n",
            "Accuracy of n02109961-Eskimo_dog: 51.85%\n",
            "Accuracy of n02110958-pug: 85.00%\n",
            "Accuracy of n02111129-Leonberg: 94.12%\n",
            "Accuracy of n02111277-Newfoundland: 71.79%\n",
            "Accuracy of n02111889-Samoyed: 81.08%\n",
            "Accuracy of n02112137-chow: 96.55%\n",
            "Accuracy of n02112706-Brabancon_griffon: 94.44%\n",
            "Accuracy of n02113624-toy_poodle: 51.52%\n",
            "Accuracy of n02113712-miniature_poodle: 11.43%\n",
            "Accuracy of n02115641-dingo: 60.71%\n",
            "Accuracy of n02116738-African_hunting_dog: 100.00%\n",
            "Epoch 4/5\n",
            "----------\n",
            "Batch 100, Loss: 0.7211, Acc: 79.44%\n",
            "Batch 200, Loss: 0.7147, Acc: 79.38%\n",
            "Batch 300, Loss: 0.7211, Acc: 79.03%\n",
            "Batch 400, Loss: 0.7178, Acc: 79.20%\n",
            "Batch 500, Loss: 0.7161, Acc: 79.16%\n",
            "Train Loss: 0.7147, Train Acc: 79.25%, F1-macro: 0.7897\n",
            "Test Loss: 0.9205, Test Acc: 72.52%, F1-macro: 0.7167\n",
            "Accuracy of n02086240-Shih-Tzu: 82.05%\n",
            "Accuracy of n02092002-Scottish_deerhound: 87.23%\n",
            "Accuracy of n02085782-Japanese_spaniel: 85.71%\n",
            "Accuracy of n02090622-borzoi: 90.32%\n",
            "Accuracy of n02088238-basset: 76.00%\n",
            "Accuracy of n02090721-Irish_wolfhound: 67.44%\n",
            "Accuracy of n02093859-Kerry_blue_terrier: 48.39%\n",
            "Accuracy of n02091467-Norwegian_elkhound: 75.00%\n",
            "Accuracy of n02091134-whippet: 60.00%\n",
            "Accuracy of n02088364-beagle: 80.95%\n",
            "Accuracy of n02093256-Staffordshire_bullterrier: 54.84%\n",
            "Accuracy of n02086910-papillon: 70.21%\n",
            "Accuracy of n02094258-Norwich_terrier: 66.67%\n",
            "Accuracy of n02088094-Afghan_hound: 92.31%\n",
            "Accuracy of n02086646-Blenheim_spaniel: 87.80%\n",
            "Accuracy of n02093428-American_Staffordshire_terrier: 50.00%\n",
            "Accuracy of n02087046-toy_terrier: 72.73%\n",
            "Accuracy of n02088466-bloodhound: 62.16%\n",
            "Accuracy of n02100236-German_short-haired_pointer: 75.00%\n",
            "Accuracy of n02096437-Dandie_Dinmont: 92.31%\n",
            "Accuracy of n02096585-Boston_bull: 93.33%\n",
            "Accuracy of n02097209-standard_schnauzer: 57.50%\n",
            "Accuracy of n02101006-Gordon_setter: 78.79%\n",
            "Accuracy of n02110806-basenji: 80.00%\n",
            "Accuracy of n02097047-miniature_schnauzer: 59.38%\n",
            "Accuracy of n02097474-Tibetan_terrier: 56.10%\n",
            "Accuracy of n02095570-Lakeland_terrier: 65.12%\n",
            "Accuracy of n02096177-cairn: 74.36%\n",
            "Accuracy of n02104029-kuvasz: 68.97%\n",
            "Accuracy of n02096051-Airedale: 87.18%\n",
            "Accuracy of n02105641-Old_English_sheepdog: 84.38%\n",
            "Accuracy of n02108089-boxer: 62.50%\n",
            "Accuracy of n02099267-flat-coated_retriever: 87.50%\n",
            "Accuracy of n02107683-Bernese_mountain_dog: 92.00%\n",
            "Accuracy of n02110063-malamute: 58.82%\n",
            "Accuracy of n02110627-affenpinscher: 67.57%\n",
            "Accuracy of n02110185-Siberian_husky: 63.16%\n",
            "Accuracy of n02102177-Welsh_springer_spaniel: 80.00%\n",
            "Accuracy of n02098413-Lhasa: 31.25%\n",
            "Accuracy of n02099429-curly-coated_retriever: 84.38%\n",
            "Accuracy of n02105855-Shetland_sheepdog: 76.00%\n",
            "Accuracy of n02102318-cocker_spaniel: 51.43%\n",
            "Accuracy of n02108000-EntleBucher: 76.74%\n",
            "Accuracy of n02102480-Sussex_spaniel: 74.19%\n",
            "Accuracy of n02107574-Greater_Swiss_Mountain_dog: 66.67%\n",
            "Accuracy of n02099849-Chesapeake_Bay_retriever: 86.36%\n",
            "Accuracy of n02108915-French_bulldog: 56.10%\n",
            "Accuracy of n02106166-Border_collie: 86.21%\n",
            "Accuracy of n02097130-giant_schnauzer: 67.86%\n",
            "Accuracy of n02099712-Labrador_retriever: 57.14%\n",
            "Accuracy of n02105505-komondor: 87.50%\n",
            "Accuracy of n02107908-Appenzeller: 72.41%\n",
            "Accuracy of n02106662-German_shepherd: 71.88%\n",
            "Accuracy of n02105162-malinois: 59.38%\n",
            "Accuracy of n02108551-Tibetan_mastiff: 68.75%\n",
            "Accuracy of n02096294-Australian_terrier: 86.36%\n",
            "Accuracy of n02098286-West_Highland_white_terrier: 83.87%\n",
            "Accuracy of n02112018-Pomeranian: 84.09%\n",
            "Accuracy of n02113023-Pembroke: 95.35%\n",
            "Accuracy of n02115913-dhole: 93.33%\n",
            "Accuracy of n02113799-standard_poodle: 50.00%\n",
            "Accuracy of n02111500-Great_Pyrenees: 63.04%\n",
            "Accuracy of n02113186-Cardigan: 41.18%\n",
            "Accuracy of n02112350-keeshond: 91.67%\n",
            "Accuracy of n02113978-Mexican_hairless: 92.86%\n",
            "Accuracy of n02085620-Chihuahua: 61.29%\n",
            "Accuracy of n02085936-Maltese_dog: 57.45%\n",
            "Accuracy of n02086079-Pekinese: 85.00%\n",
            "Accuracy of n02087394-Rhodesian_ridgeback: 43.18%\n",
            "Accuracy of n02088632-bluetick: 69.70%\n",
            "Accuracy of n02089078-black-and-tan_coonhound: 86.21%\n",
            "Accuracy of n02089867-Walker_hound: 40.74%\n",
            "Accuracy of n02089973-English_foxhound: 53.57%\n",
            "Accuracy of n02090379-redbone: 69.70%\n",
            "Accuracy of n02091032-Italian_greyhound: 73.08%\n",
            "Accuracy of n02091244-Ibizan_hound: 93.33%\n",
            "Accuracy of n02091635-otterhound: 67.74%\n",
            "Accuracy of n02091831-Saluki: 75.76%\n",
            "Accuracy of n02092339-Weimaraner: 92.59%\n",
            "Accuracy of n02093647-Bedlington_terrier: 97.67%\n",
            "Accuracy of n02093754-Border_terrier: 86.11%\n",
            "Accuracy of n02093991-Irish_terrier: 50.00%\n",
            "Accuracy of n02094114-Norfolk_terrier: 64.10%\n",
            "Accuracy of n02094433-Yorkshire_terrier: 45.00%\n",
            "Accuracy of n02095314-wire-haired_fox_terrier: 77.78%\n",
            "Accuracy of n02095889-Sealyham_terrier: 84.48%\n",
            "Accuracy of n02097298-Scotch_terrier: 85.71%\n",
            "Accuracy of n02097658-silky_terrier: 64.71%\n",
            "Accuracy of n02098105-soft-coated_wheaten_terrier: 68.00%\n",
            "Accuracy of n02099601-golden_retriever: 76.92%\n",
            "Accuracy of n02100583-vizsla: 68.42%\n",
            "Accuracy of n02100735-English_setter: 81.08%\n",
            "Accuracy of n02100877-Irish_setter: 93.55%\n",
            "Accuracy of n02101388-Brittany_spaniel: 60.00%\n",
            "Accuracy of n02101556-clumber: 82.76%\n",
            "Accuracy of n02102040-English_springer: 78.26%\n",
            "Accuracy of n02102973-Irish_water_spaniel: 82.14%\n",
            "Accuracy of n02104365-schipperke: 86.84%\n",
            "Accuracy of n02105056-groenendael: 65.00%\n",
            "Accuracy of n02105251-briard: 84.85%\n",
            "Accuracy of n02105412-kelpie: 54.55%\n",
            "Accuracy of n02106030-collie: 29.55%\n",
            "Accuracy of n02106382-Bouvier_des_Flandres: 84.38%\n",
            "Accuracy of n02106550-Rottweiler: 88.89%\n",
            "Accuracy of n02107142-Doberman: 42.86%\n",
            "Accuracy of n02107312-miniature_pinscher: 62.16%\n",
            "Accuracy of n02108422-bull_mastiff: 68.97%\n",
            "Accuracy of n02109047-Great_Dane: 66.67%\n",
            "Accuracy of n02109525-Saint_Bernard: 87.88%\n",
            "Accuracy of n02109961-Eskimo_dog: 18.52%\n",
            "Accuracy of n02110958-pug: 80.00%\n",
            "Accuracy of n02111129-Leonberg: 97.06%\n",
            "Accuracy of n02111277-Newfoundland: 76.92%\n",
            "Accuracy of n02111889-Samoyed: 75.68%\n",
            "Accuracy of n02112137-chow: 86.21%\n",
            "Accuracy of n02112706-Brabancon_griffon: 91.67%\n",
            "Accuracy of n02113624-toy_poodle: 18.18%\n",
            "Accuracy of n02113712-miniature_poodle: 60.00%\n",
            "Accuracy of n02115641-dingo: 67.86%\n",
            "Accuracy of n02116738-African_hunting_dog: 100.00%\n",
            "Epoch 5/5\n",
            "----------\n",
            "Batch 100, Loss: 0.6104, Acc: 81.97%\n",
            "Batch 200, Loss: 0.6225, Acc: 81.33%\n",
            "Batch 300, Loss: 0.6435, Acc: 80.40%\n",
            "Batch 400, Loss: 0.6447, Acc: 80.66%\n",
            "Batch 500, Loss: 0.6449, Acc: 80.79%\n",
            "Train Loss: 0.6432, Train Acc: 80.84%, F1-macro: 0.8058\n",
            "Test Loss: 0.9283, Test Acc: 72.11%, F1-macro: 0.7135\n",
            "Accuracy of n02086240-Shih-Tzu: 66.67%\n",
            "Accuracy of n02092002-Scottish_deerhound: 82.98%\n",
            "Accuracy of n02085782-Japanese_spaniel: 89.29%\n",
            "Accuracy of n02090622-borzoi: 70.97%\n",
            "Accuracy of n02088238-basset: 52.00%\n",
            "Accuracy of n02090721-Irish_wolfhound: 67.44%\n",
            "Accuracy of n02093859-Kerry_blue_terrier: 54.84%\n",
            "Accuracy of n02091467-Norwegian_elkhound: 86.11%\n",
            "Accuracy of n02091134-whippet: 53.33%\n",
            "Accuracy of n02088364-beagle: 85.71%\n",
            "Accuracy of n02093256-Staffordshire_bullterrier: 29.03%\n",
            "Accuracy of n02086910-papillon: 85.11%\n",
            "Accuracy of n02094258-Norwich_terrier: 72.22%\n",
            "Accuracy of n02088094-Afghan_hound: 96.15%\n",
            "Accuracy of n02086646-Blenheim_spaniel: 92.68%\n",
            "Accuracy of n02093428-American_Staffordshire_terrier: 42.11%\n",
            "Accuracy of n02087046-toy_terrier: 57.58%\n",
            "Accuracy of n02088466-bloodhound: 64.86%\n",
            "Accuracy of n02100236-German_short-haired_pointer: 85.00%\n",
            "Accuracy of n02096437-Dandie_Dinmont: 84.62%\n",
            "Accuracy of n02096585-Boston_bull: 43.33%\n",
            "Accuracy of n02097209-standard_schnauzer: 65.00%\n",
            "Accuracy of n02101006-Gordon_setter: 84.85%\n",
            "Accuracy of n02110806-basenji: 62.22%\n",
            "Accuracy of n02097047-miniature_schnauzer: 59.38%\n",
            "Accuracy of n02097474-Tibetan_terrier: 56.10%\n",
            "Accuracy of n02095570-Lakeland_terrier: 48.84%\n",
            "Accuracy of n02096177-cairn: 64.10%\n",
            "Accuracy of n02104029-kuvasz: 55.17%\n",
            "Accuracy of n02096051-Airedale: 84.62%\n",
            "Accuracy of n02105641-Old_English_sheepdog: 84.38%\n",
            "Accuracy of n02108089-boxer: 75.00%\n",
            "Accuracy of n02099267-flat-coated_retriever: 65.62%\n",
            "Accuracy of n02107683-Bernese_mountain_dog: 94.00%\n",
            "Accuracy of n02110063-malamute: 70.59%\n",
            "Accuracy of n02110627-affenpinscher: 54.05%\n",
            "Accuracy of n02110185-Siberian_husky: 44.74%\n",
            "Accuracy of n02102177-Welsh_springer_spaniel: 96.00%\n",
            "Accuracy of n02098413-Lhasa: 53.12%\n",
            "Accuracy of n02099429-curly-coated_retriever: 75.00%\n",
            "Accuracy of n02105855-Shetland_sheepdog: 76.00%\n",
            "Accuracy of n02102318-cocker_spaniel: 57.14%\n",
            "Accuracy of n02108000-EntleBucher: 74.42%\n",
            "Accuracy of n02102480-Sussex_spaniel: 77.42%\n",
            "Accuracy of n02107574-Greater_Swiss_Mountain_dog: 66.67%\n",
            "Accuracy of n02099849-Chesapeake_Bay_retriever: 56.82%\n",
            "Accuracy of n02108915-French_bulldog: 82.93%\n",
            "Accuracy of n02106166-Border_collie: 62.07%\n",
            "Accuracy of n02097130-giant_schnauzer: 67.86%\n",
            "Accuracy of n02099712-Labrador_retriever: 61.90%\n",
            "Accuracy of n02105505-komondor: 91.67%\n",
            "Accuracy of n02107908-Appenzeller: 68.97%\n",
            "Accuracy of n02106662-German_shepherd: 65.62%\n",
            "Accuracy of n02105162-malinois: 46.88%\n",
            "Accuracy of n02108551-Tibetan_mastiff: 71.88%\n",
            "Accuracy of n02096294-Australian_terrier: 77.27%\n",
            "Accuracy of n02098286-West_Highland_white_terrier: 87.10%\n",
            "Accuracy of n02112018-Pomeranian: 88.64%\n",
            "Accuracy of n02113023-Pembroke: 76.74%\n",
            "Accuracy of n02115913-dhole: 93.33%\n",
            "Accuracy of n02113799-standard_poodle: 45.00%\n",
            "Accuracy of n02111500-Great_Pyrenees: 65.22%\n",
            "Accuracy of n02113186-Cardigan: 58.82%\n",
            "Accuracy of n02112350-keeshond: 94.44%\n",
            "Accuracy of n02113978-Mexican_hairless: 96.43%\n",
            "Accuracy of n02085620-Chihuahua: 58.06%\n",
            "Accuracy of n02085936-Maltese_dog: 68.09%\n",
            "Accuracy of n02086079-Pekinese: 62.50%\n",
            "Accuracy of n02087394-Rhodesian_ridgeback: 84.09%\n",
            "Accuracy of n02088632-bluetick: 54.55%\n",
            "Accuracy of n02089078-black-and-tan_coonhound: 86.21%\n",
            "Accuracy of n02089867-Walker_hound: 74.07%\n",
            "Accuracy of n02089973-English_foxhound: 32.14%\n",
            "Accuracy of n02090379-redbone: 48.48%\n",
            "Accuracy of n02091032-Italian_greyhound: 76.92%\n",
            "Accuracy of n02091244-Ibizan_hound: 86.67%\n",
            "Accuracy of n02091635-otterhound: 80.65%\n",
            "Accuracy of n02091831-Saluki: 81.82%\n",
            "Accuracy of n02092339-Weimaraner: 96.30%\n",
            "Accuracy of n02093647-Bedlington_terrier: 95.35%\n",
            "Accuracy of n02093754-Border_terrier: 83.33%\n",
            "Accuracy of n02093991-Irish_terrier: 84.62%\n",
            "Accuracy of n02094114-Norfolk_terrier: 66.67%\n",
            "Accuracy of n02094433-Yorkshire_terrier: 70.00%\n",
            "Accuracy of n02095314-wire-haired_fox_terrier: 63.89%\n",
            "Accuracy of n02095889-Sealyham_terrier: 93.10%\n",
            "Accuracy of n02097298-Scotch_terrier: 64.29%\n",
            "Accuracy of n02097658-silky_terrier: 64.71%\n",
            "Accuracy of n02098105-soft-coated_wheaten_terrier: 68.00%\n",
            "Accuracy of n02099601-golden_retriever: 73.08%\n",
            "Accuracy of n02100583-vizsla: 76.32%\n",
            "Accuracy of n02100735-English_setter: 56.76%\n",
            "Accuracy of n02100877-Irish_setter: 90.32%\n",
            "Accuracy of n02101388-Brittany_spaniel: 66.67%\n",
            "Accuracy of n02101556-clumber: 86.21%\n",
            "Accuracy of n02102040-English_springer: 69.57%\n",
            "Accuracy of n02102973-Irish_water_spaniel: 89.29%\n",
            "Accuracy of n02104365-schipperke: 84.21%\n",
            "Accuracy of n02105056-groenendael: 77.50%\n",
            "Accuracy of n02105251-briard: 84.85%\n",
            "Accuracy of n02105412-kelpie: 59.09%\n",
            "Accuracy of n02106030-collie: 38.64%\n",
            "Accuracy of n02106382-Bouvier_des_Flandres: 68.75%\n",
            "Accuracy of n02106550-Rottweiler: 85.19%\n",
            "Accuracy of n02107142-Doberman: 60.71%\n",
            "Accuracy of n02107312-miniature_pinscher: 83.78%\n",
            "Accuracy of n02108422-bull_mastiff: 75.86%\n",
            "Accuracy of n02109047-Great_Dane: 50.00%\n",
            "Accuracy of n02109525-Saint_Bernard: 84.85%\n",
            "Accuracy of n02109961-Eskimo_dog: 29.63%\n",
            "Accuracy of n02110958-pug: 87.50%\n",
            "Accuracy of n02111129-Leonberg: 97.06%\n",
            "Accuracy of n02111277-Newfoundland: 89.74%\n",
            "Accuracy of n02111889-Samoyed: 91.89%\n",
            "Accuracy of n02112137-chow: 79.31%\n",
            "Accuracy of n02112706-Brabancon_griffon: 94.44%\n",
            "Accuracy of n02113624-toy_poodle: 63.64%\n",
            "Accuracy of n02113712-miniature_poodle: 11.43%\n",
            "Accuracy of n02115641-dingo: 78.57%\n",
            "Accuracy of n02116738-African_hunting_dog: 97.67%\n",
            "Best test accuracy: 72.52%\n"
          ]
        }
      ],
      "source": [
        "# First, add scikit-learn for metrics calculation\n",
        "from sklearn.metrics import f1_score\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import wandb\n",
        "\n",
        "# Ensure the model is on the correct device\n",
        "model = model.to(device)\n",
        "\n",
        "# Set up loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
        "\n",
        "# Log hyperparameters to W&B\n",
        "wandb.config.update({\n",
        "    \"optimizer\": \"Adam\",\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"criterion\": \"CrossEntropyLoss\",\n",
        "    \"epochs\": 5  # We'll train for just 5 epochs for this example\n",
        "})\n",
        "\n",
        "# Number of classes\n",
        "num_classes = len(class_labels)\n",
        "class_names = list(class_labels.keys())\n",
        "\n",
        "# Training loop\n",
        "def train_model(model, trainloader, criterion, optimizer, num_epochs=5):\n",
        "    # Track best accuracy\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        all_train_preds = []\n",
        "        all_train_labels = []\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "            # Collect predictions and labels for F1 calculation\n",
        "            all_train_preds.extend(predicted.cpu().numpy())\n",
        "            all_train_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            # Log batch statistics (every 100 batches)\n",
        "            if i % 100 == 99:\n",
        "                batch_acc = 100. * correct / total\n",
        "                batch_loss = running_loss / total\n",
        "                print(f'Batch {i+1}, Loss: {batch_loss:.4f}, Acc: {batch_acc:.2f}%')\n",
        "\n",
        "                wandb.log({\n",
        "                    \"train_batch_loss\": batch_loss,\n",
        "                    \"train_batch_acc\": batch_acc,\n",
        "                    \"epoch\": epoch + i/len(trainloader)\n",
        "                })\n",
        "\n",
        "        # Calculate epoch statistics\n",
        "        train_loss = running_loss / len(trainloader.dataset)\n",
        "        train_acc = 100. * correct / total\n",
        "\n",
        "        # Calculate F1 score for the training epoch\n",
        "        train_f1_macro = f1_score(all_train_labels, all_train_preds, average='macro')\n",
        "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, F1-macro: {train_f1_macro:.4f}')\n",
        "\n",
        "        # Evaluation phase\n",
        "        model.eval()\n",
        "        test_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        class_correct = list(0. for _ in range(num_classes))\n",
        "        class_total = list(0. for _ in range(num_classes))\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in testloader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Statistics\n",
        "                test_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "                # Per-class accuracy\n",
        "                c = (predicted == labels).squeeze()\n",
        "                for i in range(labels.size(0)):\n",
        "                    label = labels[i].item()\n",
        "                    class_correct[label] += c[i].item()\n",
        "                    class_total[label] += 1\n",
        "\n",
        "                # Store for confusion matrix and F1 calculation\n",
        "                all_preds.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        # Calculate test statistics\n",
        "        test_loss = test_loss / len(testloader.dataset)\n",
        "        test_acc = 100. * correct / total\n",
        "\n",
        "        # Calculate F1 score for test data\n",
        "        test_f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
        "        print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%, F1-macro: {test_f1_macro:.4f}')\n",
        "\n",
        "        # Per-class accuracy\n",
        "        for i in range(num_classes):\n",
        "            class_acc = 100 * class_correct[i] / class_total[i] if class_total[i] > 0 else 0\n",
        "            print(f'Accuracy of {class_names[i]}: {class_acc:.2f}%')\n",
        "\n",
        "        # Log epoch statistics to W&B\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"train_loss\": train_loss,\n",
        "            \"train_acc\": train_acc,\n",
        "            \"train_f1_macro\": train_f1_macro,\n",
        "            \"test_loss\": test_loss,\n",
        "            \"test_acc\": test_acc,\n",
        "            \"test_f1_macro\": test_f1_macro\n",
        "        })\n",
        "\n",
        "        # Log per-class accuracy\n",
        "        class_acc_dict = {f\"class_acc_{class_names[i]}\": 100 * class_correct[i] / class_total[i]\n",
        "                         if class_total[i] > 0 else 0 for i in range(num_classes)}\n",
        "        wandb.log(class_acc_dict)\n",
        "\n",
        "        # Log confusion matrix\n",
        "        wandb.log({\n",
        "            \"confusion_matrix\": wandb.plot.confusion_matrix(\n",
        "                probs=None,\n",
        "                y_true=all_labels,\n",
        "                preds=all_preds,\n",
        "                class_names=class_names\n",
        "            )\n",
        "        })\n",
        "\n",
        "        # Save model if it's the best so far\n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "            best_f1 = test_f1_macro\n",
        "            torch.save(model.state_dict(), f'resnet18_stanforddogs_epoch_{epoch+1}.pth')\n",
        "            wandb.save(f'resnet18_stanforddogs_epoch_{epoch+1}.pth')\n",
        "\n",
        "            # Log best model metrics to W&B summary\n",
        "            wandb.run.summary[\"best_accuracy\"] = best_acc\n",
        "            wandb.run.summary[\"best_f1_macro\"] = best_f1\n",
        "            wandb.run.summary[\"best_epoch\"] = epoch + 1\n",
        "\n",
        "    print(f'Best test accuracy: {best_acc:.2f}%')\n",
        "    return model\n",
        "\n",
        "# Train the model (without passing testloader)\n",
        "model = train_model(model, trainloader, criterion, optimizer)\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'resnet18_stanforddogs_final.pth')\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
